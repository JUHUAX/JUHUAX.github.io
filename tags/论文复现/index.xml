<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>论文复现 on BLOG</title>
    <link>https://juhuax.github.io/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/</link>
    <description>Recent content in 论文复现 on BLOG</description>
    <image>
      <title>BLOG</title>
      <url>https://juhuax.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://juhuax.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 11 Jun 2023 02:01:58 +0530</lastBuildDate><atom:link href="https://juhuax.github.io/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Automatic Recovery of Fine-grained Compiler Artifacts at the Binary Level复现</title>
      <link>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/automatic-recovery-of-fine-grained-compiler-artifacts-at-the-binary-level%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Sun, 11 Jun 2023 02:01:58 +0530</pubDate>
      
      <guid>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/automatic-recovery-of-fine-grained-compiler-artifacts-at-the-binary-level%E5%A4%8D%E7%8E%B0/</guid>
      <description>[[Automatic Recovery of Fine-grained Compiler Artifacts at the Binary Level]] GitHub 地址：zeropointdynamics/passtell (github.com)
数据集结构 passtell_dataset. tar. xz ：PassTell 实验中使用的数据集的存档，包括: &amp;rsquo; balanced_dataset. csv &amp;lsquo;: 用于粗粒度编译器配置分类的数据集。如第 6.1 节所述，此数据集是 NeuralCI 中使用的数据集的平衡子集。 用于 6.1 节的实验——编译器配置识别 数据集由数据集中所有动态链接的未分解的可执行文件组成，包括 binutils、busybox、coreutils、curl、ffmpeg、git、gsl、libpng、openssl、postgresql、sqlite、valgrind、vim、zlib 和 gdb。 &amp;rsquo; data. csv &amp;lsquo;: 用于 6.2 节中使用的细粒度编译器传递分类的数据集。 用于 6.2 节实验——优化传递识别 编译器传递数据集由来自用 Clang 14 编译的 binutils (2.37)、coreutils (9.0)、httpd (2.4.51) 和 sqlite (3.36.0) 程序的函数组成，使用-O0、-O1、-O2 和-O3 优化级别，在 552 个二进制文件中生成总共 149, 814 个函数。然后，我们为每一次传递平衡数据集: 对于每一次传递，我们随机选择等量的应用了传递的函数 (即正样本) 和没有应用传递的函数 (即负样本)。我们还将每次传递的最大样本数量限制为 5, 000 个正样本和 5, 000 个负样本。 &amp;rsquo; data_dynamic.</description>
    </item>
    
    <item>
      <title>Identifying Compiler and Optimization Level in Binary Code From Multiple Architectures复现</title>
      <link>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/identifying-compiler-and-optimization-level-in-binary-code-from-multiple-architectures%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Sun, 11 Jun 2023 02:01:58 +0530</pubDate>
      
      <guid>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/identifying-compiler-and-optimization-level-in-binary-code-from-multiple-architectures%E5%A4%8D%E7%8E%B0/</guid>
      <description>代码地址：GitHub - inoueke-n/optimization-detector: Optimization detection over compiled binaries [[Identifying Compiler and Optimization Level in Binary Code From Multiple Architectures]]
准备 实验用到的数据集 following link. 也可以自己按照 readme. md 文件中的 generation 节中的步骤来自己生成数据集。（因为文章中提到的担心被库文件污染，所以需要 docker 环境来生成） 文档结构 Resources 存储测试的二进制文件 Tests 和 src 文件存储源代码 generate_dataset.py 文件负责生成数据集（准确的说是交叉编译生成所需的二进制文件） optimization-detector.py 文件负责文件的提取（可执行数据），预处理（平衡数据集），训练、评估、推断。 数据集文件结构 Dataset 文件夹下的是已经经过预处理的数据集，raw 后缀表示采用原始字节作为输入，func 表示按照函数边界进行了拆分
但是没有优化等级是 O3 的数据啊 突然懂了这个逻辑，process 的输入是 func 和 raw 文件，输出 train. bin、test. Bin、validate. Bin 文件，然后 train 用 train. Bin 、validate. Bin 文件训练，evaluate 用 test. Bin 看效果</description>
    </item>
    
    <item>
      <title>NeuralCI 复现</title>
      <link>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/neuralci-%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Sun, 11 Jun 2023 02:01:58 +0530</pubDate>
      
      <guid>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/neuralci-%E5%A4%8D%E7%8E%B0/</guid>
      <description>[[Fine-Grained Compiler Identification With Sequence-Oriented Neural Modeling]] 实验评估中用 NeuralBS CNN，NeuralSD CNN 和 NeuralAD CNN 来表示基础 CNN，带有缩放点积注意力的增强 CNN 和带有附加注意力的增强 CNN 在以下实验评估中使用 NeuralBS GRU，NeuralSD GRU，NeuralAD GRU 和 NeuralQU GRU（SD 和 AD 和 CNN 一样，QU 是新加的）
识别编译器系列 family 识别编译器版本 version 识别优化级别 binaryOptimization 和 tripleOptimization
目前存在的问题：
Full 和 done 后缀的文件不明白用途，Binary 和 done 的区别 TensorFlow 版本不兼容，需要改部分代码 代码中的文件路径指向（所需要的）文件没有，貌似需要自己构建数据集（IDA pro 提取什么的） </description>
    </item>
    
    <item>
      <title>VulHawk 复现</title>
      <link>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/vulhawk-%E5%A4%8D%E7%8E%B0/</link>
      <pubDate>Sun, 11 Jun 2023 02:01:58 +0530</pubDate>
      
      <guid>https://juhuax.github.io/posts/1.%E5%AD%A6%E4%B9%A0/1.%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/%E5%A4%8D%E7%8E%B0/vulhawk-%E5%A4%8D%E7%8E%B0/</guid>
      <description>[[VulHawk Cross-architecture Vulnerability Detection with Entropy-based Binary Code Search]]
Get Started Prerequisites Windows (MacOS and Linux also work) Python 3.8.2 (64 bit) PyTorch 1.13.1 CUDA 11.7 IDA pro 7.5+ (only used for dataset processing) Quick Start File Environment Identification python 2_FileEnvironmentIdentification.py
Function Embedding Generation python 3_function_embedding_generation.py
Binary Function Similarity Detection python 4_binary_code_search.py
论文基本流程 整体输入是二进制文件，然后分两部分进行：
IRFM：对输入的二进制程序进行处理得到 IR，IR 作为 IRFM 的输入，输出是 IR 的词嵌入 首先进行 IR 生成和指令简化 然后使用 Masked Language Model (MLM)、根操作数预测 (ROP) 和相邻块预测 (ABP) 进行预训练 然后生成基本块嵌入 用基本块嵌入和 cfg 生成函数嵌入（GCN 网络是用来捕获 cfg 的） 基于熵的适配器： 首先计算二进制文件的熵值 使用残差神经网络作为分类器判断二进制文件属于哪种文件环境（编译器、优化级别等等） 上面两个一个得到二进制文件的函数嵌入，另一个得到二进制文件的文件环境，并且将二进制文件映射到一个中间环境中，减弱不同文件环境带来的影响。 用函数嵌入进行渐进式搜索</description>
    </item>
    
  </channel>
</rss>
